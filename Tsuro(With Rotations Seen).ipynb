{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10bcaa78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in c:\\users\\horridjoe\\opencv\\lib\\site-packages (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from gym) (1.23.5)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from gym) (0.0.8)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from gym) (2.2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygame in c:\\users\\horridjoe\\opencv\\lib\\site-packages (2.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf_agents==0.15.0 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (0.15.0)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tf_agents==0.15.0) (2.2.1)\n",
      "Requirement already satisfied: pygame==2.1.0 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tf_agents==0.15.0) (2.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tf_agents==0.15.0) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-probability>=0.18.0 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tf_agents==0.15.0) (0.19.0)\n",
      "Requirement already satisfied: absl-py>=0.6.1 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tf_agents==0.15.0) (1.3.0)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tf_agents==0.15.0) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tf_agents==0.15.0) (4.4.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tf_agents==0.15.0) (1.23.5)\n",
      "Requirement already satisfied: pillow in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tf_agents==0.15.0) (9.3.0)\n",
      "Requirement already satisfied: gym<=0.23.0,>=0.17.0 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tf_agents==0.15.0) (0.23.0)\n",
      "Requirement already satisfied: gin-config>=0.4.0 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tf_agents==0.15.0) (0.5.0)\n",
      "Requirement already satisfied: protobuf>=3.11.3 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tf_agents==0.15.0) (3.19.6)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from gym<=0.23.0,>=0.17.0->tf_agents==0.15.0) (0.0.8)\n",
      "Requirement already satisfied: decorator in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tensorflow-probability>=0.18.0->tf_agents==0.15.0) (5.1.1)\n",
      "Requirement already satisfied: gast>=0.3.2 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tensorflow-probability>=0.18.0->tf_agents==0.15.0) (0.4.0)\n",
      "Requirement already satisfied: dm-tree in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tensorflow-probability>=0.18.0->tf_agents==0.15.0) (0.1.8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\horridjoe\\opencv\\lib\\site-packages (2.11.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.11.0 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.19.6)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (4.4.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (22.11.23)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (65.6.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.51.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (14.0.6)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.28.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from packaging->tensorflow-intel==2.11.0->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2022.9.24)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\horridjoe\\opencv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install gym\n",
    "!pip install pygame\n",
    "!pip install tf_agents==0.15.0\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4929ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import pygame\n",
    "import time\n",
    "import random\n",
    "from gym import spaces\n",
    "from gym.envs.registration import register\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.networks import sequential\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.utils import common\n",
    "\n",
    "# player piece colors [player1, player2]\n",
    "colors = ['#FF0000', '#0000FF']\n",
    "\n",
    "# paths for each tile 1-35\n",
    "node_combinations = [ \n",
    "    [(0,3), (1,5), (2,6), (4,7)], [(0,4), (1,5), (2,6), (3,7)], [(0,3), (1,6), (2,5), (4,7)], [(0,6), (1,5), (2,4), (3,7)],\n",
    "    [(0,1), (2,3), (4,5), (6,7)], [(0,4), (1,5), (2,3), (6,7)], [(0,6), (1,5), (2,3), (4,7)], [(0,5), (1,4), (2,7), (3,6)],\n",
    "    [(0,5), (1,4), (2,6), (3,7)], [(0,3), (1,4), (2,5), (6,7)], [(0,6), (1,4), (2,5), (3,7)], [(0,5), (1,4), (2,3), (6,7)],\n",
    "    [(0,2), (1,3), (4,6), (5,7)], [(0,2), (1,3), (4,5), (6,7)], [(0,5), (1,3), (2,7), (4,6)], [(0,6), (1,3), (2,7), (4,5)],\n",
    "    [(0,4), (1,3), (2,6), (5,7)], [(0,5), (1,3), (2,6), (4,7)], [(0,4), (1,3), (2,5), (6,7)], [(0,6), (1,3), (2,5), (4,7)],\n",
    "    [(0,5), (1,3), (2,4), (6,7)], [(0,6), (1,3), (2,4), (5,7)], [(0,3), (1,2), (4,7), (5,6)], [(0,3), (1,2), (4,6), (5,7)],\n",
    "    [(0,3), (1,2), (4,5), (6,7)], [(0,4), (1,2), (3,7), (5,6)], [(0,5), (1,2), (3,7), (4,6)], [(0,6), (1,2), (3,7), (4,5)],\n",
    "    [(0,4), (1,2), (3,6), (5,7)], [(0,5), (1,2), (3,6), (4,7)], [(0,4), (1,2), (3,5), (6,7)], [(0,6), (1,2), (3,5), (4,7)],\n",
    "    [(0,5), (1,2), (3,4), (6,7)], [(0,6), (1,2), (3,4), (5,7)], [(0,7), (1,2), (3,4), (5,6)]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7550d8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tile():\n",
    "    def __init__(self, tile_num, tile_connections):\n",
    "        self.tile_num = tile_num\n",
    "        self.image = pygame.image.load(\"TsuroImages/\" + str(tile_num) + \".png\")\n",
    "        self.image = pygame.transform.scale(self.image, (100, 100))\n",
    "        self.tile_connections = tile_connections\n",
    "        self.rotation = 1\n",
    "    \n",
    "    def move(self, current_node):\n",
    "        next_node = 0\n",
    "        next_player_tile = 0\n",
    "        for connection in self.tile_connections:\n",
    "            if current_node in connection:\n",
    "                n1, n2 = connection\n",
    "                if n1 == current_node:\n",
    "                    next_node, next_player_tile, next_x, next_y = self.new_tile_node(n2)\n",
    "                else:\n",
    "                    next_node, next_player_tile, next_x, next_y = self.new_tile_node(n1)\n",
    "                return next_node, next_player_tile, next_x, next_y\n",
    "        raise Exception(\"Issue in moving players\")\n",
    "    \n",
    "    # update number of times rotation should be applied to connections and image\n",
    "    def rotate_tile(self, rotate):\n",
    "        self.image = pygame.transform.rotate(self.image, rotate * -90)\n",
    "        self.tile_connections = [tuple((element + (2 * rotate)) % 8 for element in couple ) for couple in self.tile_connections]\n",
    "        self.rotation = 1 if (self.rotation + 1 % 4 == 0) else self.rotation + 1\n",
    "        \n",
    "    def get_rotation(self):\n",
    "        return self.rotation\n",
    "    \n",
    "    def new_tile_node(self, current_node):\n",
    "        next_node = 0\n",
    "        next_x = 0\n",
    "        next_y = 0\n",
    "        next_player_tile = 0\n",
    "        match current_node:\n",
    "            case 0:\n",
    "                next_node = 3\n",
    "                next_player_tile = -1\n",
    "                next_x = -1\n",
    "            case 1:\n",
    "                next_node = 6\n",
    "                next_player_tile = -6\n",
    "                next_y = -1\n",
    "            case 2:\n",
    "                next_node = 5\n",
    "                next_player_tile = -6\n",
    "                next_y = -1\n",
    "            case 3:\n",
    "                next_node = 0\n",
    "                next_player_tile = 1\n",
    "                next_x = 1\n",
    "            case 4:\n",
    "                next_node = 7\n",
    "                next_player_tile = 1\n",
    "                next_x = 1\n",
    "            case 5:\n",
    "                next_node = 2\n",
    "                next_player_tile = 6\n",
    "                next_y = 1\n",
    "            case 6:\n",
    "                next_node = 1\n",
    "                next_player_tile = 6\n",
    "                next_y = 1\n",
    "            case 7:\n",
    "                next_node = 4\n",
    "                next_player_tile = -1\n",
    "                next_x = -1\n",
    "            case _:\n",
    "                raise Exception(\"Issue in tile board\")\n",
    "                \n",
    "        return next_node, next_player_tile, next_x, next_y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55f8391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TsuroEnv(gym.Env):\n",
    "    #\n",
    "    def __init__(self):\n",
    "        self.screen = None\n",
    "        self.current_player = 1\n",
    "        self.num_tiles = 35\n",
    "        self.tile_board_size = (6, 6)\n",
    "        self.rotation_board_size = (6, 6)\n",
    "        self.player_board_size = (36,8)\n",
    "        self.num_players = 2\n",
    "        self.tiles = []\n",
    "        for i in range(self.num_tiles):\n",
    "            self.tiles.append(Tile(i, node_combinations[i]))\n",
    "            \n",
    "        self.remaining_tiles = []\n",
    "        for i in range(self.num_tiles):\n",
    "            self.remaining_tiles.append(i)\n",
    "        random.shuffle(self.remaining_tiles)\n",
    "\n",
    "        self.remaining_players = []\n",
    "        for i in range(self.num_players):\n",
    "            self.remaining_players.append(i+1)\n",
    "        \n",
    "        self.player_tiles = []\n",
    "        for i in range(self.num_players):\n",
    "            player_tiles = []\n",
    "            for i in range(3):\n",
    "                player_tiles.append(self.remaining_tiles.pop())\n",
    "            self.player_tiles.append(player_tiles)\n",
    "            \n",
    "        self.rotation_board = np.zeros(self.rotation_board_size, dtype = int)\n",
    "        self.tile_board = np.zeros(self.tile_board_size, dtype = int)\n",
    "        self.player_board = np.zeros(self.player_board_size, dtype = int)\n",
    "\n",
    "        self.action_space = spaces.Discrete(11)\n",
    "        self.observation_space = spaces.Box(low=-1, high=35, shape=(363,))\n",
    "        \n",
    "    # Resets the environment to default state\n",
    "    def reset(self): \n",
    "        self.current_player = 1\n",
    "        self.rotation_board = np.zeros(self.rotation_board_size, dtype = int)\n",
    "        self.tile_board = np.zeros(self.tile_board_size, dtype = int)\n",
    "        self.player_board = np.zeros(self.player_board_size, dtype = int)\n",
    "        \n",
    "        self.tiles = []\n",
    "        for i in range(self.num_tiles):\n",
    "            self.tiles.append(Tile(i, node_combinations[i]))\n",
    "            \n",
    "        self.remaining_tiles = []\n",
    "        for i in range(self.num_tiles):\n",
    "            self.remaining_tiles.append(i)\n",
    "        random.shuffle(self.remaining_tiles)\n",
    "            \n",
    "        self.remaining_players = []\n",
    "        for i in range(self.num_players):\n",
    "            self.remaining_players.append(i+1)\n",
    "            \n",
    "        self.player_tiles = []\n",
    "        for i in range(self.num_players):\n",
    "            player_tiles = []\n",
    "            for i in range(3):\n",
    "                player_tiles.append(self.remaining_tiles.pop())\n",
    "            self.player_tiles.append(player_tiles)\n",
    "            \n",
    "        #########################################\n",
    "        #TODO: TESTING STUFF TO BE REMOVED LATER#\n",
    "        #########################################\n",
    "        for i in range(self.num_players):\n",
    "            self.player_board[random.randint(0,5)][i+1] = i+1\n",
    "            \n",
    "        initial_obs = np.hstack((self.player_tiles[self.current_player - 1], self.player_board.flatten(), self.tile_board.flatten(), self.rotation_board.flatten()))\n",
    "\n",
    "        return initial_obs\n",
    "    \n",
    "    # Makes a move in the game based on inputs from player or AI\n",
    "    def step(self, action = -2, move = -1):\n",
    "        if move == -1:\n",
    "            card, rotate = self.get_card(action)\n",
    "        else:\n",
    "            card = move\n",
    "            rotate = 0\n",
    "        \n",
    "        action = self.player_tiles[self.current_player - 1][card]\n",
    "        \n",
    "        if action == -1:\n",
    "            observation = np.hstack((self.player_tiles[self.current_player - 1], self.player_board.flatten(), self.tile_board.flatten(), self.rotation_board.flatten()))\n",
    "            reward = -1\n",
    "            done = 0\n",
    "            return observation, reward, done, {}\n",
    "            \n",
    "        # Removes used tile and adds new tile from deck to hand\n",
    "        self.player_tiles[self.current_player-1].remove(action)\n",
    "        if len(self.remaining_tiles) > 0:\n",
    "            self.player_tiles[self.current_player-1].append(self.remaining_tiles.pop())\n",
    "        else:\n",
    "            self.player_tiles[self.current_player-1].append(-1)\n",
    "        \n",
    "        # Rotates tile (Only used by AI)\n",
    "        self.tiles[action].rotate_tile(rotate)\n",
    "        \n",
    "        reward = 0\n",
    "        self.place_tile(action+1)\n",
    "        self.move_players()\n",
    "        reward = self.reward_function()\n",
    "        if self.game_is_over():\n",
    "            done = 1\n",
    "        else:\n",
    "            done = 0\n",
    "        self.current_player = self.next_player()\n",
    "        observation = np.hstack((self.player_tiles[self.current_player - 1], self.player_board.flatten(), self.tile_board.flatten(), self.rotation_board.flatten()))\n",
    "        return observation, reward, done, {}\n",
    "    \n",
    "    # Decides if the game is over\n",
    "    def game_is_over(self):\n",
    "        if len(self.remaining_players) <= 1:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    # Decides the reward (Only used for AI)\n",
    "    def reward_function(self):\n",
    "        if not self.game_is_over():\n",
    "            return 1\n",
    "        if self.game_is_over() and self.current_player in self.remaining_players:\n",
    "            return 2\n",
    "        return -1\n",
    "    \n",
    "    # Places tile in self.tile_board\n",
    "    def place_tile(self, tile):\n",
    "        tile_number, node_number = np.where(self.player_board == self.current_player)\n",
    "        x, y = TsuroEnv.euclidean_division(self, tile_number)\n",
    "        x = x[0]\n",
    "        y = y[0]\n",
    "        self.tile_board[x][y] += tile\n",
    "        self.rotation_board[x][y] += self.tiles[tile-1].get_rotation()\n",
    "    \n",
    "    # Moves player piece in self.player_board\n",
    "    def move_players(self):\n",
    "        for player in self.remaining_players:\n",
    "            tile_number, node_number = np.where(self.player_board == player)\n",
    "            x, y = TsuroEnv.euclidean_division(self, tile_number)\n",
    "            x = x[0]\n",
    "            y = y[0]\n",
    "            while self.tile_board[x][y] != 0:\n",
    "                tile = self.tiles[(self.tile_board[x][y])-1]\n",
    "                next_node, next_player_tile, next_x, next_y = tile.move(node_number)\n",
    "                self.player_board[tile_number[0]][node_number[0]] = 0\n",
    "                if ((tile_number[0] % 6 == 0) and ((tile_number[0] + next_player_tile) % 6 == 5)) or (tile_number[0] + next_player_tile < 0) or (tile_number[0] + next_player_tile > 35) or ((tile_number[0] % 6 == 5) and ((tile_number[0] + next_player_tile) % 6 == 0)):\n",
    "                    self.remaining_players.remove(player)\n",
    "                    break\n",
    "                else:\n",
    "                    self.player_board[tile_number[0] + next_player_tile][next_node] = player\n",
    "                    x += next_x\n",
    "                    y += next_y\n",
    "                    tile_number, node_number = np.where(self.player_board == player)\n",
    "    \n",
    "    # Quotient and Remainder\n",
    "    def euclidean_division(self, x, y = 6):\n",
    "        return x % y, x // y\n",
    "    \n",
    "    # Action (card, rotation) from input\n",
    "    def get_card(self, x, y = 4):\n",
    "        return  x // y, x % y\n",
    "\n",
    "    # Decide whos turn it is\n",
    "    def next_player(self):\n",
    "        if len(self.remaining_players) == 0:\n",
    "            return -1\n",
    "        if self.current_player not in self.remaining_players:\n",
    "            for player in self.remaining_players:\n",
    "                if player > self.current_player:\n",
    "                    return player\n",
    "                else:\n",
    "                    return self.remaining_players[0]\n",
    "        return self.remaining_players[(self.remaining_players.index(self.current_player) + 1) % len(self.remaining_players)]\n",
    "    \n",
    "    def get_state(self):\n",
    "        observation = np.hstack((self.player_tiles[self.current_player - 1], self.player_board.flatten(), self.tile_board.flatten(), self.rotation_board.flatten()))\n",
    "        return observation\n",
    "        \n",
    "    # Render the environment\n",
    "    def render(self, mode):\n",
    "        screen = pygame.display.set_mode((650, 750))\n",
    "        screen.fill((255, 255, 255))\n",
    "\n",
    "        # Draw the game board\n",
    "        board = pygame.image.load(\"TsuroImages/board.png\")\n",
    "        board = pygame.transform.scale(board, (600, 600))\n",
    "        screen.blit(board, (25,25))\n",
    "        \n",
    "        # Draw current players hand\n",
    "        for i in range (len(self.player_tiles[self.current_player-1])):\n",
    "            tile = self.player_tiles[self.current_player-1][i]\n",
    "            screen.blit(self.tiles[tile].image, (75 + (i * 200), 635))\n",
    "        \n",
    "        # Draw the tiles on the board\n",
    "        for x in range(self.tile_board_size[0]):\n",
    "            for y in range(self.tile_board_size[1]):\n",
    "                val = self.tile_board[x][y]\n",
    "                if val != 0:\n",
    "                    tile = self.tiles[val-1]\n",
    "                    screen.blit(tile.image, (25 + x * 100, 25 + y * 100))\n",
    "                    \n",
    "        # Draw the players' pieces on the board\n",
    "        for i in self.remaining_players:\n",
    "            tile_number, node_number = np.where(self.player_board == i)\n",
    "            y_add = 0\n",
    "            x_add = 0\n",
    "            y_mult = 0\n",
    "            x_mult = 0\n",
    "            \n",
    "            match node_number[0]:\n",
    "                case 0:\n",
    "                    y_add = 35\n",
    "                case 1:\n",
    "                    x_add = 35\n",
    "                case 2:\n",
    "                    x_add = 70\n",
    "                case 3:\n",
    "                    x_add = 100\n",
    "                    y_add = 35\n",
    "                case 4:\n",
    "                    x_add = 100\n",
    "                    y_add = 70\n",
    "                case 5:\n",
    "                    x_add = 70\n",
    "                    y_add = 100\n",
    "                case 6:\n",
    "                    x_add = 35\n",
    "                    y_add = 100\n",
    "                case 7:\n",
    "                     y_add = 70\n",
    "                case _:\n",
    "                    raise Exception(\"Issue in drawing the player board\")\n",
    "                    \n",
    "            if tile_number[0] != 0:\n",
    "                x_mult, y_mult = TsuroEnv.euclidean_division(self, tile_number[0])\n",
    "            \n",
    "            pygame.draw.circle(screen, colors[i-1], (25 + x_add + (100 * x_mult), 25 + y_add + (100 * y_mult)), 5)\n",
    "            \n",
    "        # Draw text to show who won when game is over\n",
    "        if self.game_is_over() or self.current_player == -1:\n",
    "            font = pygame.font.Font('freesansbold.ttf', 32)\n",
    "            text = font.render('Player ' + str(self.current_player) + ' wins', True, '#00FF00')\n",
    "            textRect = text.get_rect()\n",
    "            textRect.center = (650 // 2, 750 // 2)\n",
    "            screen.blit(text, textRect)\n",
    "            \n",
    "        pygame.display.update()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8016cc12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x1830a2d9630>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_iterations = 2500000\n",
    "\n",
    "initial_collect_steps = 5000\n",
    "collect_steps_per_iteration = 1\n",
    "replay_buffer_max_length = 100000\n",
    "\n",
    "batch_size = 100\n",
    "learning_rate = 1e-3\n",
    "log_interval = 200\n",
    "\n",
    "num_eval_episodes = 20\n",
    "eval_interval = 5000\n",
    "\n",
    "register(\n",
    "    id='TsuroEnv',\n",
    "    entry_point=TsuroEnv,\n",
    ")\n",
    "\n",
    "env_name = \"TsuroEnv\"\n",
    "\n",
    "train_py_env = suite_gym.load(env_name)\n",
    "eval_py_env = suite_gym.load(env_name)\n",
    "\n",
    "train_env = tf_py_environment.TFPyEnvironment(train_py_env)\n",
    "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)\n",
    "\n",
    "fc_layer_params = (200, 100)\n",
    "action_tensor_spec = tensor_spec.from_spec(train_env.action_spec())\n",
    "num_actions = action_tensor_spec.maximum - action_tensor_spec.minimum + 1\n",
    "\n",
    "def dense_layer(num_units):\n",
    "    return tf.keras.layers.Dense(num_units, activation=tf.keras.activations.relu, kernel_initializer=tf.keras.initializers.VarianceScaling(scale=2.0, mode='fan_in', distribution='truncated_normal'))\n",
    "\n",
    "dense_layers = [dense_layer(num_units) for num_units in fc_layer_params]\n",
    "q_values_layer = tf.keras.layers.Dense(num_actions, activation=None, kernel_initializer=tf.keras.initializers.RandomUniform(minval=-0.03, maxval=0.03), bias_initializer=tf.keras.initializers.Constant(-0.2))\n",
    "q_net = sequential.Sequential(dense_layers + [q_values_layer])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "train_step_counter = tf.Variable(0)\n",
    "\n",
    "agent = dqn_agent.DqnAgent(\n",
    "    train_env.time_step_spec(),\n",
    "    train_env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer,\n",
    "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "    train_step_counter=train_step_counter)\n",
    "\n",
    "agent.initialize()\n",
    "\n",
    "eval_policy = agent.policy\n",
    "collect_policy = agent.collect_policy\n",
    "\n",
    "random_policy = random_tf_policy.RandomTFPolicy(train_env.time_step_spec(),\n",
    "                                                train_env.action_spec())\n",
    "\n",
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    data_spec=agent.collect_data_spec,\n",
    "    batch_size=train_env.batch_size,\n",
    "    max_length=replay_buffer_max_length)\n",
    "    \n",
    "def compute_avg_return(environment, policy, num_episodes=10):\n",
    "\n",
    "    total_return = 0.0\n",
    "    for _ in range(num_episodes):\n",
    "\n",
    "        time_step = environment.reset()\n",
    "        episode_return = 0.0\n",
    "\n",
    "        while not time_step.is_last():\n",
    "            action_step = policy.action(time_step)\n",
    "            time_step = environment.step(action_step.action)\n",
    "            episode_return += time_step.reward\n",
    "        total_return += episode_return\n",
    "\n",
    "    avg_return = total_return / num_episodes\n",
    "    return avg_return.numpy()[0]\n",
    "\n",
    "def collect_step(environment, policy, buffer):\n",
    "    time_step = environment.current_time_step()\n",
    "    action_step = policy.action(time_step)\n",
    "    next_time_step = environment.step(action_step)\n",
    "    # commenting out render will make training quicker\n",
    "    # environment.render(\"human\")\n",
    "    traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
    "    buffer.add_batch(traj)\n",
    "\n",
    "def collect_data(env, policy, buffer, steps):\n",
    "    for _ in range(steps):\n",
    "        collect_step(env, policy, buffer)\n",
    "        \n",
    "train_checkpointer = common.Checkpointer(\n",
    "    ckpt_dir=\"Checkpoints1/\",\n",
    "    max_to_keep=1,\n",
    "    agent=agent,\n",
    "    policy=agent.policy,\n",
    "    replay_buffer=replay_buffer,\n",
    "    global_step=train_step_counter\n",
    ")\n",
    "\n",
    "train_checkpointer.initialize_or_restore()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7c00fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HorridJoe\\opencv\\lib\\site-packages\\tf_agents\\replay_buffers\\tf_uniform_replay_buffer.py:342: CounterV2 (from tensorflow.python.data.experimental.ops.counter) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.counter(...)` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HorridJoe\\opencv\\lib\\site-packages\\tf_agents\\replay_buffers\\tf_uniform_replay_buffer.py:342: CounterV2 (from tensorflow.python.data.experimental.ops.counter) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.counter(...)` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HorridJoe\\opencv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HorridJoe\\opencv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HorridJoe\\opencv\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HorridJoe\\opencv\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=3, \n",
    "    sample_batch_size=batch_size, \n",
    "    num_steps=2).prefetch(3)\n",
    "\n",
    "iterator = iter(dataset)\n",
    "\n",
    "agent.train = common.function(agent.train)\n",
    "\n",
    "returns = []\n",
    "\n",
    "with open(\"Checkpoints1/returns.txt\", \"r\") as txt:\n",
    "    for line in txt:\n",
    "        returns.append(line)\n",
    "        \n",
    "for i in range(len(returns)):\n",
    "    returns[i] = returns[i].strip()\n",
    "    returns[i] = float(returns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df51de87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncollect_data(train_env, random_policy, replay_buffer, initial_collect_steps)\\nagent.train_step_counter.assign(0)\\n\\navg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\\nreturns = [avg_return]\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial Collection for new agent\n",
    "'''\n",
    "collect_data(train_env, random_policy, replay_buffer, initial_collect_steps)\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "returns = [avg_return]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce32f9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HorridJoe\\opencv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.foldr(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HorridJoe\\opencv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.foldr(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 4910200: loss = 4.242068767547607\n",
      "step = 4910400: loss = 3.6957173347473145\n",
      "step = 4910600: loss = 3.7417309284210205\n",
      "step = 4910800: loss = 3.8654563426971436\n",
      "step = 4911000: loss = 3.522522449493408\n",
      "step = 4911200: loss = 3.467543363571167\n",
      "step = 4911400: loss = 4.57596492767334\n",
      "step = 4911600: loss = 4.736881732940674\n",
      "step = 4911800: loss = 3.9961531162261963\n",
      "step = 4912000: loss = 3.5100462436676025\n",
      "step = 4912200: loss = 4.569034099578857\n",
      "step = 4912400: loss = 3.286997079849243\n",
      "step = 4912600: loss = 4.12788200378418\n",
      "step = 4912800: loss = 4.19862699508667\n",
      "step = 4913000: loss = 4.36104679107666\n",
      "step = 4913200: loss = 3.366215705871582\n",
      "step = 4913400: loss = 4.484061241149902\n",
      "step = 4913600: loss = 4.552647113800049\n",
      "step = 4913800: loss = 4.136657238006592\n",
      "step = 4914000: loss = 3.7621123790740967\n",
      "step = 4914200: loss = 4.79841947555542\n",
      "step = 4914400: loss = 4.7251996994018555\n",
      "step = 4914600: loss = 3.1707098484039307\n",
      "step = 4914800: loss = 3.3531203269958496\n",
      "step = 4915000: loss = 5.266035079956055\n",
      "step = 4915000: Average Return = 2.1500000953674316\n",
      "step = 4915200: loss = 3.5015618801116943\n",
      "step = 4915400: loss = 4.543298721313477\n",
      "step = 4915600: loss = 3.4840269088745117\n",
      "step = 4915800: loss = 3.108872652053833\n",
      "step = 4916000: loss = 3.880544424057007\n",
      "step = 4916200: loss = 2.6584486961364746\n",
      "step = 4916400: loss = 4.628573894500732\n",
      "step = 4916600: loss = 4.8486785888671875\n",
      "step = 4916800: loss = 3.457953929901123\n",
      "step = 4917000: loss = 3.185154438018799\n",
      "step = 4917200: loss = 3.919224739074707\n",
      "step = 4917400: loss = 4.368724346160889\n",
      "step = 4917600: loss = 3.6126742362976074\n",
      "step = 4917800: loss = 4.256731986999512\n",
      "step = 4918000: loss = 4.611557960510254\n",
      "step = 4918200: loss = 3.132995128631592\n",
      "step = 4918400: loss = 4.6583943367004395\n",
      "step = 4918600: loss = 4.308337211608887\n",
      "step = 4918800: loss = 3.3885459899902344\n",
      "step = 4919000: loss = 3.273573875427246\n",
      "step = 4919200: loss = 3.491431474685669\n",
      "step = 4919400: loss = 4.34727668762207\n",
      "step = 4919600: loss = 4.010097503662109\n",
      "step = 4919800: loss = 4.076571941375732\n",
      "step = 4920000: loss = 4.799408912658691\n",
      "step = 4920000: Average Return = 4.0\n",
      "step = 4920200: loss = 3.2957475185394287\n",
      "step = 4920400: loss = 2.7363879680633545\n",
      "step = 4920600: loss = 4.588206768035889\n",
      "step = 4920800: loss = 4.043476104736328\n",
      "step = 4921000: loss = 4.384084224700928\n",
      "step = 4921200: loss = 2.8479690551757812\n",
      "step = 4921400: loss = 3.9065732955932617\n",
      "step = 4921600: loss = 4.611484050750732\n",
      "step = 4921800: loss = 3.776353120803833\n",
      "step = 4922000: loss = 4.689263343811035\n",
      "step = 4922200: loss = 3.4823906421661377\n",
      "step = 4922400: loss = 3.4030601978302\n",
      "step = 4922600: loss = 3.6907787322998047\n",
      "step = 4922800: loss = 5.535315990447998\n",
      "step = 4923000: loss = 4.087618827819824\n",
      "step = 4923200: loss = 3.429840087890625\n",
      "step = 4923400: loss = 3.0835466384887695\n",
      "step = 4923600: loss = 4.525887966156006\n",
      "step = 4923800: loss = 3.613420009613037\n",
      "step = 4924000: loss = 2.841487407684326\n",
      "step = 4924200: loss = 3.529055118560791\n",
      "step = 4924400: loss = 4.236056327819824\n",
      "step = 4924600: loss = 3.0780467987060547\n",
      "step = 4924800: loss = 3.21048903465271\n",
      "step = 4925000: loss = 3.672542095184326\n",
      "step = 4925000: Average Return = 1.600000023841858\n",
      "step = 4925200: loss = 4.1170501708984375\n",
      "step = 4925400: loss = 3.291142225265503\n",
      "step = 4925600: loss = 4.00057315826416\n",
      "step = 4925800: loss = 4.869316101074219\n",
      "step = 4926000: loss = 3.7506606578826904\n",
      "step = 4926200: loss = 4.255399703979492\n",
      "step = 4926400: loss = 3.623689889907837\n",
      "step = 4926600: loss = 3.124709129333496\n",
      "step = 4926800: loss = 4.289714336395264\n",
      "step = 4927000: loss = 4.31414270401001\n",
      "step = 4927200: loss = 3.8024590015411377\n",
      "step = 4927400: loss = 3.982072114944458\n",
      "step = 4927600: loss = 5.16030740737915\n",
      "step = 4927800: loss = 2.653824806213379\n",
      "step = 4928000: loss = 2.875427484512329\n",
      "step = 4928200: loss = 3.363400459289551\n",
      "step = 4928400: loss = 4.042980670928955\n",
      "step = 4928600: loss = 5.678378582000732\n",
      "step = 4928800: loss = 3.8393352031707764\n",
      "step = 4929000: loss = 3.166370153427124\n",
      "step = 4929200: loss = 4.442773818969727\n",
      "step = 4929400: loss = 3.8480944633483887\n",
      "step = 4929600: loss = 3.7110819816589355\n",
      "step = 4929800: loss = 3.3258237838745117\n",
      "step = 4930000: loss = 3.492541790008545\n",
      "step = 4930000: Average Return = 2.200000047683716\n",
      "step = 4930200: loss = 3.542715072631836\n",
      "step = 4930400: loss = 4.1201701164245605\n",
      "step = 4930600: loss = 4.296724796295166\n",
      "step = 4930800: loss = 3.7961156368255615\n",
      "step = 4931000: loss = 3.614640235900879\n",
      "step = 4931200: loss = 3.534337043762207\n",
      "step = 4931400: loss = 4.147705554962158\n",
      "step = 4931600: loss = 4.280961513519287\n",
      "step = 4931800: loss = 4.376087665557861\n",
      "step = 4932000: loss = 4.269262790679932\n",
      "step = 4932200: loss = 3.135650873184204\n",
      "step = 4932400: loss = 2.4036293029785156\n",
      "step = 4932600: loss = 3.094125986099243\n",
      "step = 4932800: loss = 3.216505289077759\n",
      "step = 4933000: loss = 3.774529218673706\n",
      "step = 4933200: loss = 3.8739798069000244\n",
      "step = 4933400: loss = 3.8530187606811523\n",
      "step = 4933600: loss = 3.935811996459961\n",
      "step = 4933800: loss = 4.7907562255859375\n",
      "step = 4934000: loss = 4.676039218902588\n",
      "step = 4934200: loss = 2.7165822982788086\n",
      "step = 4934400: loss = 4.352983474731445\n",
      "step = 4934600: loss = 3.989795446395874\n",
      "step = 4934800: loss = 5.597347259521484\n",
      "step = 4935000: loss = 3.205352306365967\n",
      "step = 4935000: Average Return = 4.050000190734863\n",
      "step = 4935200: loss = 5.42763090133667\n",
      "step = 4935400: loss = 4.751826286315918\n",
      "step = 4935600: loss = 3.5560903549194336\n",
      "step = 4935800: loss = 4.29879903793335\n",
      "step = 4936000: loss = 3.125175714492798\n",
      "step = 4936200: loss = 4.127957820892334\n",
      "step = 4936400: loss = 3.599138021469116\n",
      "step = 4936600: loss = 3.3267276287078857\n",
      "step = 4936800: loss = 4.314438819885254\n",
      "step = 4937000: loss = 3.8700530529022217\n",
      "step = 4937200: loss = 4.099582195281982\n",
      "step = 4937400: loss = 4.827986240386963\n",
      "step = 4937600: loss = 3.9771478176116943\n",
      "step = 4937800: loss = 3.566373825073242\n",
      "step = 4938000: loss = 4.062134265899658\n",
      "step = 4938200: loss = 4.61177921295166\n",
      "step = 4938400: loss = 3.6212642192840576\n",
      "step = 4938600: loss = 3.065208673477173\n",
      "step = 4938800: loss = 4.771744728088379\n",
      "step = 4939000: loss = 4.6895270347595215\n",
      "step = 4939200: loss = 3.185192584991455\n",
      "step = 4939400: loss = 3.379061222076416\n",
      "step = 4939600: loss = 3.786058187484741\n",
      "step = 4939800: loss = 3.751643180847168\n",
      "step = 4940000: loss = 3.642080307006836\n",
      "step = 4940000: Average Return = 3.0999999046325684\n",
      "step = 4940200: loss = 3.7123565673828125\n",
      "step = 4940400: loss = 3.844761371612549\n",
      "step = 4940600: loss = 3.2264976501464844\n",
      "step = 4940800: loss = 3.865626811981201\n",
      "step = 4941000: loss = 4.387393951416016\n",
      "step = 4941200: loss = 3.0855941772460938\n",
      "step = 4941400: loss = 4.433868408203125\n",
      "step = 4941600: loss = 2.7413504123687744\n",
      "step = 4941800: loss = 2.972703695297241\n",
      "step = 4942000: loss = 5.166304111480713\n",
      "step = 4942200: loss = 4.46042537689209\n",
      "step = 4942400: loss = 3.204904317855835\n",
      "step = 4942600: loss = 3.7576141357421875\n",
      "step = 4942800: loss = 4.094831943511963\n",
      "step = 4943000: loss = 4.874111652374268\n",
      "step = 4943200: loss = 3.9429092407226562\n",
      "step = 4943400: loss = 4.937001705169678\n",
      "step = 4943600: loss = 4.510542392730713\n",
      "step = 4943800: loss = 3.7137653827667236\n",
      "step = 4944000: loss = 4.577171802520752\n",
      "step = 4944200: loss = 3.9828624725341797\n",
      "step = 4944400: loss = 4.723997592926025\n",
      "step = 4944600: loss = 4.833130836486816\n",
      "step = 4944800: loss = 3.785223960876465\n",
      "step = 4945000: loss = 3.4563512802124023\n",
      "step = 4945000: Average Return = 5.099999904632568\n",
      "step = 4945200: loss = 4.273630142211914\n",
      "step = 4945400: loss = 4.889258861541748\n",
      "step = 4945600: loss = 3.462462902069092\n",
      "step = 4945800: loss = 4.15210485458374\n",
      "step = 4946000: loss = 3.9062743186950684\n",
      "step = 4946200: loss = 4.261728286743164\n",
      "step = 4946400: loss = 5.068927764892578\n",
      "step = 4946600: loss = 3.072404623031616\n",
      "step = 4946800: loss = 3.9217300415039062\n",
      "step = 4947000: loss = 4.979698181152344\n",
      "step = 4947200: loss = 4.557436466217041\n",
      "step = 4947400: loss = 5.1488938331604\n",
      "step = 4947600: loss = 4.274094104766846\n",
      "step = 4947800: loss = 3.918687105178833\n",
      "step = 4948000: loss = 2.9918739795684814\n",
      "step = 4948200: loss = 3.5660970211029053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 4948400: loss = 3.099590301513672\n",
      "step = 4948600: loss = 3.913886070251465\n",
      "step = 4948800: loss = 4.322664260864258\n",
      "step = 4949000: loss = 4.226951599121094\n",
      "step = 4949200: loss = 4.665009498596191\n",
      "step = 4949400: loss = 4.375265598297119\n",
      "step = 4949600: loss = 3.373652458190918\n",
      "step = 4949800: loss = 4.382088661193848\n",
      "step = 4950000: loss = 3.111623764038086\n",
      "step = 4950000: Average Return = 2.25\n",
      "step = 4950200: loss = 2.81516170501709\n",
      "step = 4950400: loss = 2.462397336959839\n",
      "step = 4950600: loss = 5.184128284454346\n",
      "step = 4950800: loss = 3.0734071731567383\n",
      "step = 4951000: loss = 4.610994815826416\n",
      "step = 4951200: loss = 4.7414021492004395\n",
      "step = 4951400: loss = 3.3588039875030518\n",
      "step = 4951600: loss = 5.238795280456543\n",
      "step = 4951800: loss = 3.855922222137451\n",
      "step = 4952000: loss = 3.487271547317505\n",
      "step = 4952200: loss = 4.44066047668457\n",
      "step = 4952400: loss = 4.326478004455566\n",
      "step = 4952600: loss = 3.5620105266571045\n",
      "step = 4952800: loss = 2.7313895225524902\n",
      "step = 4953000: loss = 3.2825615406036377\n",
      "step = 4953200: loss = 3.613368511199951\n",
      "step = 4953400: loss = 4.538863658905029\n",
      "step = 4953600: loss = 2.7311620712280273\n",
      "step = 4953800: loss = 2.9980013370513916\n",
      "step = 4954000: loss = 4.3561506271362305\n",
      "step = 4954200: loss = 3.6644506454467773\n",
      "step = 4954400: loss = 3.6771984100341797\n",
      "step = 4954600: loss = 2.9741899967193604\n",
      "step = 4954800: loss = 5.11165714263916\n",
      "step = 4955000: loss = 3.8776042461395264\n",
      "step = 4955000: Average Return = 2.950000047683716\n",
      "step = 4955200: loss = 3.5816707611083984\n",
      "step = 4955400: loss = 3.3590269088745117\n",
      "step = 4955600: loss = 4.79039192199707\n",
      "step = 4955800: loss = 4.406585693359375\n",
      "step = 4956000: loss = 3.944385051727295\n",
      "step = 4956200: loss = 3.9695324897766113\n",
      "step = 4956400: loss = 4.699368000030518\n",
      "step = 4956600: loss = 5.112431049346924\n",
      "step = 4956800: loss = 3.4213619232177734\n",
      "step = 4957000: loss = 4.209134578704834\n",
      "step = 4957200: loss = 3.70625901222229\n",
      "step = 4957400: loss = 3.6207737922668457\n",
      "step = 4957600: loss = 4.613946437835693\n",
      "step = 4957800: loss = 4.003304481506348\n",
      "step = 4958000: loss = 3.440477132797241\n",
      "step = 4958200: loss = 4.087714195251465\n",
      "step = 4958400: loss = 4.964702129364014\n",
      "step = 4958600: loss = 3.109027147293091\n",
      "step = 4958800: loss = 4.032886028289795\n",
      "step = 4959000: loss = 2.7526402473449707\n",
      "step = 4959200: loss = 4.725274562835693\n",
      "step = 4959400: loss = 3.6699392795562744\n",
      "step = 4959600: loss = 3.8222038745880127\n",
      "step = 4959800: loss = 3.9011199474334717\n",
      "step = 4960000: loss = 2.3617706298828125\n",
      "step = 4960000: Average Return = 3.25\n",
      "step = 4960200: loss = 3.6408424377441406\n",
      "step = 4960400: loss = 3.652153253555298\n",
      "step = 4960600: loss = 5.235286712646484\n",
      "step = 4960800: loss = 2.551342010498047\n",
      "step = 4961000: loss = 3.6265084743499756\n",
      "step = 4961200: loss = 3.906885862350464\n",
      "step = 4961400: loss = 6.185517311096191\n",
      "step = 4961600: loss = 3.718355894088745\n",
      "step = 4961800: loss = 3.447158098220825\n",
      "step = 4962000: loss = 3.440385580062866\n",
      "step = 4962200: loss = 3.744553327560425\n",
      "step = 4962400: loss = 3.702263116836548\n",
      "step = 4962600: loss = 3.417290210723877\n",
      "step = 4962800: loss = 4.038033962249756\n",
      "step = 4963000: loss = 4.467073440551758\n",
      "step = 4963200: loss = 3.196904420852661\n",
      "step = 4963400: loss = 4.395090103149414\n",
      "step = 4963600: loss = 4.620175838470459\n",
      "step = 4963800: loss = 4.171197891235352\n",
      "step = 4964000: loss = 4.799423694610596\n",
      "step = 4964200: loss = 3.1200411319732666\n",
      "step = 4964400: loss = 3.3503801822662354\n",
      "step = 4964600: loss = 3.3238275051116943\n",
      "step = 4964800: loss = 5.013261795043945\n",
      "step = 4965000: loss = 4.086583137512207\n",
      "step = 4965000: Average Return = 3.75\n",
      "step = 4965200: loss = 2.851562976837158\n",
      "step = 4965400: loss = 4.544538497924805\n",
      "step = 4965600: loss = 3.4978911876678467\n",
      "step = 4965800: loss = 4.465389728546143\n",
      "step = 4966000: loss = 4.169309616088867\n",
      "step = 4966200: loss = 4.789035797119141\n",
      "step = 4966400: loss = 4.2897844314575195\n",
      "step = 4966600: loss = 3.9766223430633545\n",
      "step = 4966800: loss = 3.376596689224243\n",
      "step = 4967000: loss = 4.041903972625732\n",
      "step = 4967200: loss = 3.5632143020629883\n",
      "step = 4967400: loss = 3.308997631072998\n",
      "step = 4967600: loss = 3.609034299850464\n",
      "step = 4967800: loss = 4.107491970062256\n",
      "step = 4968000: loss = 4.223745346069336\n",
      "step = 4968200: loss = 4.563266277313232\n",
      "step = 4968400: loss = 2.563035726547241\n",
      "step = 4968600: loss = 4.294492721557617\n",
      "step = 4968800: loss = 3.2208433151245117\n",
      "step = 4969000: loss = 4.4385175704956055\n",
      "step = 4969200: loss = 3.5161678791046143\n",
      "step = 4969400: loss = 3.339686393737793\n",
      "step = 4969600: loss = 4.620131015777588\n",
      "step = 4969800: loss = 3.881169319152832\n",
      "step = 4970000: loss = 3.956987142562866\n",
      "step = 4970000: Average Return = 3.200000047683716\n",
      "step = 4970200: loss = 4.280069351196289\n",
      "step = 4970400: loss = 4.269064903259277\n",
      "step = 4970600: loss = 4.313632488250732\n",
      "step = 4970800: loss = 3.663935422897339\n",
      "step = 4971000: loss = 2.344978094100952\n",
      "step = 4971200: loss = 4.8868608474731445\n",
      "step = 4971400: loss = 3.8449957370758057\n",
      "step = 4971600: loss = 3.9309990406036377\n",
      "step = 4971800: loss = 4.327235221862793\n",
      "step = 4972000: loss = 4.126628398895264\n",
      "step = 4972200: loss = 4.35333251953125\n",
      "step = 4972400: loss = 5.866004943847656\n",
      "step = 4972600: loss = 4.820301532745361\n",
      "step = 4972800: loss = 3.087683916091919\n",
      "step = 4973000: loss = 3.578402280807495\n",
      "step = 4973200: loss = 5.0793256759643555\n",
      "step = 4973400: loss = 3.5042662620544434\n",
      "step = 4973600: loss = 4.235743522644043\n",
      "step = 4973800: loss = 2.628509044647217\n",
      "step = 4974000: loss = 4.176784515380859\n",
      "step = 4974200: loss = 4.346879005432129\n",
      "step = 4974400: loss = 4.202582359313965\n",
      "step = 4974600: loss = 3.930229425430298\n",
      "step = 4974800: loss = 3.464445114135742\n",
      "step = 4975000: loss = 4.477229595184326\n",
      "step = 4975000: Average Return = 3.75\n",
      "step = 4975200: loss = 3.2259411811828613\n",
      "step = 4975400: loss = 3.4458744525909424\n",
      "step = 4975600: loss = 4.288153648376465\n",
      "step = 4975800: loss = 4.889744281768799\n",
      "step = 4976000: loss = 4.511908054351807\n",
      "step = 4976200: loss = 4.028099060058594\n",
      "step = 4976400: loss = 4.9784393310546875\n",
      "step = 4976600: loss = 3.720587730407715\n",
      "step = 4976800: loss = 3.9650421142578125\n",
      "step = 4977000: loss = 4.79335355758667\n",
      "step = 4977200: loss = 3.3882274627685547\n",
      "step = 4977400: loss = 3.5569064617156982\n",
      "step = 4977600: loss = 4.42645263671875\n",
      "step = 4977800: loss = 4.571249961853027\n",
      "step = 4978000: loss = 3.4938817024230957\n",
      "step = 4978200: loss = 3.9558072090148926\n",
      "step = 4978400: loss = 5.48212194442749\n",
      "step = 4978600: loss = 3.920858383178711\n",
      "step = 4978800: loss = 2.8519444465637207\n",
      "step = 4979000: loss = 3.989161491394043\n",
      "step = 4979200: loss = 3.3448805809020996\n",
      "step = 4979400: loss = 4.845752239227295\n",
      "step = 4979600: loss = 3.3355486392974854\n",
      "step = 4979800: loss = 5.599243640899658\n",
      "step = 4980000: loss = 3.669710636138916\n",
      "step = 4980000: Average Return = 3.950000047683716\n",
      "step = 4980200: loss = 4.924060821533203\n",
      "step = 4980400: loss = 2.849943161010742\n",
      "step = 4980600: loss = 2.7737877368927\n",
      "step = 4980800: loss = 2.6928324699401855\n",
      "step = 4981000: loss = 3.2099549770355225\n",
      "step = 4981200: loss = 4.822000980377197\n",
      "step = 4981400: loss = 4.857940673828125\n",
      "step = 4981600: loss = 4.924981117248535\n",
      "step = 4981800: loss = 4.348269462585449\n",
      "step = 4982000: loss = 3.542039632797241\n",
      "step = 4982200: loss = 4.081508159637451\n",
      "step = 4982400: loss = 3.687633514404297\n",
      "step = 4982600: loss = 5.405824661254883\n",
      "step = 4982800: loss = 2.956205129623413\n",
      "step = 4983000: loss = 4.910228729248047\n",
      "step = 4983200: loss = 4.555910587310791\n",
      "step = 4983400: loss = 3.6548619270324707\n",
      "step = 4983600: loss = 3.2250256538391113\n",
      "step = 4983800: loss = 4.90317440032959\n",
      "step = 4984000: loss = 2.7510757446289062\n",
      "step = 4984200: loss = 4.045654296875\n",
      "step = 4984400: loss = 3.2903225421905518\n",
      "step = 4984600: loss = 3.9259026050567627\n",
      "step = 4984800: loss = 3.5492701530456543\n",
      "step = 4985000: loss = 3.286191940307617\n",
      "step = 4985000: Average Return = 4.599999904632568\n",
      "step = 4985200: loss = 4.939748287200928\n",
      "step = 4985400: loss = 3.8918142318725586\n",
      "step = 4985600: loss = 4.540191173553467\n",
      "step = 4985800: loss = 4.568796157836914\n",
      "step = 4986000: loss = 4.034112930297852\n",
      "step = 4986200: loss = 4.061464786529541\n",
      "step = 4986400: loss = 3.705465316772461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 4986600: loss = 3.9881768226623535\n",
      "step = 4986800: loss = 3.301422595977783\n",
      "step = 4987000: loss = 3.7611634731292725\n",
      "step = 4987200: loss = 3.4207894802093506\n",
      "step = 4987400: loss = 4.18076229095459\n",
      "step = 4987600: loss = 3.899148464202881\n",
      "step = 4987800: loss = 4.796546936035156\n",
      "step = 4988000: loss = 3.312188148498535\n",
      "step = 4988200: loss = 3.652630567550659\n",
      "step = 4988400: loss = 4.0162353515625\n",
      "step = 4988600: loss = 4.4349589347839355\n",
      "step = 4988800: loss = 4.213515758514404\n",
      "step = 4989000: loss = 4.571341514587402\n",
      "step = 4989200: loss = 3.1246681213378906\n",
      "step = 4989400: loss = 3.8849334716796875\n",
      "step = 4989600: loss = 2.753955125808716\n",
      "step = 4989800: loss = 4.366640090942383\n",
      "step = 4990000: loss = 3.5524849891662598\n",
      "step = 4990000: Average Return = 3.4000000953674316\n",
      "step = 4990200: loss = 4.844635963439941\n",
      "step = 4990400: loss = 4.674066543579102\n",
      "step = 4990600: loss = 3.750828266143799\n",
      "step = 4990800: loss = 3.9779491424560547\n",
      "step = 4991000: loss = 3.7350542545318604\n",
      "step = 4991200: loss = 2.981783390045166\n",
      "step = 4991400: loss = 3.5602734088897705\n",
      "step = 4991600: loss = 4.443091869354248\n",
      "step = 4991800: loss = 3.754589080810547\n",
      "step = 4992000: loss = 3.5881850719451904\n",
      "step = 4992200: loss = 3.190927028656006\n",
      "step = 4992400: loss = 5.429963111877441\n",
      "step = 4992600: loss = 3.9961471557617188\n",
      "step = 4992800: loss = 4.231139659881592\n",
      "step = 4993000: loss = 3.488884210586548\n",
      "step = 4993200: loss = 5.670874118804932\n",
      "step = 4993400: loss = 4.581106662750244\n",
      "step = 4993600: loss = 4.044883728027344\n",
      "step = 4993800: loss = 4.379261016845703\n",
      "step = 4994000: loss = 4.755734920501709\n",
      "step = 4994200: loss = 3.8961992263793945\n",
      "step = 4994400: loss = 3.3745341300964355\n",
      "step = 4994600: loss = 3.8374040126800537\n",
      "step = 4994800: loss = 4.31804084777832\n",
      "step = 4995000: loss = 3.0350847244262695\n",
      "step = 4995000: Average Return = 2.549999952316284\n",
      "step = 4995200: loss = 3.6117818355560303\n",
      "step = 4995400: loss = 4.094664096832275\n",
      "step = 4995600: loss = 4.075004577636719\n",
      "step = 4995800: loss = 3.9532744884490967\n",
      "step = 4996000: loss = 4.573014736175537\n",
      "step = 4996200: loss = 3.4640209674835205\n",
      "step = 4996400: loss = 5.189981460571289\n",
      "step = 4996600: loss = 3.648644208908081\n",
      "step = 4996800: loss = 3.8056492805480957\n",
      "step = 4997000: loss = 3.0305073261260986\n",
      "step = 4997200: loss = 4.267786026000977\n",
      "step = 4997400: loss = 3.785985231399536\n",
      "step = 4997600: loss = 5.662352561950684\n",
      "step = 4997800: loss = 3.4570839405059814\n",
      "step = 4998000: loss = 4.949084758758545\n",
      "step = 4998200: loss = 4.632960319519043\n",
      "step = 4998400: loss = 4.415327072143555\n",
      "step = 4998600: loss = 4.631678581237793\n",
      "step = 4998800: loss = 4.1003031730651855\n",
      "step = 4999000: loss = 3.5843708515167236\n",
      "step = 4999200: loss = 4.626748085021973\n",
      "step = 4999400: loss = 3.054759979248047\n",
      "step = 4999600: loss = 4.0599894523620605\n",
      "step = 4999800: loss = 4.123973369598389\n",
      "step = 5000000: loss = 3.4168314933776855\n",
      "step = 5000000: Average Return = 2.9000000953674316\n",
      "step = 5000200: loss = 4.345486640930176\n",
      "step = 5000400: loss = 3.7291057109832764\n",
      "step = 5000600: loss = 2.8148574829101562\n",
      "step = 5000800: loss = 4.672323226928711\n",
      "step = 5001000: loss = 3.4718518257141113\n",
      "step = 5001200: loss = 3.4779887199401855\n",
      "step = 5001400: loss = 4.0057268142700195\n",
      "step = 5001600: loss = 4.602607727050781\n",
      "step = 5001800: loss = 4.101644992828369\n",
      "step = 5002000: loss = 6.077363014221191\n",
      "step = 5002200: loss = 3.5078201293945312\n",
      "step = 5002400: loss = 4.684609413146973\n",
      "step = 5002600: loss = 5.06074857711792\n",
      "step = 5002800: loss = 4.947073936462402\n",
      "step = 5003000: loss = 4.643199443817139\n",
      "step = 5003200: loss = 4.864136695861816\n",
      "step = 5003400: loss = 4.460379123687744\n",
      "step = 5003600: loss = 5.5359978675842285\n",
      "step = 5003800: loss = 3.073293447494507\n",
      "step = 5004000: loss = 4.716795444488525\n",
      "step = 5004200: loss = 4.435643672943115\n",
      "step = 5004400: loss = 3.982532262802124\n",
      "step = 5004600: loss = 4.271177768707275\n",
      "step = 5004800: loss = 5.666179656982422\n",
      "step = 5005000: loss = 4.928574085235596\n",
      "step = 5005000: Average Return = 3.049999952316284\n",
      "step = 5005200: loss = 3.8836095333099365\n",
      "step = 5005400: loss = 3.9901766777038574\n",
      "step = 5005600: loss = 4.100334167480469\n",
      "step = 5005800: loss = 4.808527946472168\n",
      "step = 5006000: loss = 3.286492347717285\n",
      "step = 5006200: loss = 4.866548538208008\n",
      "step = 5006400: loss = 3.861581325531006\n",
      "step = 5006600: loss = 4.434751510620117\n",
      "step = 5006800: loss = 3.945168972015381\n",
      "step = 5007000: loss = 4.1691765785217285\n",
      "step = 5007200: loss = 3.7327184677124023\n",
      "step = 5007400: loss = 2.8291149139404297\n",
      "step = 5007600: loss = 3.319841146469116\n",
      "step = 5007800: loss = 2.642875909805298\n",
      "step = 5008000: loss = 4.509898662567139\n",
      "step = 5008200: loss = 4.336029052734375\n",
      "step = 5008400: loss = 3.6044118404388428\n",
      "step = 5008600: loss = 2.534324884414673\n",
      "step = 5008800: loss = 3.8671467304229736\n",
      "step = 5009000: loss = 4.029365062713623\n",
      "step = 5009200: loss = 4.1346516609191895\n",
      "step = 5009400: loss = 2.6617681980133057\n",
      "step = 5009600: loss = 4.122492790222168\n",
      "step = 5009800: loss = 5.06198787689209\n",
      "step = 5010000: loss = 4.612494468688965\n",
      "step = 5010000: Average Return = 3.049999952316284\n",
      "step = 5010200: loss = 4.812112331390381\n",
      "step = 5010400: loss = 4.586329936981201\n",
      "step = 5010600: loss = 4.317171096801758\n",
      "step = 5010800: loss = 3.385267496109009\n",
      "step = 5011000: loss = 4.201388835906982\n",
      "step = 5011200: loss = 3.946481466293335\n",
      "step = 5011400: loss = 4.000202655792236\n",
      "step = 5011600: loss = 4.305636405944824\n",
      "step = 5011800: loss = 5.3382248878479\n",
      "step = 5012000: loss = 3.3414909839630127\n",
      "step = 5012200: loss = 3.5998995304107666\n",
      "step = 5012400: loss = 3.155395984649658\n",
      "step = 5012600: loss = 3.816774845123291\n",
      "step = 5012800: loss = 4.981804847717285\n",
      "step = 5013000: loss = 4.866820335388184\n",
      "step = 5013200: loss = 3.9983065128326416\n",
      "step = 5013400: loss = 3.394073486328125\n",
      "step = 5013600: loss = 3.5969014167785645\n",
      "step = 5013800: loss = 4.5770487785339355\n",
      "step = 5014000: loss = 4.514942169189453\n",
      "step = 5014200: loss = 5.915902137756348\n",
      "step = 5014400: loss = 3.6288371086120605\n",
      "step = 5014600: loss = 4.656274318695068\n",
      "step = 5014800: loss = 4.162291049957275\n",
      "step = 5015000: loss = 3.9459316730499268\n",
      "step = 5015000: Average Return = 2.9000000953674316\n",
      "step = 5015200: loss = 3.018982172012329\n",
      "step = 5015400: loss = 3.908781051635742\n",
      "step = 5015600: loss = 2.5601141452789307\n",
      "step = 5015800: loss = 3.6702165603637695\n",
      "step = 5016000: loss = 3.4680724143981934\n",
      "step = 5016200: loss = 3.80792236328125\n",
      "step = 5016400: loss = 3.6661698818206787\n",
      "step = 5016600: loss = 5.260325908660889\n",
      "step = 5016800: loss = 3.7611143589019775\n",
      "step = 5017000: loss = 3.970937967300415\n",
      "step = 5017200: loss = 4.133609294891357\n",
      "step = 5017400: loss = 4.486655235290527\n",
      "step = 5017600: loss = 5.308569431304932\n",
      "step = 5017800: loss = 4.441192150115967\n",
      "step = 5018000: loss = 3.8340470790863037\n",
      "step = 5018200: loss = 4.980800151824951\n",
      "step = 5018400: loss = 3.9871559143066406\n",
      "step = 5018600: loss = 4.932571887969971\n",
      "step = 5018800: loss = 3.4332292079925537\n",
      "step = 5019000: loss = 4.873196125030518\n",
      "step = 5019200: loss = 3.8536033630371094\n",
      "step = 5019400: loss = 4.348344802856445\n",
      "step = 5019600: loss = 3.8841841220855713\n",
      "step = 5019800: loss = 3.763348340988159\n",
      "step = 5020000: loss = 3.6379716396331787\n",
      "step = 5020000: Average Return = 4.25\n",
      "step = 5020200: loss = 5.17629861831665\n",
      "step = 5020400: loss = 2.884014129638672\n",
      "step = 5020600: loss = 3.4913949966430664\n",
      "step = 5020800: loss = 3.1325628757476807\n",
      "step = 5021000: loss = 3.912095785140991\n",
      "step = 5021200: loss = 3.72709059715271\n",
      "step = 5021400: loss = 4.280849456787109\n",
      "step = 5021600: loss = 2.6589324474334717\n",
      "step = 5021800: loss = 3.6150104999542236\n",
      "step = 5022000: loss = 4.234011650085449\n",
      "step = 5022200: loss = 3.399491548538208\n",
      "step = 5022400: loss = 3.4523210525512695\n",
      "step = 5022600: loss = 2.639889717102051\n",
      "step = 5022800: loss = 3.5165317058563232\n",
      "step = 5023000: loss = 4.048624515533447\n",
      "step = 5023200: loss = 3.374296188354492\n",
      "step = 5023400: loss = 3.0818917751312256\n",
      "step = 5023600: loss = 3.2046926021575928\n",
      "step = 5023800: loss = 5.223012447357178\n",
      "step = 5024000: loss = 5.040235996246338\n",
      "step = 5024200: loss = 4.3694963455200195\n",
      "step = 5024400: loss = 4.420813083648682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 5024600: loss = 4.543406009674072\n",
      "step = 5024800: loss = 4.695614814758301\n",
      "step = 5025000: loss = 3.0475268363952637\n",
      "step = 5025000: Average Return = 3.0\n",
      "step = 5025200: loss = 2.9081249237060547\n",
      "step = 5025400: loss = 3.4762630462646484\n",
      "step = 5025600: loss = 4.116023063659668\n",
      "step = 5025800: loss = 5.166888236999512\n",
      "step = 5026000: loss = 4.660487174987793\n",
      "step = 5026200: loss = 3.8083531856536865\n",
      "step = 5026400: loss = 4.550363063812256\n",
      "step = 5026600: loss = 4.100122451782227\n",
      "step = 5026800: loss = 4.334804058074951\n",
      "step = 5027000: loss = 3.910513162612915\n",
      "step = 5027200: loss = 4.655033588409424\n",
      "step = 5027400: loss = 4.703727722167969\n",
      "step = 5027600: loss = 3.9413299560546875\n",
      "step = 5027800: loss = 2.681413412094116\n",
      "step = 5028000: loss = 2.758471727371216\n",
      "step = 5028200: loss = 3.348395347595215\n",
      "step = 5028400: loss = 4.638436317443848\n",
      "step = 5028600: loss = 3.9966726303100586\n",
      "step = 5028800: loss = 3.488971471786499\n",
      "step = 5029000: loss = 3.819134473800659\n",
      "step = 5029200: loss = 4.275488376617432\n",
      "step = 5029400: loss = 3.704326629638672\n",
      "step = 5029600: loss = 3.687774658203125\n",
      "step = 5029800: loss = 3.294706344604492\n",
      "step = 5030000: loss = 2.862683057785034\n",
      "step = 5030000: Average Return = 5.300000190734863\n",
      "step = 5030200: loss = 4.540661334991455\n",
      "step = 5030400: loss = 3.4171459674835205\n",
      "step = 5030600: loss = 2.676043748855591\n",
      "step = 5030800: loss = 3.397534132003784\n",
      "step = 5031000: loss = 3.5419299602508545\n",
      "step = 5031200: loss = 3.1574742794036865\n",
      "step = 5031400: loss = 3.697300672531128\n",
      "step = 5031600: loss = 3.6033220291137695\n",
      "step = 5031800: loss = 3.224735736846924\n",
      "step = 5032000: loss = 4.66725492477417\n",
      "step = 5032200: loss = 4.808652400970459\n",
      "step = 5032400: loss = 3.699313163757324\n",
      "step = 5032600: loss = 2.8949334621429443\n",
      "step = 5032800: loss = 2.328990936279297\n",
      "step = 5033000: loss = 3.8211774826049805\n",
      "step = 5033200: loss = 5.244626522064209\n",
      "step = 5033400: loss = 4.913642883300781\n",
      "step = 5033600: loss = 3.126317024230957\n",
      "step = 5033800: loss = 4.146271705627441\n",
      "step = 5034000: loss = 3.7649431228637695\n",
      "step = 5034200: loss = 3.544820547103882\n",
      "step = 5034400: loss = 4.5753889083862305\n",
      "step = 5034600: loss = 5.409265041351318\n",
      "step = 5034800: loss = 4.513823986053467\n",
      "step = 5035000: loss = 3.459606647491455\n",
      "step = 5035000: Average Return = 1.7999999523162842\n",
      "step = 5035200: loss = 3.9467926025390625\n",
      "step = 5035400: loss = 3.973759174346924\n",
      "step = 5035600: loss = 2.8438634872436523\n",
      "step = 5035800: loss = 3.2806482315063477\n",
      "step = 5036000: loss = 2.996112585067749\n",
      "step = 5036200: loss = 2.831242561340332\n",
      "step = 5036400: loss = 4.953879356384277\n",
      "step = 5036600: loss = 3.5536160469055176\n",
      "step = 5036800: loss = 3.938415765762329\n",
      "step = 5037000: loss = 3.963005304336548\n",
      "step = 5037200: loss = 4.12736177444458\n",
      "step = 5037400: loss = 2.679044246673584\n",
      "step = 5037600: loss = 2.6414990425109863\n",
      "step = 5037800: loss = 3.999851703643799\n",
      "step = 5038000: loss = 4.262750148773193\n",
      "step = 5038200: loss = 5.131906509399414\n",
      "step = 5038400: loss = 4.468320846557617\n",
      "step = 5038600: loss = 4.71086311340332\n",
      "step = 5038800: loss = 3.139287233352661\n",
      "step = 5039000: loss = 2.84517765045166\n",
      "step = 5039200: loss = 4.881735324859619\n",
      "step = 5039400: loss = 4.854969501495361\n",
      "step = 5039600: loss = 4.074201583862305\n",
      "step = 5039800: loss = 3.793696165084839\n",
      "step = 5040000: loss = 4.016182899475098\n",
      "step = 5040000: Average Return = 2.700000047683716\n",
      "step = 5040200: loss = 4.296862602233887\n",
      "step = 5040400: loss = 4.263007164001465\n",
      "step = 5040600: loss = 3.9788014888763428\n",
      "step = 5040800: loss = 4.581888675689697\n",
      "step = 5041000: loss = 3.904754161834717\n",
      "step = 5041200: loss = 2.8486385345458984\n",
      "step = 5041400: loss = 4.344776153564453\n",
      "step = 5041600: loss = 3.9560296535491943\n",
      "step = 5041800: loss = 3.4871113300323486\n",
      "step = 5042000: loss = 4.244335651397705\n",
      "step = 5042200: loss = 4.334669589996338\n",
      "step = 5042400: loss = 3.656747341156006\n",
      "step = 5042600: loss = 3.5217716693878174\n",
      "step = 5042800: loss = 3.6058759689331055\n",
      "step = 5043000: loss = 3.2125966548919678\n",
      "step = 5043200: loss = 4.158348083496094\n",
      "step = 5043400: loss = 3.279120922088623\n",
      "step = 5043600: loss = 3.888805389404297\n",
      "step = 5043800: loss = 3.3250808715820312\n",
      "step = 5044000: loss = 3.6646382808685303\n",
      "step = 5044200: loss = 3.9160962104797363\n",
      "step = 5044400: loss = 4.728270053863525\n",
      "step = 5044600: loss = 3.5040855407714844\n",
      "step = 5044800: loss = 3.846511125564575\n",
      "step = 5045000: loss = 3.0193254947662354\n",
      "step = 5045000: Average Return = 5.800000190734863\n",
      "step = 5045200: loss = 3.6722090244293213\n",
      "step = 5045400: loss = 2.934455156326294\n",
      "step = 5045600: loss = 3.8227803707122803\n",
      "step = 5045800: loss = 4.651668548583984\n",
      "step = 5046000: loss = 3.6855309009552\n",
      "step = 5046200: loss = 4.313715934753418\n",
      "step = 5046400: loss = 4.052346229553223\n",
      "step = 5046600: loss = 4.031792640686035\n",
      "step = 5046800: loss = 3.658695697784424\n",
      "step = 5047000: loss = 3.6707584857940674\n",
      "step = 5047200: loss = 4.086970329284668\n",
      "step = 5047400: loss = 4.19765043258667\n",
      "step = 5047600: loss = 3.1252832412719727\n",
      "step = 5047800: loss = 4.154910087585449\n",
      "step = 5048000: loss = 3.0258140563964844\n",
      "step = 5048200: loss = 2.978299140930176\n",
      "step = 5048400: loss = 4.808769702911377\n",
      "step = 5048600: loss = 3.6885719299316406\n",
      "step = 5048800: loss = 3.195516586303711\n",
      "step = 5049000: loss = 5.147830009460449\n",
      "step = 5049200: loss = 3.6803033351898193\n",
      "step = 5049400: loss = 3.3217098712921143\n",
      "step = 5049600: loss = 2.5567574501037598\n",
      "step = 5049800: loss = 2.819164276123047\n",
      "step = 5050000: loss = 4.648338317871094\n",
      "step = 5050000: Average Return = 3.4000000953674316\n",
      "step = 5050200: loss = 4.849654197692871\n",
      "step = 5050400: loss = 2.7996292114257812\n",
      "step = 5050600: loss = 3.218989849090576\n",
      "step = 5050800: loss = 4.976153373718262\n",
      "step = 5051000: loss = 3.071913719177246\n",
      "step = 5051200: loss = 3.335684061050415\n",
      "step = 5051400: loss = 3.3599395751953125\n",
      "step = 5051600: loss = 3.7281200885772705\n",
      "step = 5051800: loss = 3.850870370864868\n",
      "step = 5052000: loss = 3.783130407333374\n",
      "step = 5052200: loss = 5.146052360534668\n",
      "step = 5052400: loss = 3.813715696334839\n",
      "step = 5052600: loss = 3.4028782844543457\n",
      "step = 5052800: loss = 3.442997694015503\n",
      "step = 5053000: loss = 3.4318950176239014\n",
      "step = 5053200: loss = 5.399277210235596\n",
      "step = 5053400: loss = 3.4612956047058105\n",
      "step = 5053600: loss = 4.363227844238281\n",
      "step = 5053800: loss = 4.017879486083984\n",
      "step = 5054000: loss = 3.6740024089813232\n",
      "step = 5054200: loss = 4.137936115264893\n",
      "step = 5054400: loss = 4.188192844390869\n",
      "step = 5054600: loss = 4.829016208648682\n",
      "step = 5054800: loss = 4.445398330688477\n",
      "step = 5055000: loss = 3.869743585586548\n",
      "step = 5055000: Average Return = 4.099999904632568\n",
      "step = 5055200: loss = 3.7225053310394287\n",
      "step = 5055400: loss = 4.315515518188477\n",
      "step = 5055600: loss = 3.3953704833984375\n",
      "step = 5055800: loss = 2.5594115257263184\n",
      "step = 5056000: loss = 2.738245725631714\n",
      "step = 5056200: loss = 3.451897621154785\n",
      "step = 5056400: loss = 2.9078400135040283\n",
      "step = 5056600: loss = 4.3432512283325195\n",
      "step = 5056800: loss = 3.4589123725891113\n",
      "step = 5057000: loss = 2.371455669403076\n",
      "step = 5057200: loss = 3.6438474655151367\n",
      "step = 5057400: loss = 4.305845260620117\n",
      "step = 5057600: loss = 4.5742926597595215\n",
      "step = 5057800: loss = 3.1137380599975586\n",
      "step = 5058000: loss = 3.324009418487549\n",
      "step = 5058200: loss = 3.6055233478546143\n",
      "step = 5058400: loss = 2.760892868041992\n",
      "step = 5058600: loss = 2.986982583999634\n",
      "step = 5058800: loss = 2.516077756881714\n",
      "step = 5059000: loss = 3.382673501968384\n",
      "step = 5059200: loss = 3.5765724182128906\n",
      "step = 5059400: loss = 2.5229649543762207\n",
      "step = 5059600: loss = 3.445549964904785\n",
      "step = 5059800: loss = 4.462228775024414\n",
      "step = 5060000: loss = 4.512431621551514\n",
      "step = 5060000: Average Return = 3.8499999046325684\n",
      "step = 5060200: loss = 4.026055335998535\n",
      "step = 5060400: loss = 3.922589063644409\n",
      "step = 5060600: loss = 4.375890254974365\n",
      "step = 5060800: loss = 3.2281744480133057\n",
      "step = 5061000: loss = 4.588657855987549\n",
      "step = 5061200: loss = 4.445413589477539\n",
      "step = 5061400: loss = 4.8539042472839355\n",
      "step = 5061600: loss = 4.083492279052734\n",
      "step = 5061800: loss = 3.9808425903320312\n",
      "step = 5062000: loss = 3.653616189956665\n",
      "step = 5062200: loss = 4.542989253997803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 5062400: loss = 3.868685245513916\n",
      "step = 5062600: loss = 3.0201592445373535\n",
      "step = 5062800: loss = 3.263977527618408\n",
      "step = 5063000: loss = 3.568701982498169\n",
      "step = 5063200: loss = 2.877167224884033\n",
      "step = 5063400: loss = 3.3136003017425537\n",
      "step = 5063600: loss = 4.680730819702148\n",
      "step = 5063800: loss = 1.6751067638397217\n",
      "step = 5064000: loss = 3.6545329093933105\n",
      "step = 5064200: loss = 4.325575351715088\n",
      "step = 5064400: loss = 4.523679256439209\n",
      "step = 5064600: loss = 4.192729949951172\n",
      "step = 5064800: loss = 3.4751596450805664\n",
      "step = 5065000: loss = 3.6723737716674805\n",
      "step = 5065000: Average Return = 3.0\n",
      "step = 5065200: loss = 3.661774158477783\n",
      "step = 5065400: loss = 4.916970729827881\n",
      "step = 5065600: loss = 4.252673149108887\n",
      "step = 5065800: loss = 5.158844947814941\n",
      "step = 5066000: loss = 5.1148762702941895\n",
      "step = 5066200: loss = 4.114335536956787\n",
      "step = 5066400: loss = 3.908846855163574\n",
      "step = 5066600: loss = 3.073747396469116\n",
      "step = 5066800: loss = 4.338920593261719\n",
      "step = 5067000: loss = 2.7963805198669434\n",
      "step = 5067200: loss = 2.6363978385925293\n",
      "step = 5067400: loss = 4.466514587402344\n",
      "step = 5067600: loss = 3.5382792949676514\n",
      "step = 5067800: loss = 3.542440414428711\n",
      "step = 5068000: loss = 3.329970598220825\n",
      "step = 5068200: loss = 3.52529239654541\n",
      "step = 5068400: loss = 3.4436111450195312\n",
      "step = 5068600: loss = 4.690247535705566\n",
      "step = 5068800: loss = 2.754497528076172\n",
      "step = 5069000: loss = 5.143799304962158\n",
      "step = 5069200: loss = 4.339145183563232\n",
      "step = 5069400: loss = 3.5099058151245117\n",
      "step = 5069600: loss = 4.859635353088379\n",
      "step = 5069800: loss = 4.703004837036133\n",
      "step = 5070000: loss = 3.867068290710449\n",
      "step = 5070000: Average Return = 3.5\n",
      "step = 5070200: loss = 4.33922815322876\n",
      "step = 5070400: loss = 4.42822790145874\n",
      "step = 5070600: loss = 3.9576244354248047\n",
      "step = 5070800: loss = 5.260731220245361\n",
      "step = 5071000: loss = 2.9282519817352295\n",
      "step = 5071200: loss = 4.82956600189209\n",
      "step = 5071400: loss = 2.8293886184692383\n",
      "step = 5071600: loss = 3.0521581172943115\n",
      "step = 5071800: loss = 3.6276087760925293\n",
      "step = 5072000: loss = 4.355922698974609\n",
      "step = 5072200: loss = 3.9525444507598877\n",
      "step = 5072400: loss = 4.577022552490234\n",
      "step = 5072600: loss = 3.5305867195129395\n",
      "step = 5072800: loss = 4.612277030944824\n",
      "step = 5073000: loss = 4.077184200286865\n",
      "step = 5073200: loss = 5.677322864532471\n",
      "step = 5073400: loss = 3.91215443611145\n",
      "step = 5073600: loss = 3.5770232677459717\n",
      "step = 5073800: loss = 3.6315786838531494\n",
      "step = 5074000: loss = 2.884075880050659\n",
      "step = 5074200: loss = 3.7766828536987305\n",
      "step = 5074400: loss = 5.737017631530762\n",
      "step = 5074600: loss = 3.101722002029419\n",
      "step = 5074800: loss = 4.197302341461182\n",
      "step = 5075000: loss = 2.7669436931610107\n",
      "step = 5075000: Average Return = 1.600000023841858\n",
      "step = 5075200: loss = 4.252676963806152\n",
      "step = 5075400: loss = 3.9853270053863525\n",
      "step = 5075600: loss = 4.131034851074219\n",
      "step = 5075800: loss = 4.766655921936035\n",
      "step = 5076000: loss = 3.5676097869873047\n",
      "step = 5076200: loss = 4.511093616485596\n",
      "step = 5076400: loss = 4.094692707061768\n",
      "step = 5076600: loss = 3.6708226203918457\n",
      "step = 5076800: loss = 4.120789051055908\n",
      "step = 5077000: loss = 3.209652900695801\n",
      "step = 5077200: loss = 4.571674346923828\n",
      "step = 5077400: loss = 4.688945293426514\n",
      "step = 5077600: loss = 3.140042543411255\n",
      "step = 5077800: loss = 3.388749837875366\n",
      "step = 5078000: loss = 2.8544867038726807\n",
      "step = 5078200: loss = 3.1905980110168457\n",
      "step = 5078400: loss = 5.340649127960205\n",
      "step = 5078600: loss = 3.6731231212615967\n",
      "step = 5078800: loss = 2.85302734375\n",
      "step = 5079000: loss = 4.963526725769043\n",
      "step = 5079200: loss = 4.6142258644104\n",
      "step = 5079400: loss = 3.7465503215789795\n",
      "step = 5079600: loss = 4.176381587982178\n",
      "step = 5079800: loss = 2.808729887008667\n",
      "step = 5080000: loss = 3.310451030731201\n",
      "step = 5080000: Average Return = 3.3499999046325684\n",
      "step = 5080200: loss = 3.532845973968506\n",
      "step = 5080400: loss = 3.1440277099609375\n",
      "step = 5080600: loss = 4.622716426849365\n",
      "step = 5080800: loss = 3.6349315643310547\n",
      "step = 5081000: loss = 4.118119239807129\n",
      "step = 5081200: loss = 3.147200345993042\n",
      "step = 5081400: loss = 3.906191825866699\n",
      "step = 5081600: loss = 3.4630675315856934\n",
      "step = 5081800: loss = 2.337271213531494\n",
      "step = 5082000: loss = 3.117797374725342\n",
      "step = 5082200: loss = 2.9818577766418457\n",
      "step = 5082400: loss = 4.517841815948486\n",
      "step = 5082600: loss = 4.915140151977539\n",
      "step = 5082800: loss = 3.3486251831054688\n",
      "step = 5083000: loss = 4.757457256317139\n",
      "step = 5083200: loss = 3.9340128898620605\n",
      "step = 5083400: loss = 3.852118968963623\n",
      "step = 5083600: loss = 3.326756000518799\n",
      "step = 5083800: loss = 4.470145225524902\n",
      "step = 5084000: loss = 4.956961154937744\n",
      "step = 5084200: loss = 3.7649998664855957\n",
      "step = 5084400: loss = 3.486157178878784\n",
      "step = 5084600: loss = 4.904017925262451\n",
      "step = 5084800: loss = 4.158398151397705\n",
      "step = 5085000: loss = 3.1195387840270996\n",
      "step = 5085000: Average Return = 3.8499999046325684\n",
      "step = 5085200: loss = 3.5749402046203613\n",
      "step = 5085400: loss = 4.284553527832031\n",
      "step = 5085600: loss = 3.728822946548462\n",
      "step = 5085800: loss = 4.460701942443848\n",
      "step = 5086000: loss = 3.767415761947632\n",
      "step = 5086200: loss = 4.564014911651611\n",
      "step = 5086400: loss = 4.306718349456787\n",
      "step = 5086600: loss = 3.4357750415802\n",
      "step = 5086800: loss = 4.424841403961182\n",
      "step = 5087000: loss = 3.299846649169922\n",
      "step = 5087200: loss = 4.505613327026367\n",
      "step = 5087400: loss = 3.836897611618042\n",
      "step = 5087600: loss = 4.059695720672607\n",
      "step = 5087800: loss = 3.548170328140259\n",
      "step = 5088000: loss = 3.4007952213287354\n",
      "step = 5088200: loss = 5.06588077545166\n",
      "step = 5088400: loss = 3.151174783706665\n",
      "step = 5088600: loss = 4.489247798919678\n",
      "step = 5088800: loss = 3.117431879043579\n",
      "step = 5089000: loss = 4.431419372558594\n",
      "step = 5089200: loss = 4.1293511390686035\n",
      "step = 5089400: loss = 3.2137365341186523\n",
      "step = 5089600: loss = 3.040102481842041\n",
      "step = 5089800: loss = 3.9466912746429443\n",
      "step = 5090000: loss = 4.026798725128174\n",
      "step = 5090000: Average Return = 3.9000000953674316\n",
      "step = 5090200: loss = 4.415626049041748\n",
      "step = 5090400: loss = 5.27456521987915\n",
      "step = 5090600: loss = 3.101325273513794\n",
      "step = 5090800: loss = 3.9043235778808594\n",
      "step = 5091000: loss = 3.080862283706665\n",
      "step = 5091200: loss = 4.478513717651367\n",
      "step = 5091400: loss = 3.9027366638183594\n",
      "step = 5091600: loss = 3.882221221923828\n",
      "step = 5091800: loss = 4.879813194274902\n",
      "step = 5092000: loss = 3.930891990661621\n",
      "step = 5092200: loss = 5.173206806182861\n",
      "step = 5092400: loss = 3.2902820110321045\n",
      "step = 5092600: loss = 3.2783164978027344\n",
      "step = 5092800: loss = 3.5761942863464355\n",
      "step = 5093000: loss = 4.8127546310424805\n",
      "step = 5093200: loss = 4.256918430328369\n",
      "step = 5093400: loss = 3.4248735904693604\n",
      "step = 5093600: loss = 3.5044565200805664\n",
      "step = 5093800: loss = 3.436884641647339\n",
      "step = 5094000: loss = 3.7070534229278564\n",
      "step = 5094200: loss = 4.120763301849365\n",
      "step = 5094400: loss = 3.5654211044311523\n",
      "step = 5094600: loss = 4.299061298370361\n",
      "step = 5094800: loss = 4.029586315155029\n",
      "step = 5095000: loss = 3.282052755355835\n",
      "step = 5095000: Average Return = 2.549999952316284\n",
      "step = 5095200: loss = 4.066016674041748\n",
      "step = 5095400: loss = 3.430467128753662\n",
      "step = 5095600: loss = 2.2140421867370605\n",
      "step = 5095800: loss = 3.4619369506835938\n",
      "step = 5096000: loss = 2.85674786567688\n",
      "step = 5096200: loss = 4.511765003204346\n",
      "step = 5096400: loss = 4.63047981262207\n",
      "step = 5096600: loss = 3.764331340789795\n",
      "step = 5096800: loss = 4.541364669799805\n",
      "step = 5097000: loss = 3.937056303024292\n",
      "step = 5097200: loss = 4.46275520324707\n",
      "step = 5097400: loss = 3.4606094360351562\n",
      "step = 5097600: loss = 3.1042697429656982\n",
      "step = 5097800: loss = 5.61399507522583\n",
      "step = 5098000: loss = 2.725550889968872\n",
      "step = 5098200: loss = 4.363617897033691\n",
      "step = 5098400: loss = 4.615573406219482\n",
      "step = 5098600: loss = 4.110594272613525\n",
      "step = 5098800: loss = 4.357203960418701\n",
      "step = 5099000: loss = 3.639565944671631\n",
      "step = 5099200: loss = 3.8879833221435547\n",
      "step = 5099400: loss = 3.0549135208129883\n",
      "step = 5099600: loss = 4.364862442016602\n",
      "step = 5099800: loss = 4.4062628746032715\n",
      "step = 5100000: loss = 4.189911365509033\n",
      "step = 5100000: Average Return = 4.599999904632568\n",
      "step = 5100200: loss = 3.9368627071380615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 5100400: loss = 4.452319622039795\n",
      "step = 5100600: loss = 3.462428569793701\n",
      "step = 5100800: loss = 4.272965431213379\n",
      "step = 5101000: loss = 3.7974114418029785\n",
      "step = 5101200: loss = 3.232576847076416\n",
      "step = 5101400: loss = 4.044919967651367\n",
      "step = 5101600: loss = 3.4468421936035156\n",
      "step = 5101800: loss = 4.19993782043457\n",
      "step = 5102000: loss = 4.591176509857178\n",
      "step = 5102200: loss = 3.581230401992798\n",
      "step = 5102400: loss = 3.90575909614563\n",
      "step = 5102600: loss = 3.2610881328582764\n",
      "step = 5102800: loss = 3.073712110519409\n",
      "step = 5103000: loss = 3.4962267875671387\n",
      "step = 5103200: loss = 3.2452306747436523\n",
      "step = 5103400: loss = 3.9635226726531982\n",
      "step = 5103600: loss = 4.2226104736328125\n",
      "step = 5103800: loss = 3.8950436115264893\n",
      "step = 5104000: loss = 4.06982946395874\n",
      "step = 5104200: loss = 4.077024936676025\n",
      "step = 5104400: loss = 3.459092617034912\n",
      "step = 5104600: loss = 3.242685079574585\n",
      "step = 5104800: loss = 2.594794750213623\n",
      "step = 5105000: loss = 3.665820837020874\n",
      "step = 5105000: Average Return = 3.25\n",
      "step = 5105200: loss = 3.661440849304199\n",
      "step = 5105400: loss = 2.9130613803863525\n",
      "step = 5105600: loss = 5.011719703674316\n",
      "step = 5105800: loss = 3.6735756397247314\n",
      "step = 5106000: loss = 3.7376468181610107\n",
      "step = 5106200: loss = 3.363948345184326\n",
      "step = 5106400: loss = 3.759274482727051\n",
      "step = 5106600: loss = 5.030668258666992\n",
      "step = 5106800: loss = 4.644900798797607\n",
      "step = 5107000: loss = 3.5446016788482666\n",
      "step = 5107200: loss = 4.568939208984375\n",
      "step = 5107400: loss = 3.9528985023498535\n",
      "step = 5107600: loss = 5.034311294555664\n",
      "step = 5107800: loss = 4.039008140563965\n",
      "step = 5108000: loss = 4.950860500335693\n",
      "step = 5108200: loss = 3.995802640914917\n",
      "step = 5108400: loss = 3.5180554389953613\n",
      "step = 5108600: loss = 3.442497491836548\n",
      "step = 5108800: loss = 3.3385419845581055\n",
      "step = 5109000: loss = 4.545395374298096\n",
      "step = 5109200: loss = 4.584101676940918\n",
      "step = 5109400: loss = 5.04932165145874\n",
      "step = 5109600: loss = 4.500898838043213\n",
      "step = 5109800: loss = 4.19193172454834\n",
      "step = 5110000: loss = 3.434683084487915\n",
      "step = 5110000: Average Return = 4.150000095367432\n",
      "step = 5110200: loss = 2.6017990112304688\n",
      "step = 5110400: loss = 3.5313613414764404\n",
      "step = 5110600: loss = 4.541733741760254\n",
      "step = 5110800: loss = 4.205789089202881\n",
      "step = 5111000: loss = 3.5663280487060547\n",
      "step = 5111200: loss = 3.646865129470825\n",
      "step = 5111400: loss = 3.2542693614959717\n",
      "step = 5111600: loss = 3.226398229598999\n",
      "step = 5111800: loss = 3.659085512161255\n",
      "step = 5112000: loss = 4.7429633140563965\n",
      "step = 5112200: loss = 3.5133538246154785\n",
      "step = 5112400: loss = 4.438125133514404\n",
      "step = 5112600: loss = 4.464192867279053\n",
      "step = 5112800: loss = 3.8340513706207275\n",
      "step = 5113000: loss = 3.080730438232422\n",
      "step = 5113200: loss = 3.9697792530059814\n",
      "step = 5113400: loss = 4.033963203430176\n",
      "step = 5113600: loss = 4.601254463195801\n",
      "step = 5113800: loss = 4.376464366912842\n",
      "step = 5114000: loss = 4.28294038772583\n",
      "step = 5114200: loss = 3.541063070297241\n",
      "step = 5114400: loss = 4.6917195320129395\n",
      "step = 5114600: loss = 4.787478446960449\n",
      "step = 5114800: loss = 3.71142315864563\n",
      "step = 5115000: loss = 3.936962127685547\n",
      "step = 5115000: Average Return = 3.799999952316284\n",
      "step = 5115200: loss = 3.721781015396118\n",
      "step = 5115400: loss = 4.50654935836792\n",
      "step = 5115600: loss = 3.314970016479492\n",
      "step = 5115800: loss = 3.3632774353027344\n",
      "step = 5116000: loss = 5.109567165374756\n",
      "step = 5116200: loss = 4.000093460083008\n",
      "step = 5116400: loss = 3.3110368251800537\n",
      "step = 5116600: loss = 4.02361536026001\n",
      "step = 5116800: loss = 4.200135707855225\n",
      "step = 5117000: loss = 5.009796619415283\n",
      "step = 5117200: loss = 3.968907594680786\n",
      "step = 5117400: loss = 3.8079655170440674\n",
      "step = 5117600: loss = 3.043835401535034\n",
      "step = 5117800: loss = 3.242692708969116\n",
      "step = 5118000: loss = 3.9903690814971924\n",
      "step = 5118200: loss = 3.9619622230529785\n",
      "step = 5118400: loss = 4.253448486328125\n",
      "step = 5118600: loss = 4.3489179611206055\n",
      "step = 5118800: loss = 3.6862432956695557\n",
      "step = 5119000: loss = 3.5897390842437744\n",
      "step = 5119200: loss = 3.0705392360687256\n",
      "step = 5119400: loss = 3.901905059814453\n",
      "step = 5119600: loss = 4.526086807250977\n",
      "step = 5119800: loss = 4.885114669799805\n",
      "step = 5120000: loss = 3.484748125076294\n",
      "step = 5120000: Average Return = 4.599999904632568\n",
      "step = 5120200: loss = 3.8410606384277344\n",
      "step = 5120400: loss = 3.664578676223755\n",
      "step = 5120600: loss = 3.5971105098724365\n",
      "step = 5120800: loss = 4.04984712600708\n",
      "step = 5121000: loss = 2.818751573562622\n",
      "step = 5121200: loss = 3.302321672439575\n",
      "step = 5121400: loss = 3.9095263481140137\n",
      "step = 5121600: loss = 3.3577568531036377\n",
      "step = 5121800: loss = 3.2812821865081787\n",
      "step = 5122000: loss = 3.5543429851531982\n",
      "step = 5122200: loss = 3.4320976734161377\n",
      "step = 5122400: loss = 3.703130006790161\n",
      "step = 5122600: loss = 4.130277156829834\n",
      "step = 5122800: loss = 4.761884689331055\n",
      "step = 5123000: loss = 4.629227638244629\n",
      "step = 5123200: loss = 4.426910400390625\n",
      "step = 5123400: loss = 3.576504945755005\n",
      "step = 5123600: loss = 4.849593162536621\n",
      "step = 5123800: loss = 3.2597854137420654\n",
      "step = 5124000: loss = 4.199055194854736\n",
      "step = 5124200: loss = 3.3963396549224854\n",
      "step = 5124400: loss = 4.227872848510742\n",
      "step = 5124600: loss = 3.5508182048797607\n",
      "step = 5124800: loss = 3.164165496826172\n",
      "step = 5125000: loss = 5.039009094238281\n",
      "step = 5125000: Average Return = 2.700000047683716\n",
      "step = 5125200: loss = 3.9293148517608643\n",
      "step = 5125400: loss = 4.475706100463867\n",
      "step = 5125600: loss = 3.018455743789673\n",
      "step = 5125800: loss = 3.702357292175293\n",
      "step = 5126000: loss = 4.023074150085449\n",
      "step = 5126200: loss = 2.7070772647857666\n",
      "step = 5126400: loss = 3.1353044509887695\n",
      "step = 5126600: loss = 4.032051086425781\n",
      "step = 5126800: loss = 2.709428548812866\n",
      "step = 5127000: loss = 3.504575729370117\n",
      "step = 5127200: loss = 4.081305027008057\n",
      "step = 5127400: loss = 5.8735246658325195\n",
      "step = 5127600: loss = 5.05300235748291\n",
      "step = 5127800: loss = 4.252607822418213\n",
      "step = 5128000: loss = 4.402459621429443\n",
      "step = 5128200: loss = 4.532186985015869\n",
      "step = 5128400: loss = 2.7991862297058105\n",
      "step = 5128600: loss = 3.579488515853882\n",
      "step = 5128800: loss = 4.101781368255615\n",
      "step = 5129000: loss = 4.229866981506348\n",
      "step = 5129200: loss = 3.296159029006958\n",
      "step = 5129400: loss = 3.6714465618133545\n",
      "step = 5129600: loss = 3.614915609359741\n",
      "step = 5129800: loss = 3.9280200004577637\n",
      "step = 5130000: loss = 4.014924049377441\n",
      "step = 5130000: Average Return = 3.0\n",
      "step = 5130200: loss = 3.4608709812164307\n",
      "step = 5130400: loss = 4.287633419036865\n",
      "step = 5130600: loss = 4.195937156677246\n",
      "step = 5130800: loss = 4.2196760177612305\n",
      "step = 5131000: loss = 3.8058674335479736\n",
      "step = 5131200: loss = 4.27695369720459\n",
      "step = 5131400: loss = 4.252825736999512\n",
      "step = 5131600: loss = 3.0032496452331543\n",
      "step = 5131800: loss = 3.0514395236968994\n",
      "step = 5132000: loss = 3.495042085647583\n",
      "step = 5132200: loss = 3.4536638259887695\n",
      "step = 5132400: loss = 3.4597203731536865\n",
      "step = 5132600: loss = 3.392303466796875\n",
      "step = 5132800: loss = 5.140664100646973\n",
      "step = 5133000: loss = 4.229524612426758\n",
      "step = 5133200: loss = 3.3656768798828125\n",
      "step = 5133400: loss = 3.973372220993042\n",
      "step = 5133600: loss = 3.3860716819763184\n",
      "step = 5133800: loss = 4.126622200012207\n",
      "step = 5134000: loss = 4.930765151977539\n",
      "step = 5134200: loss = 2.9232518672943115\n",
      "step = 5134400: loss = 3.27555251121521\n",
      "step = 5134600: loss = 3.7699878215789795\n",
      "step = 5134800: loss = 4.59808874130249\n",
      "step = 5135000: loss = 2.7261760234832764\n",
      "step = 5135000: Average Return = 5.650000095367432\n",
      "step = 5135200: loss = 4.402904510498047\n",
      "step = 5135400: loss = 4.577490329742432\n",
      "step = 5135600: loss = 3.952342987060547\n",
      "step = 5135800: loss = 4.600852012634277\n",
      "step = 5136000: loss = 2.8686559200286865\n",
      "step = 5136200: loss = 3.701911449432373\n",
      "step = 5136400: loss = 3.664573907852173\n",
      "step = 5136600: loss = 3.6668455600738525\n",
      "step = 5136800: loss = 4.021817684173584\n",
      "step = 5137000: loss = 3.22745680809021\n",
      "step = 5137200: loss = 3.398812770843506\n",
      "step = 5137400: loss = 4.381213665008545\n",
      "step = 5137600: loss = 3.8739471435546875\n",
      "step = 5137800: loss = 3.3413472175598145\n",
      "step = 5138000: loss = 3.3005998134613037\n",
      "step = 5138200: loss = 3.34405255317688\n",
      "step = 5138400: loss = 3.9974822998046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 5138600: loss = 3.1277551651000977\n",
      "step = 5138800: loss = 3.5197229385375977\n",
      "step = 5139000: loss = 3.478142023086548\n",
      "step = 5139200: loss = 4.997927188873291\n",
      "step = 5139400: loss = 3.2111599445343018\n",
      "step = 5139600: loss = 4.166362285614014\n",
      "step = 5139800: loss = 3.206271171569824\n",
      "step = 5140000: loss = 4.31138801574707\n",
      "step = 5140000: Average Return = 2.5999999046325684\n",
      "step = 5140200: loss = 3.38897442817688\n",
      "step = 5140400: loss = 4.449108600616455\n",
      "step = 5140600: loss = 4.317720413208008\n",
      "step = 5140800: loss = 4.401836395263672\n",
      "step = 5141000: loss = 4.311785697937012\n",
      "step = 5141200: loss = 3.05550217628479\n",
      "step = 5141400: loss = 3.927651882171631\n",
      "step = 5141600: loss = 5.069795608520508\n",
      "step = 5141800: loss = 3.745955228805542\n",
      "step = 5142000: loss = 3.3640213012695312\n",
      "step = 5142200: loss = 5.237348556518555\n",
      "step = 5142400: loss = 3.667161703109741\n",
      "step = 5142600: loss = 2.1734349727630615\n",
      "step = 5142800: loss = 2.678447723388672\n",
      "step = 5143000: loss = 4.1517558097839355\n",
      "step = 5143200: loss = 2.8167836666107178\n",
      "step = 5143400: loss = 4.166170597076416\n",
      "step = 5143600: loss = 4.014706611633301\n",
      "step = 5143800: loss = 3.734781503677368\n",
      "step = 5144000: loss = 3.7261528968811035\n",
      "step = 5144200: loss = 4.130655765533447\n",
      "step = 5144400: loss = 2.6862151622772217\n",
      "step = 5144600: loss = 4.176877975463867\n",
      "step = 5144800: loss = 3.666705846786499\n",
      "step = 5145000: loss = 4.223627090454102\n",
      "step = 5145000: Average Return = 4.0\n",
      "step = 5145200: loss = 4.1165666580200195\n",
      "step = 5145400: loss = 3.7859885692596436\n",
      "step = 5145600: loss = 3.8803179264068604\n",
      "step = 5145800: loss = 3.2805681228637695\n",
      "step = 5146000: loss = 4.446643352508545\n",
      "step = 5146200: loss = 3.8533313274383545\n",
      "step = 5146400: loss = 3.2903292179107666\n",
      "step = 5146600: loss = 3.513869047164917\n",
      "step = 5146800: loss = 3.1421453952789307\n",
      "step = 5147000: loss = 4.468693256378174\n",
      "step = 5147200: loss = 2.9969985485076904\n",
      "step = 5147400: loss = 3.712658405303955\n",
      "step = 5147600: loss = 3.2071444988250732\n",
      "step = 5147800: loss = 3.924921751022339\n",
      "step = 5148000: loss = 5.523812294006348\n",
      "step = 5148200: loss = 2.9141154289245605\n",
      "step = 5148400: loss = 3.3656671047210693\n",
      "step = 5148600: loss = 3.833004951477051\n",
      "step = 5148800: loss = 4.638354778289795\n",
      "step = 5149000: loss = 3.4966683387756348\n",
      "step = 5149200: loss = 2.64833664894104\n",
      "step = 5149400: loss = 3.666602611541748\n",
      "step = 5149600: loss = 2.61407470703125\n",
      "step = 5149800: loss = 3.175255298614502\n",
      "step = 5150000: loss = 4.589542865753174\n",
      "step = 5150000: Average Return = 3.1500000953674316\n",
      "step = 5150200: loss = 4.395480155944824\n",
      "step = 5150400: loss = 3.31246280670166\n",
      "step = 5150600: loss = 4.0179123878479\n",
      "step = 5150800: loss = 3.1127123832702637\n",
      "step = 5151000: loss = 3.9254205226898193\n",
      "step = 5151200: loss = 4.045637130737305\n",
      "step = 5151400: loss = 4.890441417694092\n",
      "step = 5151600: loss = 2.716073513031006\n",
      "step = 5151800: loss = 3.24648118019104\n",
      "step = 5152000: loss = 4.179605007171631\n",
      "step = 5152200: loss = 5.458559036254883\n",
      "step = 5152400: loss = 3.477816581726074\n",
      "step = 5152600: loss = 3.7594501972198486\n",
      "step = 5152800: loss = 3.9784367084503174\n",
      "step = 5153000: loss = 4.46395206451416\n",
      "step = 5153200: loss = 3.5798919200897217\n",
      "step = 5153400: loss = 3.5381076335906982\n",
      "step = 5153600: loss = 4.118673801422119\n",
      "step = 5153800: loss = 4.005722522735596\n",
      "step = 5154000: loss = 4.63059663772583\n",
      "step = 5154200: loss = 2.5135297775268555\n",
      "step = 5154400: loss = 2.703397274017334\n",
      "step = 5154600: loss = 3.5787901878356934\n",
      "step = 5154800: loss = 4.173372745513916\n",
      "step = 5155000: loss = 3.818540573120117\n",
      "step = 5155000: Average Return = 4.099999904632568\n",
      "step = 5155200: loss = 3.2724902629852295\n",
      "step = 5155400: loss = 2.8044111728668213\n",
      "step = 5155600: loss = 2.837756872177124\n",
      "step = 5155800: loss = 3.873976469039917\n",
      "step = 5156000: loss = 4.031718730926514\n",
      "step = 5156200: loss = 4.67415714263916\n",
      "step = 5156400: loss = 4.6884989738464355\n",
      "step = 5156600: loss = 4.066421031951904\n",
      "step = 5156800: loss = 3.7038748264312744\n",
      "step = 5157000: loss = 4.214092254638672\n",
      "step = 5157200: loss = 3.4181933403015137\n",
      "step = 5157400: loss = 2.944040536880493\n",
      "step = 5157600: loss = 2.1321868896484375\n",
      "step = 5157800: loss = 3.4402754306793213\n",
      "step = 5158000: loss = 3.4146389961242676\n",
      "step = 5158200: loss = 4.636978626251221\n",
      "step = 5158400: loss = 4.900959491729736\n",
      "step = 5158600: loss = 3.5185399055480957\n",
      "step = 5158800: loss = 4.3415207862854\n",
      "step = 5159000: loss = 4.243019104003906\n",
      "step = 5159200: loss = 3.930499792098999\n",
      "step = 5159400: loss = 3.999877452850342\n",
      "step = 5159600: loss = 4.363658428192139\n",
      "step = 5159800: loss = 3.8044722080230713\n",
      "step = 5160000: loss = 4.385372638702393\n",
      "step = 5160000: Average Return = 3.4000000953674316\n",
      "step = 5160200: loss = 3.779393196105957\n",
      "step = 5160400: loss = 3.7915921211242676\n",
      "step = 5160600: loss = 5.117117881774902\n",
      "step = 5160800: loss = 3.8821771144866943\n",
      "step = 5161000: loss = 2.9772253036499023\n",
      "step = 5161200: loss = 4.039200782775879\n",
      "step = 5161400: loss = 3.5991015434265137\n",
      "step = 5161600: loss = 4.121155738830566\n",
      "step = 5161800: loss = 4.403510093688965\n",
      "step = 5162000: loss = 4.683162689208984\n",
      "step = 5162200: loss = 4.634654521942139\n",
      "step = 5162400: loss = 3.179495096206665\n",
      "step = 5162600: loss = 3.7458107471466064\n",
      "step = 5162800: loss = 2.927399158477783\n",
      "step = 5163000: loss = 2.98974871635437\n",
      "step = 5163200: loss = 3.1244313716888428\n",
      "step = 5163400: loss = 3.664041042327881\n",
      "step = 5163600: loss = 3.3669328689575195\n",
      "step = 5163800: loss = 3.73105788230896\n",
      "step = 5164000: loss = 4.05890417098999\n",
      "step = 5164200: loss = 3.7441213130950928\n",
      "step = 5164400: loss = 4.133722305297852\n",
      "step = 5164600: loss = 3.858739137649536\n",
      "step = 5164800: loss = 4.010680675506592\n",
      "step = 5165000: loss = 3.786524772644043\n",
      "step = 5165000: Average Return = 3.4000000953674316\n",
      "step = 5165200: loss = 4.2991461753845215\n",
      "step = 5165400: loss = 3.68265700340271\n",
      "step = 5165600: loss = 3.4159257411956787\n",
      "step = 5165800: loss = 4.331192493438721\n",
      "step = 5166000: loss = 2.2502832412719727\n",
      "step = 5166200: loss = 3.8023247718811035\n",
      "step = 5166400: loss = 4.7980570793151855\n",
      "step = 5166600: loss = 3.8922648429870605\n",
      "step = 5166800: loss = 4.757651329040527\n",
      "step = 5167000: loss = 3.842862367630005\n",
      "step = 5167200: loss = 4.657029628753662\n",
      "step = 5167400: loss = 4.493727207183838\n",
      "step = 5167600: loss = 4.102652072906494\n",
      "step = 5167800: loss = 3.4316885471343994\n",
      "step = 5168000: loss = 2.523681879043579\n",
      "step = 5168200: loss = 4.748996257781982\n",
      "step = 5168400: loss = 2.923771381378174\n",
      "step = 5168600: loss = 4.309208393096924\n",
      "step = 5168800: loss = 4.718255996704102\n",
      "step = 5169000: loss = 3.904297113418579\n",
      "step = 5169200: loss = 4.220934867858887\n",
      "step = 5169400: loss = 3.046842575073242\n",
      "step = 5169600: loss = 4.262844085693359\n",
      "step = 5169800: loss = 5.264276027679443\n",
      "step = 5170000: loss = 3.753291606903076\n",
      "step = 5170000: Average Return = 3.75\n",
      "step = 5170200: loss = 3.1434807777404785\n",
      "step = 5170400: loss = 3.949655294418335\n",
      "step = 5170600: loss = 3.1944940090179443\n",
      "step = 5170800: loss = 2.461057424545288\n",
      "step = 5171000: loss = 3.980595111846924\n",
      "step = 5171200: loss = 3.609469413757324\n",
      "step = 5171400: loss = 5.194214820861816\n",
      "step = 5171600: loss = 3.1008682250976562\n",
      "step = 5171800: loss = 3.405353307723999\n",
      "step = 5172000: loss = 3.9224908351898193\n",
      "step = 5172200: loss = 3.5435969829559326\n",
      "step = 5172400: loss = 3.38830304145813\n",
      "step = 5172600: loss = 3.1961588859558105\n",
      "step = 5172800: loss = 2.2694902420043945\n",
      "step = 5173000: loss = 3.5929689407348633\n",
      "step = 5173200: loss = 4.673122882843018\n",
      "step = 5173400: loss = 2.978339195251465\n",
      "step = 5173600: loss = 3.577923536300659\n",
      "step = 5173800: loss = 4.69064998626709\n",
      "step = 5174000: loss = 3.6559245586395264\n",
      "step = 5174200: loss = 4.306243419647217\n",
      "step = 5174400: loss = 4.608105182647705\n",
      "step = 5174600: loss = 3.839639186859131\n",
      "step = 5174800: loss = 4.383857727050781\n",
      "step = 5175000: loss = 3.0295770168304443\n",
      "step = 5175000: Average Return = 3.049999952316284\n",
      "step = 5175200: loss = 4.917120933532715\n",
      "step = 5175400: loss = 3.820223569869995\n",
      "step = 5175600: loss = 3.5147624015808105\n",
      "step = 5175800: loss = 4.09689474105835\n",
      "step = 5176000: loss = 3.401296854019165\n",
      "step = 5176200: loss = 3.338052272796631\n",
      "step = 5176400: loss = 3.2429771423339844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 5176600: loss = 2.7439382076263428\n",
      "step = 5176800: loss = 3.391524314880371\n",
      "step = 5177000: loss = 4.637409210205078\n",
      "step = 5177200: loss = 3.4460060596466064\n",
      "step = 5177400: loss = 4.154609203338623\n",
      "step = 5177600: loss = 2.2177865505218506\n",
      "step = 5177800: loss = 4.223108291625977\n",
      "step = 5178000: loss = 3.263983726501465\n",
      "step = 5178200: loss = 4.1758551597595215\n",
      "step = 5178400: loss = 3.650921583175659\n",
      "step = 5178600: loss = 3.108553409576416\n",
      "step = 5178800: loss = 4.222033500671387\n",
      "step = 5179000: loss = 3.6547396183013916\n",
      "step = 5179200: loss = 4.775564670562744\n",
      "step = 5179400: loss = 3.9248852729797363\n",
      "step = 5179600: loss = 2.025848627090454\n",
      "step = 5179800: loss = 3.336073637008667\n",
      "step = 5180000: loss = 3.314671277999878\n",
      "step = 5180000: Average Return = 4.550000190734863\n",
      "step = 5180200: loss = 4.237945556640625\n",
      "step = 5180400: loss = 4.452174663543701\n",
      "step = 5180600: loss = 3.5877623558044434\n",
      "step = 5180800: loss = 4.695822715759277\n",
      "step = 5181000: loss = 2.6713290214538574\n",
      "step = 5181200: loss = 3.4853081703186035\n",
      "step = 5181400: loss = 3.7299370765686035\n",
      "step = 5181600: loss = 3.412551164627075\n",
      "step = 5181800: loss = 3.6266283988952637\n",
      "step = 5182000: loss = 4.5053911209106445\n",
      "step = 5182200: loss = 2.862186908721924\n",
      "step = 5182400: loss = 3.76102352142334\n",
      "step = 5182600: loss = 3.259751319885254\n",
      "step = 5182800: loss = 3.87013840675354\n",
      "step = 5183000: loss = 4.402772426605225\n",
      "step = 5183200: loss = 3.275444984436035\n",
      "step = 5183400: loss = 3.692979097366333\n",
      "step = 5183600: loss = 4.391374111175537\n",
      "step = 5183800: loss = 3.1264965534210205\n",
      "step = 5184000: loss = 4.282947540283203\n",
      "step = 5184200: loss = 3.403841972351074\n",
      "step = 5184400: loss = 4.431523323059082\n",
      "step = 5184600: loss = 4.67482328414917\n",
      "step = 5184800: loss = 2.784430503845215\n",
      "step = 5185000: loss = 4.743504047393799\n",
      "step = 5185000: Average Return = 4.0\n",
      "step = 5185200: loss = 3.739637613296509\n",
      "step = 5185400: loss = 3.475071907043457\n",
      "step = 5185600: loss = 3.8743298053741455\n",
      "step = 5185800: loss = 3.2538299560546875\n",
      "step = 5186000: loss = 2.9424853324890137\n",
      "step = 5186200: loss = 5.082695960998535\n",
      "step = 5186400: loss = 4.858686923980713\n",
      "step = 5186600: loss = 3.1048076152801514\n",
      "step = 5186800: loss = 4.383044719696045\n",
      "step = 5187000: loss = 3.0057170391082764\n",
      "step = 5187200: loss = 4.536728382110596\n",
      "step = 5187400: loss = 4.007240295410156\n",
      "step = 5187600: loss = 4.116950035095215\n",
      "step = 5187800: loss = 4.120486736297607\n",
      "step = 5188000: loss = 3.9716484546661377\n",
      "step = 5188200: loss = 3.566822052001953\n",
      "step = 5188400: loss = 3.442056894302368\n",
      "step = 5188600: loss = 3.3702895641326904\n",
      "step = 5188800: loss = 3.07220196723938\n",
      "step = 5189000: loss = 3.866286516189575\n",
      "step = 5189200: loss = 3.453909158706665\n",
      "step = 5189400: loss = 3.3546416759490967\n",
      "step = 5189600: loss = 2.757988214492798\n",
      "step = 5189800: loss = 3.622283935546875\n",
      "step = 5190000: loss = 3.658095121383667\n",
      "step = 5190000: Average Return = 3.200000047683716\n",
      "step = 5190200: loss = 4.224143028259277\n",
      "step = 5190400: loss = 4.849154949188232\n",
      "step = 5190600: loss = 4.195704936981201\n",
      "step = 5190800: loss = 2.4655513763427734\n",
      "step = 5191000: loss = 3.190798282623291\n",
      "step = 5191200: loss = 4.405990123748779\n",
      "step = 5191400: loss = 2.875988483428955\n",
      "step = 5191600: loss = 3.60830020904541\n",
      "step = 5191800: loss = 3.9538562297821045\n",
      "step = 5192000: loss = 4.045871257781982\n",
      "step = 5192200: loss = 4.498140811920166\n",
      "step = 5192400: loss = 3.1572320461273193\n",
      "step = 5192600: loss = 2.6859405040740967\n",
      "step = 5192800: loss = 3.8131964206695557\n",
      "step = 5193000: loss = 3.6146023273468018\n",
      "step = 5193200: loss = 4.113552570343018\n",
      "step = 5193400: loss = 4.049271583557129\n",
      "step = 5193600: loss = 3.8567276000976562\n",
      "step = 5193800: loss = 3.4426019191741943\n",
      "step = 5194000: loss = 4.370034694671631\n",
      "step = 5194200: loss = 4.144618034362793\n",
      "step = 5194400: loss = 3.0951271057128906\n",
      "step = 5194600: loss = 3.419560432434082\n",
      "step = 5194800: loss = 3.1536505222320557\n",
      "step = 5195000: loss = 4.543455123901367\n",
      "step = 5195000: Average Return = 4.099999904632568\n",
      "step = 5195200: loss = 3.8774850368499756\n",
      "step = 5195400: loss = 2.4473299980163574\n",
      "step = 5195600: loss = 2.649827718734741\n",
      "step = 5195800: loss = 4.905781269073486\n",
      "step = 5196000: loss = 3.836205244064331\n",
      "step = 5196200: loss = 1.4380522966384888\n",
      "step = 5196400: loss = 2.681013822555542\n",
      "step = 5196600: loss = 4.518755912780762\n",
      "step = 5196800: loss = 3.057926654815674\n",
      "step = 5197000: loss = 3.5838584899902344\n",
      "step = 5197200: loss = 2.83203125\n",
      "step = 5197400: loss = 2.43137264251709\n",
      "step = 5197600: loss = 3.069143533706665\n",
      "step = 5197800: loss = 3.522857666015625\n",
      "step = 5198000: loss = 3.6126396656036377\n",
      "step = 5198200: loss = 4.217239856719971\n",
      "step = 5198400: loss = 4.62135648727417\n",
      "step = 5198600: loss = 3.006850242614746\n",
      "step = 5198800: loss = 2.3726396560668945\n",
      "step = 5199000: loss = 3.0384957790374756\n",
      "step = 5199200: loss = 3.329136848449707\n",
      "step = 5199400: loss = 3.839369535446167\n",
      "step = 5199600: loss = 4.40175724029541\n",
      "step = 5199800: loss = 4.9812493324279785\n",
      "step = 5200000: loss = 4.342606544494629\n",
      "step = 5200000: Average Return = 3.799999952316284\n",
      "step = 5200200: loss = 5.03896427154541\n",
      "step = 5200400: loss = 3.0370593070983887\n",
      "step = 5200600: loss = 4.226214408874512\n",
      "step = 5200800: loss = 4.941057205200195\n",
      "step = 5201000: loss = 3.5827324390411377\n",
      "step = 5201200: loss = 3.4892094135284424\n",
      "step = 5201400: loss = 3.0689783096313477\n",
      "step = 5201600: loss = 4.274788856506348\n",
      "step = 5201800: loss = 4.499672889709473\n",
      "step = 5202000: loss = 4.324828624725342\n",
      "step = 5202200: loss = 3.120000123977661\n",
      "step = 5202400: loss = 5.784374713897705\n",
      "step = 5202600: loss = 5.087371826171875\n",
      "step = 5202800: loss = 3.799266815185547\n",
      "step = 5203000: loss = 3.0499846935272217\n",
      "step = 5203200: loss = 4.158503532409668\n",
      "step = 5203400: loss = 4.354538917541504\n",
      "step = 5203600: loss = 4.6941962242126465\n",
      "step = 5203800: loss = 4.416951656341553\n",
      "step = 5204000: loss = 2.904541492462158\n",
      "step = 5204200: loss = 1.8915079832077026\n",
      "step = 5204400: loss = 3.58880877494812\n",
      "step = 5204600: loss = 3.9236228466033936\n",
      "step = 5204800: loss = 2.65289306640625\n",
      "step = 5205000: loss = 4.932915210723877\n",
      "step = 5205000: Average Return = 3.6500000953674316\n",
      "step = 5205200: loss = 3.348191499710083\n",
      "step = 5205400: loss = 4.672546863555908\n",
      "step = 5205600: loss = 5.307502269744873\n",
      "step = 5205800: loss = 3.0549159049987793\n",
      "step = 5206000: loss = 5.8435845375061035\n",
      "step = 5206200: loss = 4.055149555206299\n",
      "step = 5206400: loss = 4.240538120269775\n",
      "step = 5206600: loss = 3.132099151611328\n",
      "step = 5206800: loss = 3.7521607875823975\n",
      "step = 5207000: loss = 3.626225709915161\n",
      "step = 5207200: loss = 3.0947234630584717\n",
      "step = 5207400: loss = 4.350209712982178\n",
      "step = 5207600: loss = 4.363368511199951\n",
      "step = 5207800: loss = 3.7511417865753174\n",
      "step = 5208000: loss = 3.1505086421966553\n",
      "step = 5208200: loss = 4.44389009475708\n",
      "step = 5208400: loss = 3.1227245330810547\n",
      "step = 5208600: loss = 2.955937385559082\n",
      "step = 5208800: loss = 3.764009714126587\n",
      "step = 5209000: loss = 3.189711570739746\n",
      "step = 5209200: loss = 4.151077747344971\n",
      "step = 5209400: loss = 3.72940731048584\n",
      "step = 5209600: loss = 4.966547966003418\n",
      "step = 5209800: loss = 4.225762367248535\n",
      "step = 5210000: loss = 2.090350866317749\n",
      "step = 5210000: Average Return = 3.9000000953674316\n",
      "step = 5210200: loss = 3.493025541305542\n",
      "step = 5210400: loss = 3.5925114154815674\n",
      "step = 5210600: loss = 4.30054235458374\n",
      "step = 5210800: loss = 4.747970104217529\n",
      "step = 5211000: loss = 3.3810110092163086\n",
      "step = 5211200: loss = 3.790961503982544\n",
      "step = 5211400: loss = 5.770791053771973\n",
      "step = 5211600: loss = 4.2117462158203125\n",
      "step = 5211800: loss = 3.523790121078491\n",
      "step = 5212000: loss = 3.8291544914245605\n",
      "step = 5212200: loss = 3.82173752784729\n",
      "step = 5212400: loss = 3.627797842025757\n",
      "step = 5212600: loss = 3.7051260471343994\n",
      "step = 5212800: loss = 2.4996438026428223\n",
      "step = 5213000: loss = 3.816312074661255\n",
      "step = 5213200: loss = 3.13578724861145\n",
      "step = 5213400: loss = 4.022515296936035\n",
      "step = 5213600: loss = 4.446619033813477\n",
      "step = 5213800: loss = 3.6665544509887695\n",
      "step = 5214000: loss = 3.804429531097412\n",
      "step = 5214200: loss = 4.973912715911865\n",
      "step = 5214400: loss = 4.405769348144531\n",
      "step = 5214600: loss = 4.103895664215088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 5214800: loss = 3.8330559730529785\n",
      "step = 5215000: loss = 4.795876979827881\n",
      "step = 5215000: Average Return = 2.299999952316284\n",
      "step = 5215200: loss = 2.9874627590179443\n",
      "step = 5215400: loss = 3.4506847858428955\n",
      "step = 5215600: loss = 3.226691722869873\n",
      "step = 5215800: loss = 5.1098151206970215\n",
      "step = 5216000: loss = 3.447432518005371\n",
      "step = 5216200: loss = 3.5754525661468506\n",
      "step = 5216400: loss = 4.472060680389404\n",
      "step = 5216600: loss = 3.7787671089172363\n",
      "step = 5216800: loss = 5.269227981567383\n",
      "step = 5217000: loss = 4.0594048500061035\n",
      "step = 5217200: loss = 2.737380266189575\n",
      "step = 5217400: loss = 2.6232409477233887\n",
      "step = 5217600: loss = 3.596181631088257\n",
      "step = 5217800: loss = 4.003772258758545\n",
      "step = 5218000: loss = 3.995577335357666\n",
      "step = 5218200: loss = 4.493158340454102\n",
      "step = 5218400: loss = 3.4522526264190674\n",
      "step = 5218600: loss = 3.8879034519195557\n",
      "step = 5218800: loss = 4.04446268081665\n",
      "step = 5219000: loss = 4.2798590660095215\n",
      "step = 5219200: loss = 3.911301374435425\n",
      "step = 5219400: loss = 3.284421682357788\n",
      "step = 5219600: loss = 2.694434404373169\n",
      "step = 5219800: loss = 3.958254814147949\n",
      "step = 5220000: loss = 2.533921957015991\n",
      "step = 5220000: Average Return = 3.0999999046325684\n",
      "step = 5220200: loss = 3.050971031188965\n",
      "step = 5220400: loss = 3.7217061519622803\n",
      "step = 5220600: loss = 3.8161680698394775\n",
      "step = 5220800: loss = 3.44152569770813\n",
      "step = 5221000: loss = 4.324559688568115\n",
      "step = 5221200: loss = 4.886990070343018\n",
      "step = 5221400: loss = 3.2747280597686768\n",
      "step = 5221600: loss = 3.010422945022583\n",
      "step = 5221800: loss = 2.8198845386505127\n",
      "step = 5222000: loss = 3.4595696926116943\n",
      "step = 5222200: loss = 2.6495048999786377\n",
      "step = 5222400: loss = 3.102518320083618\n",
      "step = 5222600: loss = 2.380185127258301\n",
      "step = 5222800: loss = 3.9309475421905518\n",
      "step = 5223000: loss = 3.2567138671875\n",
      "step = 5223200: loss = 3.179905891418457\n",
      "step = 5223400: loss = 3.7719886302948\n",
      "step = 5223600: loss = 5.593837738037109\n",
      "step = 5223800: loss = 3.7798380851745605\n",
      "step = 5224000: loss = 3.940762519836426\n",
      "step = 5224200: loss = 3.737460136413574\n",
      "step = 5224400: loss = 3.129574775695801\n",
      "step = 5224600: loss = 3.0629122257232666\n",
      "step = 5224800: loss = 2.989518404006958\n",
      "step = 5225000: loss = 3.4921789169311523\n",
      "step = 5225000: Average Return = 3.0999999046325684\n",
      "step = 5225200: loss = 4.206603527069092\n",
      "step = 5225400: loss = 2.945216417312622\n",
      "step = 5225600: loss = 4.084207534790039\n",
      "step = 5225800: loss = 3.5808827877044678\n",
      "step = 5226000: loss = 3.4656126499176025\n",
      "step = 5226200: loss = 3.1676037311553955\n",
      "step = 5226400: loss = 2.863189697265625\n",
      "step = 5226600: loss = 3.323873281478882\n",
      "step = 5226800: loss = 5.053977012634277\n",
      "step = 5227000: loss = 3.4822752475738525\n",
      "step = 5227200: loss = 3.2254366874694824\n",
      "step = 5227400: loss = 4.342762470245361\n",
      "step = 5227600: loss = 4.684586524963379\n",
      "step = 5227800: loss = 3.477480888366699\n",
      "step = 5228000: loss = 5.711559295654297\n",
      "step = 5228200: loss = 2.468334674835205\n",
      "step = 5228400: loss = 3.80487060546875\n",
      "step = 5228600: loss = 3.2836406230926514\n",
      "step = 5228800: loss = 3.206888437271118\n",
      "step = 5229000: loss = 4.324528217315674\n",
      "step = 5229200: loss = 2.8981823921203613\n",
      "step = 5229400: loss = 3.07745361328125\n",
      "step = 5229600: loss = 3.829193592071533\n",
      "step = 5229800: loss = 4.160778522491455\n",
      "step = 5230000: loss = 4.957248210906982\n",
      "step = 5230000: Average Return = 4.099999904632568\n",
      "step = 5230200: loss = 3.598487138748169\n",
      "step = 5230400: loss = 2.8291261196136475\n",
      "step = 5230600: loss = 4.0448760986328125\n",
      "step = 5230800: loss = 3.842867374420166\n",
      "step = 5231000: loss = 3.4443047046661377\n",
      "step = 5231200: loss = 4.456717014312744\n",
      "step = 5231400: loss = 4.58237886428833\n",
      "step = 5231600: loss = 2.782733201980591\n",
      "step = 5231800: loss = 3.996068239212036\n",
      "step = 5232000: loss = 4.984753131866455\n",
      "step = 5232200: loss = 3.160382032394409\n",
      "step = 5232400: loss = 3.283604145050049\n",
      "step = 5232600: loss = 3.21398663520813\n",
      "step = 5232800: loss = 4.25511360168457\n",
      "step = 5233000: loss = 2.7977664470672607\n",
      "step = 5233200: loss = 3.801661252975464\n",
      "step = 5233400: loss = 3.7062838077545166\n",
      "step = 5233600: loss = 3.096487283706665\n",
      "step = 5233800: loss = 3.8098161220550537\n",
      "step = 5234000: loss = 3.5596961975097656\n",
      "step = 5234200: loss = 4.73942756652832\n",
      "step = 5234400: loss = 4.294510841369629\n",
      "step = 5234600: loss = 4.343869686126709\n",
      "step = 5234800: loss = 4.412659645080566\n",
      "step = 5235000: loss = 3.403806447982788\n",
      "step = 5235000: Average Return = 2.8499999046325684\n",
      "step = 5235200: loss = 3.2194128036499023\n",
      "step = 5235400: loss = 5.063837051391602\n",
      "step = 5235600: loss = 3.740534543991089\n",
      "step = 5235800: loss = 3.4337334632873535\n",
      "step = 5236000: loss = 3.502082347869873\n",
      "step = 5236200: loss = 4.721546649932861\n",
      "step = 5236400: loss = 3.442732095718384\n",
      "step = 5236600: loss = 4.644092082977295\n",
      "step = 5236800: loss = 3.279036283493042\n",
      "step = 5237000: loss = 4.449090957641602\n",
      "step = 5237200: loss = 3.275592565536499\n",
      "step = 5237400: loss = 4.039754390716553\n",
      "step = 5237600: loss = 3.6904563903808594\n",
      "step = 5237800: loss = 4.785951614379883\n",
      "step = 5238000: loss = 3.2798173427581787\n",
      "step = 5238200: loss = 4.007129192352295\n",
      "step = 5238400: loss = 4.017626762390137\n",
      "step = 5238600: loss = 4.190338611602783\n",
      "step = 5238800: loss = 3.2560088634490967\n",
      "step = 5239000: loss = 3.7417898178100586\n",
      "step = 5239200: loss = 3.1538538932800293\n",
      "step = 5239400: loss = 3.9133474826812744\n",
      "step = 5239600: loss = 3.7996325492858887\n",
      "step = 5239800: loss = 3.732255220413208\n",
      "step = 5240000: loss = 4.940789222717285\n",
      "step = 5240000: Average Return = 3.200000047683716\n",
      "step = 5240200: loss = 3.2336573600769043\n",
      "step = 5240400: loss = 3.756953239440918\n",
      "step = 5240600: loss = 2.2954928874969482\n",
      "step = 5240800: loss = 3.2951836585998535\n",
      "step = 5241000: loss = 4.247745990753174\n",
      "step = 5241200: loss = 3.732412576675415\n",
      "step = 5241400: loss = 4.496464252471924\n",
      "step = 5241600: loss = 4.14302921295166\n",
      "step = 5241800: loss = 4.263314247131348\n",
      "step = 5242000: loss = 3.3419439792633057\n",
      "step = 5242200: loss = 5.067798137664795\n",
      "step = 5242400: loss = 3.234308958053589\n",
      "step = 5242600: loss = 5.085549831390381\n",
      "step = 5242800: loss = 3.9534003734588623\n",
      "step = 5243000: loss = 4.276813983917236\n",
      "step = 5243200: loss = 3.766929864883423\n",
      "step = 5243400: loss = 3.24979567527771\n",
      "step = 5243600: loss = 3.8483359813690186\n",
      "step = 5243800: loss = 4.160493850708008\n",
      "step = 5244000: loss = 3.9613499641418457\n",
      "step = 5244200: loss = 5.23674201965332\n",
      "step = 5244400: loss = 5.822526931762695\n",
      "step = 5244600: loss = 3.513533353805542\n",
      "step = 5244800: loss = 2.8864080905914307\n",
      "step = 5245000: loss = 3.4222261905670166\n",
      "step = 5245000: Average Return = 5.150000095367432\n",
      "step = 5245200: loss = 4.016119480133057\n",
      "step = 5245400: loss = 2.278984785079956\n",
      "step = 5245600: loss = 4.3887939453125\n",
      "step = 5245800: loss = 2.323402166366577\n",
      "step = 5246000: loss = 3.50063419342041\n",
      "step = 5246200: loss = 4.588639259338379\n",
      "step = 5246400: loss = 3.029111862182617\n",
      "step = 5246600: loss = 3.8268182277679443\n",
      "step = 5246800: loss = 4.191842555999756\n",
      "step = 5247000: loss = 4.92678689956665\n",
      "step = 5247200: loss = 3.7899279594421387\n",
      "step = 5247400: loss = 2.163367509841919\n",
      "step = 5247600: loss = 4.468574047088623\n",
      "step = 5247800: loss = 2.6741716861724854\n",
      "step = 5248000: loss = 3.8271424770355225\n",
      "step = 5248200: loss = 4.0483784675598145\n",
      "step = 5248400: loss = 3.1788783073425293\n",
      "step = 5248600: loss = 2.9767448902130127\n",
      "step = 5248800: loss = 4.35040283203125\n",
      "step = 5249000: loss = 3.3558177947998047\n",
      "step = 5249200: loss = 3.424595355987549\n",
      "step = 5249400: loss = 5.076235294342041\n",
      "step = 5249600: loss = 3.706829786300659\n",
      "step = 5249800: loss = 3.6444344520568848\n",
      "step = 5250000: loss = 3.4623498916625977\n",
      "step = 5250000: Average Return = 2.9000000953674316\n",
      "step = 5250200: loss = 3.492075204849243\n",
      "step = 5250400: loss = 4.465982437133789\n",
      "step = 5250600: loss = 5.189538478851318\n",
      "step = 5250800: loss = 4.092894077301025\n",
      "step = 5251000: loss = 3.21187424659729\n",
      "step = 5251200: loss = 5.041586875915527\n",
      "step = 5251400: loss = 3.768890857696533\n",
      "step = 5251600: loss = 2.8820464611053467\n",
      "step = 5251800: loss = 4.015163898468018\n",
      "step = 5252000: loss = 3.071484327316284\n",
      "step = 5252200: loss = 5.125457763671875\n",
      "step = 5252400: loss = 3.2955267429351807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 5252600: loss = 3.97361421585083\n",
      "step = 5252800: loss = 4.11555290222168\n",
      "step = 5253000: loss = 4.634034156799316\n",
      "step = 5253200: loss = 3.8367393016815186\n",
      "step = 5253400: loss = 2.7216784954071045\n",
      "step = 5253600: loss = 5.0927510261535645\n",
      "step = 5253800: loss = 3.2226383686065674\n",
      "step = 5254000: loss = 3.5931222438812256\n",
      "step = 5254200: loss = 2.7205700874328613\n",
      "step = 5254400: loss = 4.009316921234131\n",
      "step = 5254600: loss = 2.915921211242676\n",
      "step = 5254800: loss = 3.844133138656616\n",
      "step = 5255000: loss = 2.3122427463531494\n",
      "step = 5255000: Average Return = 4.25\n",
      "step = 5255200: loss = 4.108933925628662\n",
      "step = 5255400: loss = 4.246535778045654\n",
      "step = 5255600: loss = 3.3407788276672363\n",
      "step = 5255800: loss = 3.7109718322753906\n",
      "step = 5256000: loss = 3.6880481243133545\n",
      "step = 5256200: loss = 2.4836056232452393\n",
      "step = 5256400: loss = 3.716437816619873\n",
      "step = 5256600: loss = 5.0483245849609375\n",
      "step = 5256800: loss = 3.424738645553589\n",
      "step = 5257000: loss = 3.6986076831817627\n",
      "step = 5257200: loss = 3.2267189025878906\n",
      "step = 5257400: loss = 2.9132213592529297\n",
      "step = 5257600: loss = 2.839019775390625\n",
      "step = 5257800: loss = 4.313056468963623\n",
      "step = 5258000: loss = 3.812758684158325\n",
      "step = 5258200: loss = 3.406632661819458\n",
      "step = 5258400: loss = 4.068264484405518\n",
      "step = 5258600: loss = 3.614091157913208\n",
      "step = 5258800: loss = 3.008065700531006\n",
      "step = 5259000: loss = 3.305548906326294\n",
      "step = 5259200: loss = 3.3635263442993164\n",
      "step = 5259400: loss = 3.669973611831665\n",
      "step = 5259600: loss = 4.610515594482422\n",
      "step = 5259800: loss = 4.8024749755859375\n",
      "step = 5260000: loss = 3.393235921859741\n",
      "step = 5260000: Average Return = 5.650000095367432\n",
      "step = 5260200: loss = 5.617041110992432\n",
      "step = 5260400: loss = 3.68833065032959\n",
      "step = 5260600: loss = 4.701420783996582\n",
      "step = 5260800: loss = 3.1610372066497803\n",
      "step = 5261000: loss = 4.197507381439209\n",
      "step = 5261200: loss = 3.294095993041992\n",
      "step = 5261400: loss = 3.6151909828186035\n",
      "step = 5261600: loss = 2.7303781509399414\n",
      "step = 5261800: loss = 3.0674502849578857\n",
      "step = 5262000: loss = 2.7761294841766357\n",
      "step = 5262200: loss = 3.579958438873291\n",
      "step = 5262400: loss = 3.5308821201324463\n",
      "step = 5262600: loss = 2.8327553272247314\n",
      "step = 5262800: loss = 3.3403828144073486\n",
      "step = 5263000: loss = 3.6850969791412354\n",
      "step = 5263200: loss = 3.6715145111083984\n",
      "step = 5263400: loss = 2.9905083179473877\n",
      "step = 5263600: loss = 3.6560990810394287\n",
      "step = 5263800: loss = 2.999876022338867\n",
      "step = 5264000: loss = 3.7130556106567383\n",
      "step = 5264200: loss = 3.5177531242370605\n",
      "step = 5264400: loss = 3.800386667251587\n",
      "step = 5264600: loss = 3.5190093517303467\n",
      "step = 5264800: loss = 2.904376268386841\n",
      "step = 5265000: loss = 5.415214538574219\n",
      "step = 5265000: Average Return = 2.200000047683716\n",
      "step = 5265200: loss = 3.0737569332122803\n",
      "step = 5265400: loss = 3.637364625930786\n",
      "step = 5265600: loss = 3.3944878578186035\n",
      "step = 5265800: loss = 3.50103759765625\n",
      "step = 5266000: loss = 3.5149755477905273\n",
      "step = 5266200: loss = 3.2524797916412354\n",
      "step = 5266400: loss = 2.561835765838623\n",
      "step = 5266600: loss = 5.0153117179870605\n",
      "step = 5266800: loss = 3.823101043701172\n",
      "step = 5267000: loss = 3.7882847785949707\n",
      "step = 5267200: loss = 2.05551815032959\n",
      "step = 5267400: loss = 3.8606202602386475\n",
      "step = 5267600: loss = 3.434922933578491\n",
      "step = 5267800: loss = 4.002042770385742\n",
      "step = 5268000: loss = 3.383000373840332\n",
      "step = 5268200: loss = 3.3919737339019775\n",
      "step = 5268400: loss = 3.824324369430542\n",
      "step = 5268600: loss = 3.3906071186065674\n",
      "step = 5268800: loss = 3.4885318279266357\n",
      "step = 5269000: loss = 4.269744873046875\n",
      "step = 5269200: loss = 3.294278383255005\n",
      "step = 5269400: loss = 4.461684703826904\n",
      "step = 5269600: loss = 4.531593322753906\n",
      "step = 5269800: loss = 4.235755443572998\n",
      "step = 5270000: loss = 3.641258955001831\n",
      "step = 5270000: Average Return = 2.9000000953674316\n",
      "step = 5270200: loss = 3.035400629043579\n",
      "step = 5270400: loss = 3.592435836791992\n",
      "step = 5270600: loss = 3.213979721069336\n",
      "step = 5270800: loss = 4.314218044281006\n",
      "step = 5271000: loss = 3.699486494064331\n",
      "step = 5271200: loss = 2.900258779525757\n",
      "step = 5271400: loss = 4.007391452789307\n",
      "step = 5271600: loss = 3.8930773735046387\n",
      "step = 5271800: loss = 3.0388762950897217\n",
      "step = 5272000: loss = 4.548281192779541\n",
      "step = 5272200: loss = 3.5204670429229736\n",
      "step = 5272400: loss = 4.999669075012207\n",
      "step = 5272600: loss = 3.9711244106292725\n",
      "step = 5272800: loss = 4.2264180183410645\n",
      "step = 5273000: loss = 4.57017183303833\n",
      "step = 5273200: loss = 4.8735504150390625\n",
      "step = 5273400: loss = 2.3811471462249756\n",
      "step = 5273600: loss = 3.6773695945739746\n",
      "step = 5273800: loss = 3.9403209686279297\n",
      "step = 5274000: loss = 3.485586166381836\n",
      "step = 5274200: loss = 3.5280659198760986\n",
      "step = 5274400: loss = 5.223143100738525\n",
      "step = 5274600: loss = 5.449441909790039\n",
      "step = 5274800: loss = 2.8281946182250977\n",
      "step = 5275000: loss = 3.129686117172241\n",
      "step = 5275000: Average Return = 2.200000047683716\n",
      "step = 5275200: loss = 4.955325603485107\n",
      "step = 5275400: loss = 3.7076714038848877\n",
      "step = 5275600: loss = 4.586458683013916\n",
      "step = 5275800: loss = 3.5147740840911865\n",
      "step = 5276000: loss = 3.2752511501312256\n",
      "step = 5276200: loss = 4.174334526062012\n",
      "step = 5276400: loss = 3.368007183074951\n",
      "step = 5276600: loss = 3.067034959793091\n",
      "step = 5276800: loss = 3.247361421585083\n",
      "step = 5277000: loss = 3.2278339862823486\n",
      "step = 5277200: loss = 4.186038017272949\n",
      "step = 5277400: loss = 3.3483104705810547\n",
      "step = 5277600: loss = 3.6141788959503174\n",
      "step = 5277800: loss = 3.6910998821258545\n",
      "step = 5278000: loss = 3.6463000774383545\n",
      "step = 5278200: loss = 3.817513942718506\n",
      "step = 5278400: loss = 2.604449510574341\n",
      "step = 5278600: loss = 4.124082565307617\n",
      "step = 5278800: loss = 3.844898223876953\n",
      "step = 5279000: loss = 4.987915992736816\n",
      "step = 5279200: loss = 3.024479627609253\n",
      "step = 5279400: loss = 3.0382463932037354\n",
      "step = 5279600: loss = 3.749368190765381\n",
      "step = 5279800: loss = 4.315828323364258\n",
      "step = 5280000: loss = 2.9901013374328613\n",
      "step = 5280000: Average Return = 4.5\n",
      "step = 5280200: loss = 4.122140407562256\n",
      "step = 5280400: loss = 5.214259147644043\n",
      "step = 5280600: loss = 3.414771556854248\n",
      "step = 5280800: loss = 4.800693988800049\n",
      "step = 5281000: loss = 3.7158708572387695\n",
      "step = 5281200: loss = 4.51595401763916\n",
      "step = 5281400: loss = 4.127879619598389\n",
      "step = 5281600: loss = 2.3773036003112793\n",
      "step = 5281800: loss = 2.7532918453216553\n",
      "step = 5282000: loss = 5.02581262588501\n",
      "step = 5282200: loss = 3.046238422393799\n",
      "step = 5282400: loss = 4.1379828453063965\n",
      "step = 5282600: loss = 4.040863990783691\n",
      "step = 5282800: loss = 3.6220085620880127\n",
      "step = 5283000: loss = 3.5608646869659424\n",
      "step = 5283200: loss = 3.0683412551879883\n",
      "step = 5283400: loss = 4.1490278244018555\n",
      "step = 5283600: loss = 4.239027500152588\n",
      "step = 5283800: loss = 3.98433256149292\n",
      "step = 5284000: loss = 4.641276836395264\n",
      "step = 5284200: loss = 2.615309476852417\n",
      "step = 5284400: loss = 4.113258361816406\n",
      "step = 5284600: loss = 4.926512718200684\n",
      "step = 5284800: loss = 3.3696534633636475\n",
      "step = 5285000: loss = 3.365995168685913\n",
      "step = 5285000: Average Return = 2.9000000953674316\n",
      "step = 5285200: loss = 3.7263870239257812\n",
      "step = 5285400: loss = 2.982042074203491\n",
      "step = 5285600: loss = 2.774517059326172\n",
      "step = 5285800: loss = 4.79606819152832\n",
      "step = 5286000: loss = 3.270479917526245\n",
      "step = 5286200: loss = 3.2835686206817627\n",
      "step = 5286400: loss = 3.734778642654419\n",
      "step = 5286600: loss = 3.448469877243042\n",
      "step = 5286800: loss = 3.8276078701019287\n",
      "step = 5287000: loss = 3.5007216930389404\n",
      "step = 5287200: loss = 5.052879333496094\n",
      "step = 5287400: loss = 4.119949817657471\n",
      "step = 5287600: loss = 3.970400333404541\n",
      "step = 5287800: loss = 3.0588464736938477\n",
      "step = 5288000: loss = 5.05232572555542\n",
      "step = 5288200: loss = 5.230763912200928\n",
      "step = 5288400: loss = 3.2440502643585205\n",
      "step = 5288600: loss = 4.290273189544678\n",
      "step = 5288800: loss = 3.035935401916504\n",
      "step = 5289000: loss = 4.232955455780029\n",
      "step = 5289200: loss = 3.6651415824890137\n",
      "step = 5289400: loss = 3.598423957824707\n",
      "step = 5289600: loss = 4.077198505401611\n",
      "step = 5289800: loss = 3.4944207668304443\n",
      "step = 5290000: loss = 2.9871859550476074\n",
      "step = 5290000: Average Return = 3.700000047683716\n",
      "step = 5290200: loss = 4.095759391784668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 5290400: loss = 4.377599239349365\n",
      "step = 5290600: loss = 3.4959018230438232\n",
      "step = 5290800: loss = 3.207386016845703\n",
      "step = 5291000: loss = 3.278719425201416\n",
      "step = 5291200: loss = 4.399014949798584\n",
      "step = 5291400: loss = 3.2592873573303223\n",
      "step = 5291600: loss = 4.070048809051514\n",
      "step = 5291800: loss = 5.427054405212402\n",
      "step = 5292000: loss = 5.329145431518555\n",
      "step = 5292200: loss = 4.176764011383057\n",
      "step = 5292400: loss = 2.6870110034942627\n",
      "step = 5292600: loss = 4.597273349761963\n",
      "step = 5292800: loss = 4.384054183959961\n",
      "step = 5293000: loss = 4.012572765350342\n",
      "step = 5293200: loss = 4.316593647003174\n",
      "step = 5293400: loss = 4.074034214019775\n",
      "step = 5293600: loss = 5.068535804748535\n",
      "step = 5293800: loss = 3.407137393951416\n",
      "step = 5294000: loss = 4.872228145599365\n",
      "step = 5294200: loss = 4.234776020050049\n",
      "step = 5294400: loss = 5.400385856628418\n",
      "step = 5294600: loss = 3.622708559036255\n",
      "step = 5294800: loss = 3.5868780612945557\n",
      "step = 5295000: loss = 4.363556385040283\n",
      "step = 5295000: Average Return = 4.300000190734863\n",
      "step = 5295200: loss = 5.04506778717041\n",
      "step = 5295400: loss = 3.7557737827301025\n",
      "step = 5295600: loss = 4.347737789154053\n",
      "step = 5295800: loss = 4.336230754852295\n",
      "step = 5296000: loss = 3.876089334487915\n",
      "step = 5296200: loss = 3.4451744556427\n",
      "step = 5296400: loss = 4.088466644287109\n",
      "step = 5296600: loss = 4.064664363861084\n",
      "step = 5296800: loss = 4.787503719329834\n",
      "step = 5297000: loss = 4.0767502784729\n",
      "step = 5297200: loss = 2.984858274459839\n",
      "step = 5297400: loss = 3.6130383014678955\n",
      "step = 5297600: loss = 4.273106575012207\n",
      "step = 5297800: loss = 4.385730266571045\n",
      "step = 5298000: loss = 2.838527202606201\n",
      "step = 5298200: loss = 4.562406063079834\n",
      "step = 5298400: loss = 2.856278896331787\n",
      "step = 5298600: loss = 5.3240766525268555\n",
      "step = 5298800: loss = 4.029481887817383\n",
      "step = 5299000: loss = 4.739506244659424\n",
      "step = 5299200: loss = 4.83247709274292\n",
      "step = 5299400: loss = 3.4498138427734375\n",
      "step = 5299600: loss = 4.174680709838867\n",
      "step = 5299800: loss = 3.8367247581481934\n",
      "step = 5300000: loss = 3.9531471729278564\n",
      "step = 5300000: Average Return = 2.549999952316284\n",
      "step = 5300200: loss = 4.256955623626709\n",
      "step = 5300400: loss = 2.8614726066589355\n",
      "step = 5300600: loss = 3.988687038421631\n",
      "step = 5300800: loss = 4.438193321228027\n",
      "step = 5301000: loss = 4.317762851715088\n",
      "step = 5301200: loss = 4.609797477722168\n",
      "step = 5301400: loss = 3.6470048427581787\n",
      "step = 5301600: loss = 3.8594915866851807\n",
      "step = 5301800: loss = 3.502664804458618\n",
      "step = 5302000: loss = 4.072422504425049\n",
      "step = 5302200: loss = 2.9883172512054443\n",
      "step = 5302400: loss = 4.9741034507751465\n",
      "step = 5302600: loss = 2.3048925399780273\n",
      "step = 5302800: loss = 2.9710159301757812\n",
      "step = 5303000: loss = 3.6784772872924805\n",
      "step = 5303200: loss = 3.7489540576934814\n",
      "step = 5303400: loss = 4.22252082824707\n",
      "step = 5303600: loss = 3.754443883895874\n",
      "step = 5303800: loss = 3.57743763923645\n",
      "step = 5304000: loss = 3.0585949420928955\n",
      "step = 5304200: loss = 4.85099458694458\n",
      "step = 5304400: loss = 4.321183204650879\n",
      "step = 5304600: loss = 3.5880627632141113\n",
      "step = 5304800: loss = 4.2450056076049805\n",
      "step = 5305000: loss = 3.5119500160217285\n",
      "step = 5305000: Average Return = 3.549999952316284\n",
      "step = 5305200: loss = 3.4161508083343506\n",
      "step = 5305400: loss = 5.350974082946777\n",
      "step = 5305600: loss = 4.104677200317383\n",
      "step = 5305800: loss = 3.034381151199341\n",
      "step = 5306000: loss = 2.741574764251709\n",
      "step = 5306200: loss = 3.816775321960449\n",
      "step = 5306400: loss = 3.502312660217285\n",
      "step = 5306600: loss = 4.002377033233643\n",
      "step = 5306800: loss = 4.458634376525879\n",
      "step = 5307000: loss = 4.359119892120361\n",
      "step = 5307200: loss = 3.9247779846191406\n",
      "step = 5307400: loss = 5.0481438636779785\n",
      "step = 5307600: loss = 3.5866472721099854\n",
      "step = 5307800: loss = 2.8979744911193848\n",
      "step = 5308000: loss = 4.970314979553223\n",
      "step = 5308200: loss = 3.386942148208618\n",
      "step = 5308400: loss = 4.515843868255615\n",
      "step = 5308600: loss = 3.764688730239868\n",
      "step = 5308800: loss = 3.095379590988159\n",
      "step = 5309000: loss = 3.840880870819092\n",
      "step = 5309200: loss = 3.681209087371826\n",
      "step = 5309400: loss = 4.206538200378418\n",
      "step = 5309600: loss = 3.533567190170288\n",
      "step = 5309800: loss = 3.3921279907226562\n",
      "step = 5310000: loss = 4.136258602142334\n",
      "step = 5310000: Average Return = 3.6500000953674316\n",
      "step = 5310200: loss = 3.40974760055542\n",
      "step = 5310400: loss = 3.3533577919006348\n",
      "step = 5310600: loss = 4.312722682952881\n",
      "step = 5310800: loss = 3.751856803894043\n",
      "step = 5311000: loss = 3.6821157932281494\n",
      "step = 5311200: loss = 4.273877143859863\n",
      "step = 5311400: loss = 3.4546215534210205\n",
      "step = 5311600: loss = 3.37890625\n",
      "step = 5311800: loss = 4.649343013763428\n",
      "step = 5312000: loss = 3.1849734783172607\n",
      "step = 5312200: loss = 2.6820244789123535\n",
      "step = 5312400: loss = 3.7060415744781494\n",
      "step = 5312600: loss = 3.8376872539520264\n",
      "step = 5312800: loss = 4.296597957611084\n",
      "step = 5313000: loss = 4.268701076507568\n",
      "step = 5313200: loss = 3.918985605239868\n",
      "step = 5313400: loss = 3.840963363647461\n",
      "step = 5313600: loss = 4.441303730010986\n",
      "step = 5313800: loss = 3.2625646591186523\n",
      "step = 5314000: loss = 2.893798351287842\n",
      "step = 5314200: loss = 3.2447509765625\n",
      "step = 5314400: loss = 3.0088276863098145\n",
      "step = 5314600: loss = 3.463038444519043\n",
      "step = 5314800: loss = 2.9454379081726074\n",
      "step = 5315000: loss = 3.8371336460113525\n",
      "step = 5315000: Average Return = 2.8499999046325684\n",
      "step = 5315200: loss = 2.7904372215270996\n",
      "step = 5315400: loss = 3.2271087169647217\n",
      "step = 5315600: loss = 4.335624694824219\n",
      "step = 5315800: loss = 3.6237587928771973\n",
      "step = 5316000: loss = 4.269319534301758\n",
      "step = 5316200: loss = 4.3702592849731445\n",
      "step = 5316400: loss = 4.269522190093994\n",
      "step = 5316600: loss = 4.405655384063721\n",
      "step = 5316800: loss = 4.4353485107421875\n",
      "step = 5317000: loss = 4.932445526123047\n",
      "step = 5317200: loss = 3.662205219268799\n",
      "step = 5317400: loss = 3.9022600650787354\n",
      "step = 5317600: loss = 4.114615440368652\n",
      "step = 5317800: loss = 3.0347683429718018\n",
      "step = 5318000: loss = 3.7972450256347656\n",
      "step = 5318200: loss = 4.781781196594238\n",
      "step = 5318400: loss = 3.518571615219116\n",
      "step = 5318600: loss = 3.2301831245422363\n",
      "step = 5318800: loss = 3.393763303756714\n",
      "step = 5319000: loss = 4.0855488777160645\n",
      "step = 5319200: loss = 6.114962577819824\n",
      "step = 5319400: loss = 5.417762279510498\n",
      "step = 5319600: loss = 4.361668109893799\n",
      "step = 5319800: loss = 4.369253158569336\n",
      "step = 5320000: loss = 3.031470537185669\n",
      "step = 5320000: Average Return = 4.050000190734863\n",
      "step = 5320200: loss = 2.6202054023742676\n",
      "step = 5320400: loss = 4.339636325836182\n",
      "step = 5320600: loss = 3.736780881881714\n",
      "step = 5320800: loss = 3.1045022010803223\n",
      "step = 5321000: loss = 3.76902437210083\n",
      "step = 5321200: loss = 2.947658061981201\n",
      "step = 5321400: loss = 3.290663480758667\n",
      "step = 5321600: loss = 3.6761326789855957\n",
      "step = 5321800: loss = 3.835840940475464\n",
      "step = 5322000: loss = 3.4861249923706055\n",
      "step = 5322200: loss = 3.9077308177948\n",
      "step = 5322400: loss = 4.6518473625183105\n",
      "step = 5322600: loss = 4.113288402557373\n",
      "step = 5322800: loss = 4.1259846687316895\n",
      "step = 5323000: loss = 3.99938702583313\n",
      "step = 5323200: loss = 4.1424455642700195\n",
      "step = 5323400: loss = 3.100403308868408\n",
      "step = 5323600: loss = 4.679193496704102\n",
      "step = 5323800: loss = 4.075263977050781\n",
      "step = 5324000: loss = 3.65360689163208\n",
      "step = 5324200: loss = 3.390557289123535\n",
      "step = 5324400: loss = 3.9804258346557617\n",
      "step = 5324600: loss = 2.578247547149658\n",
      "step = 5324800: loss = 3.8456358909606934\n",
      "step = 5325000: loss = 4.119075775146484\n",
      "step = 5325000: Average Return = 4.0\n",
      "step = 5325200: loss = 2.8662514686584473\n",
      "step = 5325400: loss = 3.89040207862854\n",
      "step = 5325600: loss = 1.5897387266159058\n",
      "step = 5325800: loss = 3.65691876411438\n",
      "step = 5326000: loss = 4.885364055633545\n",
      "step = 5326200: loss = 4.6956353187561035\n",
      "step = 5326400: loss = 2.29770565032959\n",
      "step = 5326600: loss = 3.4549028873443604\n",
      "step = 5326800: loss = 4.21077299118042\n",
      "step = 5327000: loss = 4.891306400299072\n",
      "step = 5327200: loss = 4.798917293548584\n",
      "step = 5327400: loss = 2.9501750469207764\n",
      "step = 5327600: loss = 4.291626930236816\n",
      "step = 5327800: loss = 4.128376483917236\n",
      "step = 5328000: loss = 4.971101760864258\n",
      "step = 5328200: loss = 4.081405162811279\n",
      "step = 5328400: loss = 3.066598415374756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 5328600: loss = 3.8903110027313232\n",
      "step = 5328800: loss = 3.975008487701416\n",
      "step = 5329000: loss = 4.194693088531494\n",
      "step = 5329200: loss = 4.011086463928223\n",
      "step = 5329400: loss = 3.7514610290527344\n",
      "step = 5329600: loss = 4.371150493621826\n",
      "step = 5329800: loss = 4.062038421630859\n",
      "step = 5330000: loss = 3.65496563911438\n",
      "step = 5330000: Average Return = 2.0999999046325684\n",
      "step = 5330200: loss = 3.3508317470550537\n",
      "step = 5330400: loss = 4.225661754608154\n",
      "step = 5330600: loss = 2.891974925994873\n",
      "step = 5330800: loss = 4.742306232452393\n",
      "step = 5331000: loss = 4.530898571014404\n",
      "step = 5331200: loss = 2.5117130279541016\n",
      "step = 5331400: loss = 3.528160572052002\n",
      "step = 5331600: loss = 4.573582172393799\n",
      "step = 5331800: loss = 3.8822038173675537\n",
      "step = 5332000: loss = 3.27573823928833\n",
      "step = 5332200: loss = 5.653420925140381\n",
      "step = 5332400: loss = 3.449007749557495\n",
      "step = 5332600: loss = 4.047481536865234\n",
      "step = 5332800: loss = 4.2555975914001465\n",
      "step = 5333000: loss = 3.599644660949707\n",
      "step = 5333200: loss = 4.78192138671875\n",
      "step = 5333400: loss = 5.309021949768066\n",
      "step = 5333600: loss = 4.503769874572754\n",
      "step = 5333800: loss = 3.17215633392334\n",
      "step = 5334000: loss = 5.366567134857178\n",
      "step = 5334200: loss = 4.734950065612793\n",
      "step = 5334400: loss = 2.9052515029907227\n",
      "step = 5334600: loss = 4.343710422515869\n",
      "step = 5334800: loss = 4.62463903427124\n",
      "step = 5335000: loss = 4.193124294281006\n",
      "step = 5335000: Average Return = 2.75\n",
      "step = 5335200: loss = 4.036628723144531\n",
      "step = 5335400: loss = 3.97048020362854\n",
      "step = 5335600: loss = 4.367240905761719\n",
      "step = 5335800: loss = 3.9300100803375244\n",
      "step = 5336000: loss = 4.677996635437012\n",
      "step = 5336200: loss = 3.9854249954223633\n",
      "step = 5336400: loss = 3.4350781440734863\n",
      "step = 5336600: loss = 4.390434265136719\n",
      "step = 5336800: loss = 4.786811828613281\n",
      "step = 5337000: loss = 4.269400596618652\n",
      "step = 5337200: loss = 4.461353778839111\n",
      "step = 5337400: loss = 3.2580809593200684\n",
      "step = 5337600: loss = 3.292513370513916\n",
      "step = 5337800: loss = 4.883821487426758\n",
      "step = 5338000: loss = 3.2142906188964844\n",
      "step = 5338200: loss = 3.9266679286956787\n",
      "step = 5338400: loss = 3.0072503089904785\n",
      "step = 5338600: loss = 4.809971809387207\n",
      "step = 5338800: loss = 3.542840003967285\n",
      "step = 5339000: loss = 4.738399505615234\n",
      "step = 5339200: loss = 3.158783435821533\n",
      "step = 5339400: loss = 4.276992321014404\n",
      "step = 5339600: loss = 3.1906120777130127\n",
      "step = 5339800: loss = 3.9256560802459717\n",
      "step = 5340000: loss = 2.41422700881958\n",
      "step = 5340000: Average Return = 4.949999809265137\n",
      "step = 5340200: loss = 3.718905448913574\n",
      "step = 5340400: loss = 4.76149845123291\n",
      "step = 5340600: loss = 4.389620780944824\n",
      "step = 5340800: loss = 2.2078933715820312\n",
      "step = 5341000: loss = 3.27795672416687\n",
      "step = 5341200: loss = 1.912746548652649\n",
      "step = 5341400: loss = 3.299633741378784\n",
      "step = 5341600: loss = 5.40998649597168\n",
      "step = 5341800: loss = 4.50927734375\n",
      "step = 5342000: loss = 2.8009774684906006\n",
      "step = 5342200: loss = 4.443737506866455\n",
      "step = 5342400: loss = 4.390030860900879\n",
      "step = 5342600: loss = 2.550023078918457\n",
      "step = 5342800: loss = 4.075906753540039\n",
      "step = 5343000: loss = 3.7615787982940674\n",
      "step = 5343200: loss = 2.9612317085266113\n",
      "step = 5343400: loss = 4.48663854598999\n",
      "step = 5343600: loss = 3.234980583190918\n",
      "step = 5343800: loss = 3.615874767303467\n",
      "step = 5344000: loss = 3.3221216201782227\n",
      "step = 5344200: loss = 3.4878740310668945\n",
      "step = 5344400: loss = 3.865506410598755\n",
      "step = 5344600: loss = 4.149418830871582\n",
      "step = 5344800: loss = 2.577615261077881\n",
      "step = 5345000: loss = 2.706429958343506\n",
      "step = 5345000: Average Return = 3.299999952316284\n",
      "step = 5345200: loss = 4.471875190734863\n",
      "step = 5345400: loss = 2.423067092895508\n",
      "step = 5345600: loss = 3.621685743331909\n",
      "step = 5345800: loss = 3.9517998695373535\n",
      "step = 5346000: loss = 2.9301981925964355\n",
      "step = 5346200: loss = 3.848385810852051\n",
      "step = 5346400: loss = 3.50982403755188\n",
      "step = 5346600: loss = 4.083073139190674\n",
      "step = 5346800: loss = 3.7284533977508545\n",
      "step = 5347000: loss = 4.5830278396606445\n",
      "step = 5347200: loss = 4.074854850769043\n",
      "step = 5347400: loss = 2.484163761138916\n",
      "step = 5347600: loss = 3.6393842697143555\n",
      "step = 5347800: loss = 3.3869175910949707\n",
      "step = 5348000: loss = 3.932241201400757\n",
      "step = 5348200: loss = 3.361753463745117\n",
      "step = 5348400: loss = 3.9053122997283936\n",
      "step = 5348600: loss = 4.809776306152344\n",
      "step = 5348800: loss = 3.665322780609131\n",
      "step = 5349000: loss = 3.4765095710754395\n",
      "step = 5349200: loss = 4.143916130065918\n",
      "step = 5349400: loss = 3.1836650371551514\n",
      "step = 5349600: loss = 3.873897075653076\n",
      "step = 5349800: loss = 4.801732063293457\n",
      "step = 5350000: loss = 3.3871452808380127\n",
      "step = 5350000: Average Return = 1.75\n",
      "step = 5350200: loss = 4.500924587249756\n",
      "step = 5350400: loss = 3.9779775142669678\n",
      "step = 5350600: loss = 3.665985584259033\n",
      "step = 5350800: loss = 4.15696382522583\n",
      "step = 5351000: loss = 4.004323482513428\n",
      "step = 5351200: loss = 3.1085119247436523\n",
      "step = 5351400: loss = 3.8547379970550537\n",
      "step = 5351600: loss = 4.418651580810547\n",
      "step = 5351800: loss = 3.144584894180298\n",
      "step = 5352000: loss = 4.582810401916504\n",
      "step = 5352200: loss = 3.8669042587280273\n",
      "step = 5352400: loss = 3.4197380542755127\n",
      "step = 5352600: loss = 4.108131408691406\n",
      "step = 5352800: loss = 4.422701835632324\n",
      "step = 5353000: loss = 3.8498711585998535\n",
      "step = 5353200: loss = 4.047732353210449\n",
      "step = 5353400: loss = 4.604781627655029\n",
      "step = 5353600: loss = 3.1780035495758057\n",
      "step = 5353800: loss = 4.233187675476074\n",
      "step = 5354000: loss = 3.417851448059082\n",
      "step = 5354200: loss = 4.205728054046631\n",
      "step = 5354400: loss = 2.9125120639801025\n",
      "step = 5354600: loss = 3.5859222412109375\n",
      "step = 5354800: loss = 4.6174750328063965\n",
      "step = 5355000: loss = 3.7299466133117676\n",
      "step = 5355000: Average Return = 2.6500000953674316\n",
      "step = 5355200: loss = 2.898423433303833\n",
      "step = 5355400: loss = 3.5166289806365967\n",
      "step = 5355600: loss = 3.228408098220825\n",
      "step = 5355800: loss = 4.3890228271484375\n",
      "step = 5356000: loss = 3.965240716934204\n",
      "step = 5356200: loss = 3.719776153564453\n",
      "step = 5356400: loss = 3.584533929824829\n",
      "step = 5356600: loss = 4.463627338409424\n",
      "step = 5356800: loss = 4.481860637664795\n",
      "step = 5357000: loss = 4.116917133331299\n",
      "step = 5357200: loss = 3.1997387409210205\n",
      "step = 5357400: loss = 4.395008563995361\n",
      "step = 5357600: loss = 4.251796245574951\n",
      "step = 5357800: loss = 5.25720739364624\n",
      "step = 5358000: loss = 3.2927818298339844\n",
      "step = 5358200: loss = 3.948930501937866\n",
      "step = 5358400: loss = 3.756425619125366\n",
      "step = 5358600: loss = 3.5737664699554443\n",
      "step = 5358800: loss = 4.591521739959717\n",
      "step = 5359000: loss = 4.69877290725708\n",
      "step = 5359200: loss = 3.3868958950042725\n",
      "step = 5359400: loss = 5.2588911056518555\n",
      "step = 5359600: loss = 4.188377380371094\n",
      "step = 5359800: loss = 3.1982686519622803\n",
      "step = 5360000: loss = 2.717358350753784\n",
      "step = 5360000: Average Return = 3.0\n",
      "step = 5360200: loss = 4.495086669921875\n",
      "step = 5360400: loss = 2.462350845336914\n",
      "step = 5360600: loss = 4.404783725738525\n",
      "step = 5360800: loss = 4.401886940002441\n",
      "step = 5361000: loss = 3.6399333477020264\n",
      "step = 5361200: loss = 2.640768051147461\n",
      "step = 5361400: loss = 3.7705259323120117\n",
      "step = 5361600: loss = 4.028167247772217\n",
      "step = 5361800: loss = 3.2118380069732666\n",
      "step = 5362000: loss = 2.910008430480957\n",
      "step = 5362200: loss = 4.090149879455566\n",
      "step = 5362400: loss = 3.433041572570801\n",
      "step = 5362600: loss = 3.1905434131622314\n",
      "step = 5362800: loss = 3.1992874145507812\n",
      "step = 5363000: loss = 2.4535651206970215\n",
      "step = 5363200: loss = 3.3655455112457275\n",
      "step = 5363400: loss = 3.0605430603027344\n",
      "step = 5363600: loss = 5.643428802490234\n",
      "step = 5363800: loss = 3.645179271697998\n",
      "step = 5364000: loss = 3.2704989910125732\n",
      "step = 5364200: loss = 4.013212203979492\n",
      "step = 5364400: loss = 4.115957736968994\n",
      "step = 5364600: loss = 3.340972900390625\n",
      "step = 5364800: loss = 3.57450270652771\n",
      "step = 5365000: loss = 3.484267234802246\n",
      "step = 5365000: Average Return = 3.5\n",
      "step = 5365200: loss = 3.2271203994750977\n",
      "step = 5365400: loss = 4.258391857147217\n",
      "step = 5365600: loss = 3.221874237060547\n",
      "step = 5365800: loss = 4.175546646118164\n",
      "step = 5366000: loss = 3.444795846939087\n",
      "step = 5366200: loss = 3.508230447769165\n",
      "step = 5366400: loss = 3.4682860374450684\n",
      "step = 5366600: loss = 4.212127208709717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 5366800: loss = 2.7506566047668457\n",
      "step = 5367000: loss = 4.123302936553955\n",
      "step = 5367200: loss = 3.248493194580078\n",
      "step = 5367400: loss = 4.459519386291504\n",
      "step = 5367600: loss = 4.310845375061035\n",
      "step = 5367800: loss = 3.8717291355133057\n",
      "step = 5368000: loss = 3.7180874347686768\n",
      "step = 5368200: loss = 3.8000760078430176\n",
      "step = 5368400: loss = 4.244602680206299\n",
      "step = 5368600: loss = 3.411454200744629\n",
      "step = 5368800: loss = 3.23624324798584\n",
      "step = 5369000: loss = 3.882099151611328\n",
      "step = 5369200: loss = 3.981830358505249\n",
      "step = 5369400: loss = 3.3799166679382324\n",
      "step = 5369600: loss = 3.52431321144104\n",
      "step = 5369800: loss = 4.4503655433654785\n",
      "step = 5370000: loss = 3.9598686695098877\n",
      "step = 5370000: Average Return = 3.799999952316284\n",
      "step = 5370200: loss = 4.507136344909668\n",
      "step = 5370400: loss = 2.7670018672943115\n",
      "step = 5370600: loss = 3.3744053840637207\n",
      "step = 5370800: loss = 1.7446166276931763\n",
      "step = 5371000: loss = 4.985359191894531\n",
      "step = 5371200: loss = 2.946377992630005\n",
      "step = 5371400: loss = 3.4929258823394775\n",
      "step = 5371600: loss = 2.9002668857574463\n",
      "step = 5371800: loss = 3.1889488697052\n",
      "step = 5372000: loss = 4.403500080108643\n",
      "step = 5372200: loss = 3.6201367378234863\n",
      "step = 5372400: loss = 3.7835404872894287\n",
      "step = 5372600: loss = 3.689422845840454\n",
      "step = 5372800: loss = 2.7750613689422607\n",
      "step = 5373000: loss = 4.092610836029053\n",
      "step = 5373200: loss = 4.140795707702637\n",
      "step = 5373400: loss = 3.0127904415130615\n",
      "step = 5373600: loss = 2.9300549030303955\n",
      "step = 5373800: loss = 4.49369478225708\n",
      "step = 5374000: loss = 3.6858654022216797\n",
      "step = 5374200: loss = 3.5208494663238525\n",
      "step = 5374400: loss = 3.5368309020996094\n",
      "step = 5374600: loss = 2.859159231185913\n",
      "step = 5374800: loss = 3.715182304382324\n",
      "step = 5375000: loss = 4.667763710021973\n",
      "step = 5375000: Average Return = 4.349999904632568\n",
      "step = 5375200: loss = 4.584850311279297\n",
      "step = 5375400: loss = 4.859827518463135\n",
      "step = 5375600: loss = 4.3202338218688965\n",
      "step = 5375800: loss = 2.8891851902008057\n",
      "step = 5376000: loss = 3.5267999172210693\n",
      "step = 5376200: loss = 4.367963790893555\n",
      "step = 5376400: loss = 4.224672794342041\n",
      "step = 5376600: loss = 4.245910167694092\n",
      "step = 5376800: loss = 3.9027605056762695\n",
      "step = 5377000: loss = 4.478457450866699\n",
      "step = 5377200: loss = 3.4362285137176514\n",
      "step = 5377400: loss = 4.907490253448486\n",
      "step = 5377600: loss = 4.172842979431152\n",
      "step = 5377800: loss = 4.200473785400391\n",
      "step = 5378000: loss = 5.187034606933594\n",
      "step = 5378200: loss = 3.688324213027954\n",
      "step = 5378400: loss = 3.0689797401428223\n",
      "step = 5378600: loss = 2.9651448726654053\n",
      "step = 5378800: loss = 3.7786169052124023\n",
      "step = 5379000: loss = 3.4464757442474365\n",
      "step = 5379200: loss = 3.5590226650238037\n",
      "step = 5379400: loss = 3.75177001953125\n",
      "step = 5379600: loss = 3.670180559158325\n",
      "step = 5379800: loss = 4.625587463378906\n",
      "step = 5380000: loss = 3.3234527111053467\n",
      "step = 5380000: Average Return = 6.0\n",
      "step = 5380200: loss = 3.536719799041748\n",
      "step = 5380400: loss = 4.085296630859375\n",
      "step = 5380600: loss = 3.725069999694824\n",
      "step = 5380800: loss = 3.4900808334350586\n",
      "step = 5381000: loss = 4.245978355407715\n",
      "step = 5381200: loss = 3.017291784286499\n",
      "step = 5381400: loss = 2.743832588195801\n",
      "step = 5381600: loss = 3.679290771484375\n",
      "step = 5381800: loss = 4.337826251983643\n",
      "step = 5382000: loss = 3.5116143226623535\n",
      "step = 5382200: loss = 3.883049488067627\n",
      "step = 5382400: loss = 2.846912145614624\n",
      "step = 5382600: loss = 3.402771472930908\n",
      "step = 5382800: loss = 3.5025148391723633\n",
      "step = 5383000: loss = 5.395577430725098\n",
      "step = 5383200: loss = 3.9802398681640625\n",
      "step = 5383400: loss = 3.502580404281616\n",
      "step = 5383600: loss = 4.425357818603516\n",
      "step = 5383800: loss = 4.565131187438965\n",
      "step = 5384000: loss = 2.6800756454467773\n",
      "step = 5384200: loss = 4.555129051208496\n",
      "step = 5384400: loss = 2.544691801071167\n",
      "step = 5384600: loss = 3.2212984561920166\n",
      "step = 5384800: loss = 4.038808345794678\n",
      "step = 5385000: loss = 3.918146848678589\n",
      "step = 5385000: Average Return = 4.0\n",
      "step = 5385200: loss = 4.724541664123535\n",
      "step = 5385400: loss = 2.883192300796509\n",
      "step = 5385600: loss = 4.083962917327881\n",
      "step = 5385800: loss = 3.954486608505249\n",
      "step = 5386000: loss = 2.9649651050567627\n",
      "step = 5386200: loss = 3.691746711730957\n",
      "step = 5386400: loss = 3.2548906803131104\n",
      "step = 5386600: loss = 3.1205391883850098\n",
      "step = 5386800: loss = 3.9531285762786865\n",
      "step = 5387000: loss = 2.8243021965026855\n",
      "step = 5387200: loss = 3.448523998260498\n",
      "step = 5387400: loss = 3.841881513595581\n",
      "step = 5387600: loss = 3.2837846279144287\n",
      "step = 5387800: loss = 4.304194450378418\n",
      "step = 5388000: loss = 3.4447600841522217\n",
      "step = 5388200: loss = 3.82442307472229\n",
      "step = 5388400: loss = 4.773829936981201\n",
      "step = 5388600: loss = 3.187115430831909\n",
      "step = 5388800: loss = 3.3390307426452637\n",
      "step = 5389000: loss = 3.7613513469696045\n",
      "step = 5389200: loss = 3.00046443939209\n",
      "step = 5389400: loss = 1.998553991317749\n",
      "step = 5389600: loss = 3.651137113571167\n",
      "step = 5389800: loss = 3.3832879066467285\n",
      "step = 5390000: loss = 4.249503135681152\n",
      "step = 5390000: Average Return = 3.0999999046325684\n",
      "step = 5390200: loss = 4.207516193389893\n",
      "step = 5390400: loss = 5.597286224365234\n",
      "step = 5390600: loss = 3.533719778060913\n",
      "step = 5390800: loss = 3.0617263317108154\n",
      "step = 5391000: loss = 3.7008776664733887\n",
      "step = 5391200: loss = 3.73539662361145\n",
      "step = 5391400: loss = 3.1238458156585693\n",
      "step = 5391600: loss = 4.94150447845459\n",
      "step = 5391800: loss = 4.83145809173584\n",
      "step = 5392000: loss = 5.285329341888428\n",
      "step = 5392200: loss = 2.92333984375\n",
      "step = 5392400: loss = 3.6912715435028076\n",
      "step = 5392600: loss = 3.566819429397583\n",
      "step = 5392800: loss = 3.2468791007995605\n",
      "step = 5393000: loss = 5.306218147277832\n",
      "step = 5393200: loss = 2.4829189777374268\n",
      "step = 5393400: loss = 3.6194419860839844\n",
      "step = 5393600: loss = 3.916224956512451\n",
      "step = 5393800: loss = 4.296833515167236\n",
      "step = 5394000: loss = 3.0669751167297363\n",
      "step = 5394200: loss = 2.8554494380950928\n",
      "step = 5394400: loss = 3.055488109588623\n",
      "step = 5394600: loss = 4.094090938568115\n",
      "step = 5394800: loss = 3.616058826446533\n",
      "step = 5395000: loss = 5.618916988372803\n",
      "step = 5395000: Average Return = 2.700000047683716\n",
      "step = 5395200: loss = 3.78301739692688\n",
      "step = 5395400: loss = 3.4967596530914307\n",
      "step = 5395600: loss = 4.152465343475342\n",
      "step = 5395800: loss = 4.6977081298828125\n",
      "step = 5396000: loss = 4.328049659729004\n",
      "step = 5396200: loss = 3.8568999767303467\n",
      "step = 5396400: loss = 4.640407562255859\n",
      "step = 5396600: loss = 3.279651641845703\n",
      "step = 5396800: loss = 4.344682216644287\n",
      "step = 5397000: loss = 4.64801025390625\n",
      "step = 5397200: loss = 3.9771568775177\n",
      "step = 5397400: loss = 4.421721935272217\n",
      "step = 5397600: loss = 4.525378227233887\n",
      "step = 5397800: loss = 4.358187675476074\n",
      "step = 5398000: loss = 4.056934833526611\n",
      "step = 5398200: loss = 2.271240472793579\n",
      "step = 5398400: loss = 4.085019588470459\n",
      "step = 5398600: loss = 4.256600856781006\n",
      "step = 5398800: loss = 4.337113380432129\n",
      "step = 5399000: loss = 4.4680867195129395\n",
      "step = 5399200: loss = 3.524409055709839\n",
      "step = 5399400: loss = 3.9730448722839355\n",
      "step = 5399600: loss = 3.171278238296509\n",
      "step = 5399800: loss = 4.075094699859619\n",
      "step = 5400000: loss = 3.435427188873291\n",
      "step = 5400000: Average Return = 1.649999976158142\n",
      "step = 5400200: loss = 4.358175754547119\n",
      "step = 5400400: loss = 3.3668127059936523\n",
      "step = 5400600: loss = 3.774169445037842\n",
      "step = 5400800: loss = 4.961034297943115\n",
      "step = 5401000: loss = 3.3838963508605957\n",
      "step = 5401200: loss = 3.291720390319824\n",
      "step = 5401400: loss = 5.03033971786499\n",
      "step = 5401600: loss = 4.115665912628174\n",
      "step = 5401800: loss = 3.3451390266418457\n",
      "step = 5402000: loss = 4.451812267303467\n",
      "step = 5402200: loss = 2.967517375946045\n",
      "step = 5402400: loss = 3.8817296028137207\n",
      "step = 5402600: loss = 3.8818342685699463\n",
      "step = 5402800: loss = 5.432104587554932\n",
      "step = 5403000: loss = 1.4671398401260376\n",
      "step = 5403200: loss = 4.392580032348633\n",
      "step = 5403400: loss = 6.03750467300415\n",
      "step = 5403600: loss = 3.3015222549438477\n",
      "step = 5403800: loss = 2.8821370601654053\n",
      "step = 5404000: loss = 3.7994070053100586\n",
      "step = 5404200: loss = 3.947988748550415\n",
      "step = 5404400: loss = 3.4529058933258057\n",
      "step = 5404600: loss = 3.2945849895477295\n",
      "step = 5404800: loss = 3.0962541103363037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 5405000: loss = 3.8098645210266113\n",
      "step = 5405000: Average Return = 2.9000000953674316\n",
      "step = 5405200: loss = 3.3343820571899414\n",
      "step = 5405400: loss = 4.555854320526123\n",
      "step = 5405600: loss = 3.5933456420898438\n",
      "step = 5405800: loss = 3.4888410568237305\n",
      "step = 5406000: loss = 3.2598202228546143\n",
      "step = 5406200: loss = 3.3412835597991943\n",
      "step = 5406400: loss = 4.371590614318848\n",
      "step = 5406600: loss = 4.273242473602295\n",
      "step = 5406800: loss = 3.7770018577575684\n",
      "step = 5407000: loss = 4.7407307624816895\n",
      "step = 5407200: loss = 4.114449977874756\n",
      "step = 5407400: loss = 4.227054119110107\n",
      "step = 5407600: loss = 4.303606033325195\n",
      "step = 5407800: loss = 2.5380001068115234\n",
      "step = 5408000: loss = 4.0578484535217285\n",
      "step = 5408200: loss = 4.637341022491455\n",
      "step = 5408400: loss = 4.201617240905762\n",
      "step = 5408600: loss = 2.988744020462036\n",
      "step = 5408800: loss = 5.519503116607666\n",
      "step = 5409000: loss = 3.229739189147949\n",
      "step = 5409200: loss = 3.963679790496826\n",
      "step = 5409400: loss = 3.902703046798706\n",
      "step = 5409600: loss = 3.6798222064971924\n",
      "step = 5409800: loss = 4.516934394836426\n",
      "step = 5410000: loss = 4.4563398361206055\n",
      "step = 5410000: Average Return = 3.200000047683716\n",
      "step = 5410200: loss = 3.2557811737060547\n",
      "step = 5410400: loss = 3.3604393005371094\n",
      "step = 5410600: loss = 4.149956703186035\n",
      "step = 5410800: loss = 4.161746025085449\n",
      "step = 5411000: loss = 4.716221332550049\n",
      "step = 5411200: loss = 5.186555862426758\n",
      "step = 5411400: loss = 3.9068071842193604\n",
      "step = 5411600: loss = 2.2961039543151855\n",
      "step = 5411800: loss = 2.791274309158325\n",
      "step = 5412000: loss = 4.213253498077393\n",
      "step = 5412200: loss = 5.452901363372803\n",
      "step = 5412400: loss = 4.967527866363525\n",
      "step = 5412600: loss = 3.843062162399292\n",
      "step = 5412800: loss = 4.057070255279541\n",
      "step = 5413000: loss = 2.801675319671631\n",
      "step = 5413200: loss = 4.762825012207031\n",
      "step = 5413400: loss = 3.1430928707122803\n",
      "step = 5413600: loss = 4.244997024536133\n",
      "step = 5413800: loss = 5.282628536224365\n",
      "step = 5414000: loss = 3.905353307723999\n",
      "step = 5414200: loss = 3.4681239128112793\n",
      "step = 5414400: loss = 4.412597179412842\n",
      "step = 5414600: loss = 4.433266639709473\n",
      "step = 5414800: loss = 4.4876017570495605\n",
      "step = 5415000: loss = 4.943703651428223\n",
      "step = 5415000: Average Return = 2.8499999046325684\n",
      "step = 5415200: loss = 4.457329750061035\n",
      "step = 5415400: loss = 3.3523213863372803\n",
      "step = 5415600: loss = 4.289040565490723\n",
      "step = 5415800: loss = 3.2939772605895996\n",
      "step = 5416000: loss = 4.048699378967285\n",
      "step = 5416200: loss = 3.934235095977783\n",
      "step = 5416400: loss = 4.813681602478027\n",
      "step = 5416600: loss = 5.085254192352295\n",
      "step = 5416800: loss = 2.194570779800415\n",
      "step = 5417000: loss = 4.067916393280029\n",
      "step = 5417200: loss = 3.3995916843414307\n",
      "step = 5417400: loss = 3.2431883811950684\n",
      "step = 5417600: loss = 3.074540615081787\n",
      "step = 5417800: loss = 4.2965168952941895\n",
      "step = 5418000: loss = 4.298341274261475\n",
      "step = 5418200: loss = 2.3352839946746826\n",
      "step = 5418400: loss = 5.504555702209473\n",
      "step = 5418600: loss = 2.8077175617218018\n",
      "step = 5418800: loss = 3.635136127471924\n",
      "step = 5419000: loss = 3.2346959114074707\n",
      "step = 5419200: loss = 4.69846773147583\n",
      "step = 5419400: loss = 5.175698280334473\n",
      "step = 5419600: loss = 4.0826263427734375\n",
      "step = 5419800: loss = 4.30788516998291\n",
      "step = 5420000: loss = 2.6586973667144775\n",
      "step = 5420000: Average Return = 4.75\n",
      "step = 5420200: loss = 4.373532295227051\n",
      "step = 5420400: loss = 3.768268346786499\n",
      "step = 5420600: loss = 4.650331497192383\n",
      "step = 5420800: loss = 3.7253594398498535\n",
      "step = 5421000: loss = 3.2777256965637207\n",
      "step = 5421200: loss = 3.433067560195923\n",
      "step = 5421400: loss = 4.860023498535156\n",
      "step = 5421600: loss = 4.056733131408691\n",
      "step = 5421800: loss = 4.236034870147705\n",
      "step = 5422000: loss = 5.415807247161865\n",
      "step = 5422200: loss = 3.939683675765991\n",
      "step = 5422400: loss = 3.217533588409424\n",
      "step = 5422600: loss = 3.743372678756714\n",
      "step = 5422800: loss = 4.3538737297058105\n",
      "step = 5423000: loss = 2.826024293899536\n",
      "step = 5423200: loss = 3.687757730484009\n",
      "step = 5423400: loss = 4.497714519500732\n",
      "step = 5423600: loss = 3.534898519515991\n",
      "step = 5423800: loss = 3.3212969303131104\n",
      "step = 5424000: loss = 4.441628932952881\n",
      "step = 5424200: loss = 3.3437931537628174\n",
      "step = 5424400: loss = 2.63039231300354\n",
      "step = 5424600: loss = 3.386033296585083\n",
      "step = 5424800: loss = 5.741458415985107\n",
      "step = 5425000: loss = 2.419837474822998\n",
      "step = 5425000: Average Return = 4.550000190734863\n",
      "step = 5425200: loss = 3.013317108154297\n",
      "step = 5425400: loss = 3.6268935203552246\n",
      "step = 5425600: loss = 3.735048770904541\n",
      "step = 5425800: loss = 3.438655376434326\n",
      "step = 5426000: loss = 3.738154172897339\n",
      "step = 5426200: loss = 4.049842357635498\n",
      "step = 5426400: loss = 3.3508574962615967\n",
      "step = 5426600: loss = 3.415346384048462\n",
      "step = 5426800: loss = 3.9482078552246094\n",
      "step = 5427000: loss = 3.5933961868286133\n",
      "step = 5427200: loss = 5.139037132263184\n",
      "step = 5427400: loss = 3.4265005588531494\n",
      "step = 5427600: loss = 3.595876932144165\n",
      "step = 5427800: loss = 2.532827138900757\n",
      "step = 5428000: loss = 4.099607944488525\n",
      "step = 5428200: loss = 3.2945101261138916\n",
      "step = 5428400: loss = 4.058445453643799\n",
      "step = 5428600: loss = 4.5754618644714355\n",
      "step = 5428800: loss = 3.9274559020996094\n",
      "step = 5429000: loss = 3.7433531284332275\n",
      "step = 5429200: loss = 4.562771797180176\n",
      "step = 5429400: loss = 5.101418495178223\n",
      "step = 5429600: loss = 3.231022357940674\n",
      "step = 5429800: loss = 3.8033337593078613\n",
      "step = 5430000: loss = 3.5802760124206543\n",
      "step = 5430000: Average Return = 3.0999999046325684\n",
      "step = 5430200: loss = 4.037312984466553\n",
      "step = 5430400: loss = 3.4250786304473877\n",
      "step = 5430600: loss = 3.4440300464630127\n",
      "step = 5430800: loss = 3.8912065029144287\n",
      "step = 5431000: loss = 3.4654743671417236\n",
      "step = 5431200: loss = 3.6841979026794434\n",
      "step = 5431400: loss = 2.8675732612609863\n",
      "step = 5431600: loss = 4.040731906890869\n",
      "step = 5431800: loss = 3.1538522243499756\n",
      "step = 5432000: loss = 2.5959384441375732\n",
      "step = 5432200: loss = 4.849568843841553\n",
      "step = 5432400: loss = 3.7670533657073975\n",
      "step = 5432600: loss = 1.9313520193099976\n",
      "step = 5432800: loss = 4.139553070068359\n",
      "step = 5433000: loss = 3.1560068130493164\n",
      "step = 5433200: loss = 4.14586877822876\n",
      "step = 5433400: loss = 3.7533462047576904\n",
      "step = 5433600: loss = 5.02876615524292\n",
      "step = 5433800: loss = 4.439696788787842\n",
      "step = 5434000: loss = 3.9676432609558105\n",
      "step = 5434200: loss = 3.3262758255004883\n",
      "step = 5434400: loss = 3.303550958633423\n",
      "step = 5434600: loss = 4.10801887512207\n",
      "step = 5434800: loss = 3.973391056060791\n",
      "step = 5435000: loss = 3.4749743938446045\n",
      "step = 5435000: Average Return = 2.700000047683716\n",
      "step = 5435200: loss = 5.130627155303955\n",
      "step = 5435400: loss = 3.9855566024780273\n",
      "step = 5435600: loss = 3.958477735519409\n",
      "step = 5435800: loss = 3.724165201187134\n",
      "step = 5436000: loss = 2.857966184616089\n",
      "step = 5436200: loss = 5.0952067375183105\n",
      "step = 5436400: loss = 3.46380615234375\n",
      "step = 5436600: loss = 4.743116855621338\n",
      "step = 5436800: loss = 4.316628932952881\n",
      "step = 5437000: loss = 3.725972890853882\n",
      "step = 5437200: loss = 3.108492374420166\n",
      "step = 5437400: loss = 3.202960729598999\n",
      "step = 5437600: loss = 3.7009222507476807\n",
      "step = 5437800: loss = 4.251949787139893\n",
      "step = 5438000: loss = 3.8106648921966553\n",
      "step = 5438200: loss = 3.5505049228668213\n",
      "step = 5438400: loss = 4.428276062011719\n",
      "step = 5438600: loss = 2.8027772903442383\n",
      "step = 5438800: loss = 4.965837478637695\n",
      "step = 5439000: loss = 3.478710174560547\n",
      "step = 5439200: loss = 3.3853914737701416\n",
      "step = 5439400: loss = 4.423980236053467\n",
      "step = 5439600: loss = 3.6127376556396484\n",
      "step = 5439800: loss = 3.557981491088867\n",
      "step = 5440000: loss = 4.418838024139404\n",
      "step = 5440000: Average Return = 2.549999952316284\n",
      "step = 5440200: loss = 2.852322578430176\n",
      "step = 5440400: loss = 4.141582012176514\n",
      "step = 5440600: loss = 6.109686374664307\n",
      "step = 5440800: loss = 4.526459693908691\n",
      "step = 5441000: loss = 4.031188011169434\n",
      "step = 5441200: loss = 3.7328081130981445\n",
      "step = 5441400: loss = 3.622030019760132\n",
      "step = 5441600: loss = 3.0876808166503906\n",
      "step = 5441800: loss = 4.533755302429199\n",
      "step = 5442000: loss = 3.8486974239349365\n",
      "step = 5442200: loss = 4.891724586486816\n",
      "step = 5442400: loss = 3.58534574508667\n",
      "step = 5442600: loss = 3.627236843109131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 5442800: loss = 4.444387912750244\n",
      "step = 5443000: loss = 3.9062583446502686\n",
      "step = 5443200: loss = 3.803656816482544\n",
      "step = 5443400: loss = 3.0663628578186035\n",
      "step = 5443600: loss = 3.9113011360168457\n",
      "step = 5443800: loss = 3.6100358963012695\n",
      "step = 5444000: loss = 4.504044055938721\n",
      "step = 5444200: loss = 4.33710241317749\n",
      "step = 5444400: loss = 3.8075475692749023\n",
      "step = 5444600: loss = 3.5260095596313477\n",
      "step = 5444800: loss = 3.292956829071045\n",
      "step = 5445000: loss = 4.259210586547852\n",
      "step = 5445000: Average Return = 3.799999952316284\n",
      "step = 5445200: loss = 4.069674491882324\n",
      "step = 5445400: loss = 3.380851984024048\n",
      "step = 5445600: loss = 2.474262237548828\n",
      "step = 5445800: loss = 4.395114421844482\n",
      "step = 5446000: loss = 3.9449846744537354\n",
      "step = 5446200: loss = 3.902402877807617\n",
      "step = 5446400: loss = 3.050956964492798\n",
      "step = 5446600: loss = 4.212399959564209\n",
      "step = 5446800: loss = 3.2025249004364014\n",
      "step = 5447000: loss = 4.527222633361816\n",
      "step = 5447200: loss = 2.096086263656616\n",
      "step = 5447400: loss = 3.2312207221984863\n",
      "step = 5447600: loss = 2.5293831825256348\n",
      "step = 5447800: loss = 3.483776807785034\n",
      "step = 5448000: loss = 4.408442974090576\n",
      "step = 5448200: loss = 4.301854133605957\n",
      "step = 5448400: loss = 3.4279839992523193\n",
      "step = 5448600: loss = 4.69812536239624\n",
      "step = 5448800: loss = 2.1829075813293457\n",
      "step = 5449000: loss = 3.8394999504089355\n",
      "step = 5449200: loss = 3.8452672958374023\n",
      "step = 5449400: loss = 4.623933792114258\n",
      "step = 5449600: loss = 2.3451132774353027\n",
      "step = 5449800: loss = 4.285450458526611\n",
      "step = 5450000: loss = 4.351383686065674\n",
      "step = 5450000: Average Return = 3.3499999046325684\n",
      "step = 5450200: loss = 3.8010332584381104\n",
      "step = 5450400: loss = 4.080151081085205\n",
      "step = 5450600: loss = 2.704904079437256\n",
      "step = 5450800: loss = 4.991109371185303\n",
      "step = 5451000: loss = 4.486755847930908\n",
      "step = 5451200: loss = 4.291980266571045\n",
      "step = 5451400: loss = 4.673945426940918\n",
      "step = 5451600: loss = 5.597501277923584\n",
      "step = 5451800: loss = 4.123611927032471\n",
      "step = 5452000: loss = 3.6405766010284424\n",
      "step = 5452200: loss = 4.4202470779418945\n",
      "step = 5452400: loss = 3.09617280960083\n",
      "step = 5452600: loss = 2.8914852142333984\n",
      "step = 5452800: loss = 3.2468104362487793\n",
      "step = 5453000: loss = 3.491420269012451\n",
      "step = 5453200: loss = 4.271146297454834\n",
      "step = 5453400: loss = 4.374236583709717\n",
      "step = 5453600: loss = 3.6519694328308105\n",
      "step = 5453800: loss = 3.650334358215332\n",
      "step = 5454000: loss = 4.178022861480713\n",
      "step = 5454200: loss = 2.6902072429656982\n",
      "step = 5454400: loss = 3.938438653945923\n",
      "step = 5454600: loss = 3.835645914077759\n",
      "step = 5454800: loss = 2.9925789833068848\n",
      "step = 5455000: loss = 4.894052505493164\n",
      "step = 5455000: Average Return = 4.650000095367432\n",
      "step = 5455200: loss = 3.172589063644409\n",
      "step = 5455400: loss = 5.072131156921387\n",
      "step = 5455600: loss = 3.247588634490967\n",
      "step = 5455800: loss = 3.8723318576812744\n",
      "step = 5456000: loss = 3.4352612495422363\n",
      "step = 5456200: loss = 3.2801787853240967\n",
      "step = 5456400: loss = 3.8773534297943115\n",
      "step = 5456600: loss = 4.342366695404053\n",
      "step = 5456800: loss = 3.35998797416687\n",
      "step = 5457000: loss = 3.7787628173828125\n",
      "step = 5457200: loss = 3.270838499069214\n",
      "step = 5457400: loss = 4.568084239959717\n",
      "step = 5457600: loss = 4.252514362335205\n",
      "step = 5457800: loss = 4.04313850402832\n",
      "step = 5458000: loss = 4.132261753082275\n",
      "step = 5458200: loss = 4.075592041015625\n",
      "step = 5458400: loss = 4.080414295196533\n",
      "step = 5458600: loss = 5.24333381652832\n",
      "step = 5458800: loss = 2.5589962005615234\n",
      "step = 5459000: loss = 4.306042671203613\n",
      "step = 5459200: loss = 3.4786322116851807\n",
      "step = 5459400: loss = 6.114399433135986\n",
      "step = 5459600: loss = 3.804224729537964\n",
      "step = 5459800: loss = 4.7114973068237305\n",
      "step = 5460000: loss = 4.1371564865112305\n",
      "step = 5460000: Average Return = 2.0\n",
      "step = 5460200: loss = 3.803208589553833\n",
      "step = 5460400: loss = 3.6799275875091553\n",
      "step = 5460600: loss = 4.953307628631592\n",
      "step = 5460800: loss = 4.697939872741699\n",
      "step = 5461000: loss = 4.677308082580566\n",
      "step = 5461200: loss = 2.9437484741210938\n",
      "step = 5461400: loss = 2.724440336227417\n",
      "step = 5461600: loss = 4.973959922790527\n",
      "step = 5461800: loss = 3.706843852996826\n",
      "step = 5462000: loss = 3.8370203971862793\n",
      "step = 5462200: loss = 3.179166078567505\n",
      "step = 5462400: loss = 2.700584888458252\n",
      "step = 5462600: loss = 2.772214889526367\n",
      "step = 5462800: loss = 4.583792209625244\n",
      "step = 5463000: loss = 4.665450096130371\n",
      "step = 5463200: loss = 3.762089729309082\n",
      "step = 5463400: loss = 4.947669982910156\n",
      "step = 5463600: loss = 4.773016452789307\n",
      "step = 5463800: loss = 4.188441753387451\n",
      "step = 5464000: loss = 5.147622108459473\n",
      "step = 5464200: loss = 4.439316749572754\n",
      "step = 5464400: loss = 3.5813114643096924\n",
      "step = 5464600: loss = 3.3338537216186523\n",
      "step = 5464800: loss = 4.202692031860352\n",
      "step = 5465000: loss = 4.721299171447754\n",
      "step = 5465000: Average Return = 4.150000095367432\n",
      "step = 5465200: loss = 5.048317909240723\n",
      "step = 5465400: loss = 3.827282667160034\n",
      "step = 5465600: loss = 3.6279830932617188\n",
      "step = 5465800: loss = 3.0548839569091797\n",
      "step = 5466000: loss = 3.2876198291778564\n",
      "step = 5466200: loss = 5.654181957244873\n",
      "step = 5466400: loss = 5.034391403198242\n",
      "step = 5466600: loss = 2.839573860168457\n",
      "step = 5466800: loss = 3.414395570755005\n",
      "step = 5467000: loss = 5.82837438583374\n",
      "step = 5467200: loss = 5.186369895935059\n",
      "step = 5467400: loss = 5.125727653503418\n",
      "step = 5467600: loss = 6.037938594818115\n",
      "step = 5467800: loss = 3.4098384380340576\n",
      "step = 5468000: loss = 3.366969585418701\n",
      "step = 5468200: loss = 3.4073739051818848\n",
      "step = 5468400: loss = 2.6445775032043457\n",
      "step = 5468600: loss = 3.657240629196167\n",
      "step = 5468800: loss = 4.138570308685303\n",
      "step = 5469000: loss = 3.1700148582458496\n",
      "step = 5469200: loss = 2.64151668548584\n",
      "step = 5469400: loss = 2.9170210361480713\n",
      "step = 5469600: loss = 4.453660011291504\n",
      "step = 5469800: loss = 4.260009288787842\n",
      "step = 5470000: loss = 4.268304824829102\n",
      "step = 5470000: Average Return = 4.099999904632568\n",
      "step = 5470200: loss = 3.8644542694091797\n",
      "step = 5470400: loss = 4.090870380401611\n",
      "step = 5470600: loss = 3.8438796997070312\n",
      "step = 5470800: loss = 2.5921154022216797\n",
      "step = 5471000: loss = 3.8887689113616943\n",
      "step = 5471200: loss = 4.302828788757324\n",
      "step = 5471400: loss = 3.893411874771118\n",
      "step = 5471600: loss = 3.6250100135803223\n",
      "step = 5471800: loss = 4.3387017250061035\n",
      "step = 5472000: loss = 2.9875094890594482\n",
      "step = 5472200: loss = 4.246311187744141\n",
      "step = 5472400: loss = 3.589642286300659\n",
      "step = 5472600: loss = 2.8709490299224854\n",
      "step = 5472800: loss = 3.4303479194641113\n",
      "step = 5473000: loss = 3.9960556030273438\n",
      "step = 5473200: loss = 4.879674434661865\n",
      "step = 5473400: loss = 4.265717029571533\n",
      "step = 5473600: loss = 2.318082094192505\n",
      "step = 5473800: loss = 3.583360433578491\n",
      "step = 5474000: loss = 3.630449056625366\n",
      "step = 5474200: loss = 3.0616514682769775\n",
      "step = 5474400: loss = 3.5759007930755615\n",
      "step = 5474600: loss = 3.9473745822906494\n",
      "step = 5474800: loss = 3.9148783683776855\n",
      "step = 5475000: loss = 4.961598873138428\n",
      "step = 5475000: Average Return = 3.450000047683716\n",
      "step = 5475200: loss = 2.6326005458831787\n",
      "step = 5475400: loss = 2.681118965148926\n",
      "step = 5475600: loss = 3.941255807876587\n",
      "step = 5475800: loss = 3.007215738296509\n",
      "step = 5476000: loss = 3.18650484085083\n",
      "step = 5476200: loss = 4.040170192718506\n",
      "step = 5476400: loss = 2.798492908477783\n",
      "step = 5476600: loss = 4.362128257751465\n",
      "step = 5476800: loss = 3.363342761993408\n",
      "step = 5477000: loss = 4.246620178222656\n",
      "step = 5477200: loss = 4.0954461097717285\n",
      "step = 5477400: loss = 3.730043888092041\n",
      "step = 5477600: loss = 4.242773532867432\n",
      "step = 5477800: loss = 4.2581610679626465\n",
      "step = 5478000: loss = 3.6226587295532227\n",
      "step = 5478200: loss = 4.229902744293213\n",
      "step = 5478400: loss = 3.7764010429382324\n",
      "step = 5478600: loss = 3.688898801803589\n",
      "step = 5478800: loss = 3.7402937412261963\n",
      "step = 5479000: loss = 3.165597677230835\n",
      "step = 5479200: loss = 3.2235589027404785\n",
      "step = 5479400: loss = 4.113945484161377\n",
      "step = 5479600: loss = 2.9387528896331787\n",
      "step = 5479800: loss = 3.948291540145874\n",
      "step = 5480000: loss = 4.808873653411865\n",
      "step = 5480000: Average Return = 3.25\n",
      "step = 5480200: loss = 3.887552499771118\n",
      "step = 5480400: loss = 3.2259416580200195\n",
      "step = 5480600: loss = 4.226539611816406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 5480800: loss = 2.7303597927093506\n",
      "step = 5481000: loss = 4.155486583709717\n",
      "step = 5481200: loss = 2.912996768951416\n",
      "step = 5481400: loss = 2.9915478229522705\n",
      "step = 5481600: loss = 5.208403587341309\n",
      "step = 5481800: loss = 3.4671037197113037\n",
      "step = 5482000: loss = 3.725935697555542\n",
      "step = 5482200: loss = 4.011597156524658\n",
      "step = 5482400: loss = 3.868567943572998\n",
      "step = 5482600: loss = 3.9255282878875732\n",
      "step = 5482800: loss = 3.797778844833374\n",
      "step = 5483000: loss = 3.1009514331817627\n",
      "step = 5483200: loss = 4.603562355041504\n",
      "step = 5483400: loss = 3.6822423934936523\n",
      "step = 5483600: loss = 4.431117534637451\n",
      "step = 5483800: loss = 3.949985980987549\n",
      "step = 5484000: loss = 4.601755142211914\n",
      "step = 5484200: loss = 3.064331531524658\n",
      "step = 5484400: loss = 4.1636552810668945\n",
      "step = 5484600: loss = 4.569368839263916\n",
      "step = 5484800: loss = 4.924286365509033\n",
      "step = 5485000: loss = 3.670461654663086\n",
      "step = 5485000: Average Return = 2.3499999046325684\n",
      "step = 5485200: loss = 3.283698558807373\n",
      "step = 5485400: loss = 3.060551643371582\n",
      "step = 5485600: loss = 4.475131511688232\n",
      "step = 5485800: loss = 4.395521640777588\n",
      "step = 5486000: loss = 3.9133925437927246\n",
      "step = 5486200: loss = 2.515899181365967\n",
      "step = 5486400: loss = 4.850305080413818\n",
      "step = 5486600: loss = 3.3952770233154297\n",
      "step = 5486800: loss = 5.090694427490234\n",
      "step = 5487000: loss = 2.193531036376953\n",
      "step = 5487200: loss = 3.641638994216919\n",
      "step = 5487400: loss = 3.8347392082214355\n",
      "step = 5487600: loss = 4.6988067626953125\n",
      "step = 5487800: loss = 3.736515760421753\n",
      "step = 5488000: loss = 3.8969531059265137\n",
      "step = 5488200: loss = 4.85817289352417\n",
      "step = 5488400: loss = 2.6186137199401855\n",
      "step = 5488600: loss = 4.379550457000732\n",
      "step = 5488800: loss = 3.2782914638519287\n",
      "step = 5489000: loss = 4.237905979156494\n",
      "step = 5489200: loss = 3.7151854038238525\n",
      "step = 5489400: loss = 3.5085034370422363\n",
      "step = 5489600: loss = 3.298916816711426\n",
      "step = 5489800: loss = 3.3946428298950195\n",
      "step = 5490000: loss = 3.6991522312164307\n",
      "step = 5490000: Average Return = 2.200000047683716\n",
      "step = 5490200: loss = 2.5046069622039795\n",
      "step = 5490400: loss = 2.7866530418395996\n",
      "step = 5490600: loss = 3.679523229598999\n",
      "step = 5490800: loss = 6.039777755737305\n",
      "step = 5491000: loss = 3.7915241718292236\n",
      "step = 5491200: loss = 2.8487954139709473\n",
      "step = 5491400: loss = 3.1419036388397217\n",
      "step = 5491600: loss = 5.231018543243408\n",
      "step = 5491800: loss = 4.1367034912109375\n",
      "step = 5492000: loss = 3.6402065753936768\n",
      "step = 5492200: loss = 3.838557243347168\n",
      "step = 5492400: loss = 3.5646259784698486\n",
      "step = 5492600: loss = 2.977397918701172\n",
      "step = 5492800: loss = 5.024105548858643\n",
      "step = 5493000: loss = 4.351382732391357\n",
      "step = 5493200: loss = 4.097855091094971\n",
      "step = 5493400: loss = 3.0171759128570557\n",
      "step = 5493600: loss = 3.4265458583831787\n",
      "step = 5493800: loss = 4.031952381134033\n",
      "step = 5494000: loss = 3.538710355758667\n",
      "step = 5494200: loss = 4.6500959396362305\n",
      "step = 5494400: loss = 3.3717687129974365\n",
      "step = 5494600: loss = 3.4641880989074707\n",
      "step = 5494800: loss = 2.14168119430542\n",
      "step = 5495000: loss = 5.07407283782959\n",
      "step = 5495000: Average Return = 1.649999976158142\n",
      "step = 5495200: loss = 3.9961564540863037\n",
      "step = 5495400: loss = 3.655273914337158\n",
      "step = 5495600: loss = 4.109588623046875\n",
      "step = 5495800: loss = 3.7269303798675537\n",
      "step = 5496000: loss = 3.337235450744629\n",
      "step = 5496200: loss = 4.84719705581665\n",
      "step = 5496400: loss = 4.538300037384033\n",
      "step = 5496600: loss = 3.664058208465576\n",
      "step = 5496800: loss = 5.242121696472168\n",
      "step = 5497000: loss = 3.5806989669799805\n",
      "step = 5497200: loss = 4.71348237991333\n",
      "step = 5497400: loss = 4.224397659301758\n",
      "step = 5497600: loss = 4.235137462615967\n",
      "step = 5497800: loss = 3.6439056396484375\n",
      "step = 5498000: loss = 3.1528337001800537\n",
      "step = 5498200: loss = 4.927115440368652\n",
      "step = 5498400: loss = 4.671811580657959\n",
      "step = 5498600: loss = 3.6077799797058105\n",
      "step = 5498800: loss = 4.507378101348877\n",
      "step = 5499000: loss = 4.755402565002441\n",
      "step = 5499200: loss = 3.1890957355499268\n",
      "step = 5499400: loss = 4.482847213745117\n",
      "step = 5499600: loss = 3.476884126663208\n",
      "step = 5499800: loss = 4.587241172790527\n",
      "step = 5500000: loss = 3.080117702484131\n",
      "step = 5500000: Average Return = 3.25\n",
      "step = 5500200: loss = 3.4195656776428223\n",
      "step = 5500400: loss = 3.5099496841430664\n",
      "step = 5500600: loss = 4.689614295959473\n",
      "step = 5500800: loss = 4.044989109039307\n",
      "step = 5501000: loss = 4.684285640716553\n",
      "step = 5501200: loss = 3.1664772033691406\n",
      "step = 5501400: loss = 3.1841375827789307\n",
      "step = 5501600: loss = 3.3366000652313232\n",
      "step = 5501800: loss = 4.235694408416748\n",
      "step = 5502000: loss = 4.7470526695251465\n",
      "step = 5502200: loss = 4.100322723388672\n",
      "step = 5502400: loss = 2.896782398223877\n",
      "step = 5502600: loss = 3.9322640895843506\n",
      "step = 5502800: loss = 2.9378154277801514\n",
      "step = 5503000: loss = 3.2501513957977295\n",
      "step = 5503200: loss = 4.485062599182129\n",
      "step = 5503400: loss = 3.6020164489746094\n",
      "step = 5503600: loss = 2.804291009902954\n",
      "step = 5503800: loss = 4.716847896575928\n",
      "step = 5504000: loss = 3.8474578857421875\n",
      "step = 5504200: loss = 4.055361270904541\n",
      "step = 5504400: loss = 3.6679418087005615\n",
      "step = 5504600: loss = 4.878782749176025\n",
      "step = 5504800: loss = 4.968544960021973\n",
      "step = 5505000: loss = 5.153431415557861\n",
      "step = 5505000: Average Return = 4.400000095367432\n",
      "step = 5505200: loss = 2.9891905784606934\n",
      "step = 5505400: loss = 4.324105262756348\n",
      "step = 5505600: loss = 4.122363567352295\n",
      "step = 5505800: loss = 3.2572505474090576\n",
      "step = 5506000: loss = 3.419780731201172\n",
      "step = 5506200: loss = 3.1951353549957275\n",
      "step = 5506400: loss = 5.255678653717041\n",
      "step = 5506600: loss = 3.2008323669433594\n",
      "step = 5506800: loss = 4.499886512756348\n",
      "step = 5507000: loss = 2.405277967453003\n",
      "step = 5507200: loss = 4.786767482757568\n",
      "step = 5507400: loss = 4.591950416564941\n",
      "step = 5507600: loss = 4.103712558746338\n",
      "step = 5507800: loss = 3.03623104095459\n",
      "step = 5508000: loss = 4.193285942077637\n",
      "step = 5508200: loss = 3.339909076690674\n",
      "step = 5508400: loss = 4.555832862854004\n",
      "step = 5508600: loss = 4.014429092407227\n",
      "step = 5508800: loss = 4.422791957855225\n",
      "step = 5509000: loss = 3.577220916748047\n",
      "step = 5509200: loss = 4.3653035163879395\n",
      "step = 5509400: loss = 2.6378815174102783\n",
      "step = 5509600: loss = 3.5129644870758057\n",
      "step = 5509800: loss = 3.658177375793457\n",
      "step = 5510000: loss = 4.608302593231201\n",
      "step = 5510000: Average Return = 4.599999904632568\n",
      "step = 5510200: loss = 4.979018211364746\n",
      "step = 5510400: loss = 3.6416921615600586\n",
      "step = 5510600: loss = 5.564021587371826\n",
      "step = 5510800: loss = 5.037003993988037\n",
      "step = 5511000: loss = 2.6126439571380615\n",
      "step = 5511200: loss = 3.794481039047241\n",
      "step = 5511400: loss = 3.4092376232147217\n",
      "step = 5511600: loss = 3.058255434036255\n",
      "step = 5511800: loss = 4.183372974395752\n",
      "step = 5512000: loss = 3.6137304306030273\n",
      "step = 5512200: loss = 4.738971710205078\n",
      "step = 5512400: loss = 4.119622230529785\n",
      "step = 5512600: loss = 3.3326287269592285\n",
      "step = 5512800: loss = 3.5528171062469482\n",
      "step = 5513000: loss = 3.823758363723755\n",
      "step = 5513200: loss = 4.365371227264404\n",
      "step = 5513400: loss = 4.6210432052612305\n",
      "step = 5513600: loss = 4.092978000640869\n",
      "step = 5513800: loss = 4.213490962982178\n",
      "step = 5514000: loss = 2.8802807331085205\n",
      "step = 5514200: loss = 4.514573097229004\n",
      "step = 5514400: loss = 3.506452798843384\n",
      "step = 5514600: loss = 3.4063615798950195\n",
      "step = 5514800: loss = 4.194799900054932\n",
      "step = 5515000: loss = 4.4275360107421875\n",
      "step = 5515000: Average Return = 3.549999952316284\n",
      "step = 5515200: loss = 3.235264778137207\n",
      "step = 5515400: loss = 4.552377223968506\n",
      "step = 5515600: loss = 4.148499488830566\n",
      "step = 5515800: loss = 4.0368781089782715\n",
      "step = 5516000: loss = 5.5358195304870605\n",
      "step = 5516200: loss = 4.704121112823486\n",
      "step = 5516400: loss = 4.255496501922607\n",
      "step = 5516600: loss = 5.617680549621582\n",
      "step = 5516800: loss = 4.15259313583374\n",
      "step = 5517000: loss = 4.45054817199707\n",
      "step = 5517200: loss = 3.9083683490753174\n",
      "step = 5517400: loss = 3.9172115325927734\n",
      "step = 5517600: loss = 4.289444446563721\n",
      "step = 5517800: loss = 5.230164527893066\n",
      "step = 5518000: loss = 3.8642337322235107\n",
      "step = 5518200: loss = 4.531030654907227\n",
      "step = 5518400: loss = 3.720228910446167\n",
      "step = 5518600: loss = 3.9596993923187256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 5518800: loss = 3.177441358566284\n",
      "step = 5519000: loss = 3.8841090202331543\n",
      "step = 5519200: loss = 2.9410481452941895\n",
      "step = 5519400: loss = 3.8042681217193604\n",
      "step = 5519600: loss = 5.0034403800964355\n",
      "step = 5519800: loss = 3.245736837387085\n",
      "step = 5520000: loss = 3.792119264602661\n",
      "step = 5520000: Average Return = 3.299999952316284\n",
      "step = 5520200: loss = 3.693897008895874\n",
      "step = 5520400: loss = 3.7975964546203613\n",
      "step = 5520600: loss = 3.2986950874328613\n",
      "step = 5520800: loss = 3.7737767696380615\n",
      "step = 5521000: loss = 4.063823223114014\n",
      "step = 5521200: loss = 2.6095190048217773\n",
      "step = 5521400: loss = 3.279189109802246\n",
      "step = 5521600: loss = 4.330759525299072\n",
      "step = 5521800: loss = 2.760700225830078\n",
      "step = 5522000: loss = 4.015453338623047\n",
      "step = 5522200: loss = 3.5740575790405273\n",
      "step = 5522400: loss = 4.552173137664795\n",
      "step = 5522600: loss = 3.3257675170898438\n",
      "step = 5522800: loss = 4.603585720062256\n",
      "step = 5523000: loss = 3.0238354206085205\n",
      "step = 5523200: loss = 3.1977224349975586\n",
      "step = 5523400: loss = 2.9680066108703613\n",
      "step = 5523600: loss = 4.080999851226807\n",
      "step = 5523800: loss = 4.9072089195251465\n",
      "step = 5524000: loss = 4.109080791473389\n",
      "step = 5524200: loss = 3.0847485065460205\n",
      "step = 5524400: loss = 5.565217018127441\n",
      "step = 5524600: loss = 3.5837130546569824\n",
      "step = 5524800: loss = 4.007591247558594\n",
      "step = 5525000: loss = 4.005451679229736\n",
      "step = 5525000: Average Return = 4.5\n",
      "step = 5525200: loss = 3.835768461227417\n",
      "step = 5525400: loss = 4.745584487915039\n",
      "step = 5525600: loss = 3.730464458465576\n",
      "step = 5525800: loss = 3.591588020324707\n",
      "step = 5526000: loss = 4.1000847816467285\n",
      "step = 5526200: loss = 4.401204586029053\n",
      "step = 5526400: loss = 3.759247303009033\n",
      "step = 5526600: loss = 3.060056447982788\n",
      "step = 5526800: loss = 4.218451499938965\n",
      "step = 5527000: loss = 3.0102837085723877\n",
      "step = 5527200: loss = 3.473209857940674\n",
      "step = 5527400: loss = 4.5693583488464355\n",
      "step = 5527600: loss = 4.314603805541992\n",
      "step = 5527800: loss = 3.711824893951416\n",
      "step = 5528000: loss = 3.090254545211792\n",
      "step = 5528200: loss = 4.3198676109313965\n",
      "step = 5528400: loss = 3.425262689590454\n",
      "step = 5528600: loss = 3.750995397567749\n",
      "step = 5528800: loss = 3.8218061923980713\n",
      "step = 5529000: loss = 3.168355703353882\n",
      "step = 5529200: loss = 3.8755717277526855\n",
      "step = 5529400: loss = 3.2845330238342285\n",
      "step = 5529600: loss = 3.835035562515259\n",
      "step = 5529800: loss = 3.013955593109131\n",
      "step = 5530000: loss = 4.767203330993652\n",
      "step = 5530000: Average Return = 3.450000047683716\n",
      "step = 5530200: loss = 3.435642719268799\n",
      "step = 5530400: loss = 4.3639397621154785\n",
      "step = 5530600: loss = 4.00988245010376\n",
      "step = 5530800: loss = 4.00234317779541\n",
      "step = 5531000: loss = 3.701555013656616\n",
      "step = 5531200: loss = 3.962311267852783\n",
      "step = 5531400: loss = 3.5398499965667725\n",
      "step = 5531600: loss = 2.8694286346435547\n",
      "step = 5531800: loss = 4.546600341796875\n",
      "step = 5532000: loss = 2.9567668437957764\n",
      "step = 5532200: loss = 4.186607360839844\n",
      "step = 5532400: loss = 5.17287540435791\n",
      "step = 5532600: loss = 4.7107648849487305\n",
      "step = 5532800: loss = 3.7607803344726562\n",
      "step = 5533000: loss = 4.9554243087768555\n",
      "step = 5533200: loss = 4.087798595428467\n",
      "step = 5533400: loss = 4.491513729095459\n",
      "step = 5533600: loss = 4.346377849578857\n",
      "step = 5533800: loss = 3.5408618450164795\n",
      "step = 5534000: loss = 3.5642552375793457\n",
      "step = 5534200: loss = 3.9303081035614014\n",
      "step = 5534400: loss = 3.6881706714630127\n",
      "step = 5534600: loss = 3.147095203399658\n",
      "step = 5534800: loss = 4.225174903869629\n",
      "step = 5535000: loss = 4.478961944580078\n",
      "step = 5535000: Average Return = 2.3499999046325684\n",
      "step = 5535200: loss = 3.551360607147217\n",
      "step = 5535400: loss = 3.336475372314453\n",
      "step = 5535600: loss = 4.652912139892578\n",
      "step = 5535800: loss = 4.18463659286499\n",
      "step = 5536000: loss = 3.8012938499450684\n",
      "step = 5536200: loss = 3.5788700580596924\n",
      "step = 5536400: loss = 4.113306999206543\n",
      "step = 5536600: loss = 3.215493679046631\n",
      "step = 5536800: loss = 5.010310173034668\n",
      "step = 5537000: loss = 3.596919536590576\n",
      "step = 5537200: loss = 5.974318504333496\n",
      "step = 5537400: loss = 4.092398166656494\n",
      "step = 5537600: loss = 3.7664031982421875\n",
      "step = 5537800: loss = 3.1965138912200928\n",
      "step = 5538000: loss = 4.6504411697387695\n",
      "step = 5538200: loss = 3.6876165866851807\n",
      "step = 5538400: loss = 4.411050796508789\n",
      "step = 5538600: loss = 4.044074535369873\n",
      "step = 5538800: loss = 3.0671629905700684\n",
      "step = 5539000: loss = 3.647536039352417\n",
      "step = 5539200: loss = 3.262274742126465\n",
      "step = 5539400: loss = 3.9966423511505127\n",
      "step = 5539600: loss = 3.149967670440674\n",
      "step = 5539800: loss = 4.941420555114746\n",
      "step = 5540000: loss = 3.5585551261901855\n",
      "step = 5540000: Average Return = 2.8499999046325684\n",
      "step = 5540200: loss = 3.7707231044769287\n",
      "step = 5540400: loss = 3.677116632461548\n",
      "step = 5540600: loss = 2.485764503479004\n",
      "step = 5540800: loss = 2.645416259765625\n",
      "step = 5541000: loss = 5.140751838684082\n",
      "step = 5541200: loss = 5.179657936096191\n",
      "step = 5541400: loss = 2.8552370071411133\n",
      "step = 5541600: loss = 3.7169604301452637\n",
      "step = 5541800: loss = 4.1735148429870605\n",
      "step = 5542000: loss = 4.381904602050781\n",
      "step = 5542200: loss = 3.673252582550049\n",
      "step = 5542400: loss = 4.027426719665527\n",
      "step = 5542600: loss = 3.785095691680908\n",
      "step = 5542800: loss = 3.761748790740967\n",
      "step = 5543000: loss = 4.738570213317871\n",
      "step = 5543200: loss = 3.055467128753662\n",
      "step = 5543400: loss = 5.1921491622924805\n",
      "step = 5543600: loss = 4.325433731079102\n",
      "step = 5543800: loss = 3.632411479949951\n",
      "step = 5544000: loss = 4.54866886138916\n",
      "step = 5544200: loss = 1.9980584383010864\n",
      "step = 5544400: loss = 4.268428325653076\n",
      "step = 5544600: loss = 2.461643695831299\n",
      "step = 5544800: loss = 4.711677074432373\n",
      "step = 5545000: loss = 3.835679769515991\n",
      "step = 5545000: Average Return = 3.8499999046325684\n",
      "step = 5545200: loss = 3.0979974269866943\n",
      "step = 5545400: loss = 4.800995826721191\n",
      "step = 5545600: loss = 3.689039468765259\n",
      "step = 5545800: loss = 4.398207187652588\n",
      "step = 5546000: loss = 2.944253444671631\n",
      "step = 5546200: loss = 3.14713978767395\n",
      "step = 5546400: loss = 2.9146342277526855\n",
      "step = 5546600: loss = 3.7783684730529785\n",
      "step = 5546800: loss = 4.938364028930664\n",
      "step = 5547000: loss = 5.357156753540039\n",
      "step = 5547200: loss = 3.8725154399871826\n",
      "step = 5547400: loss = 2.78173828125\n",
      "step = 5547600: loss = 5.67300271987915\n",
      "step = 5547800: loss = 4.024318218231201\n",
      "step = 5548000: loss = 4.426941871643066\n",
      "step = 5548200: loss = 3.042255163192749\n",
      "step = 5548400: loss = 3.3258535861968994\n",
      "step = 5548600: loss = 4.857740879058838\n",
      "step = 5548800: loss = 3.753862142562866\n",
      "step = 5549000: loss = 4.00120210647583\n",
      "step = 5549200: loss = 4.664549350738525\n",
      "step = 5549400: loss = 3.805091142654419\n",
      "step = 5549600: loss = 2.219038724899292\n",
      "step = 5549800: loss = 2.680764675140381\n",
      "step = 5550000: loss = 2.6619341373443604\n",
      "step = 5550000: Average Return = 3.549999952316284\n",
      "step = 5550200: loss = 4.08514928817749\n",
      "step = 5550400: loss = 4.014467239379883\n",
      "step = 5550600: loss = 4.340837478637695\n",
      "step = 5550800: loss = 3.357431650161743\n",
      "step = 5551000: loss = 3.0163586139678955\n",
      "step = 5551200: loss = 3.5945653915405273\n",
      "step = 5551400: loss = 1.6794146299362183\n",
      "step = 5551600: loss = 4.0521955490112305\n",
      "step = 5551800: loss = 3.9174554347991943\n",
      "step = 5552000: loss = 3.9810023307800293\n",
      "step = 5552200: loss = 3.1174070835113525\n",
      "step = 5552400: loss = 2.368584632873535\n",
      "step = 5552600: loss = 3.7384774684906006\n",
      "step = 5552800: loss = 3.747032880783081\n",
      "step = 5553000: loss = 2.606740713119507\n",
      "step = 5553200: loss = 4.519309997558594\n",
      "step = 5553400: loss = 3.494539737701416\n",
      "step = 5553600: loss = 3.6844966411590576\n",
      "step = 5553800: loss = 3.399168014526367\n",
      "step = 5554000: loss = 3.9436962604522705\n",
      "step = 5554200: loss = 4.051487445831299\n",
      "step = 5554400: loss = 4.131267547607422\n",
      "step = 5554600: loss = 4.470921039581299\n",
      "step = 5554800: loss = 4.352208137512207\n",
      "step = 5555000: loss = 4.020632743835449\n",
      "step = 5555000: Average Return = 2.1500000953674316\n",
      "step = 5555200: loss = 4.312592029571533\n",
      "step = 5555400: loss = 3.890446662902832\n",
      "step = 5555600: loss = 3.568868398666382\n",
      "step = 5555800: loss = 4.826615333557129\n",
      "step = 5556000: loss = 3.182734251022339\n",
      "step = 5556200: loss = 3.1119799613952637\n",
      "step = 5556400: loss = 4.0622172355651855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 5556600: loss = 3.3918871879577637\n",
      "step = 5556800: loss = 3.7921338081359863\n",
      "step = 5557000: loss = 2.5414023399353027\n",
      "step = 5557200: loss = 3.2338597774505615\n",
      "step = 5557400: loss = 3.63557505607605\n",
      "step = 5557600: loss = 3.453627824783325\n",
      "step = 5557800: loss = 3.7245073318481445\n",
      "step = 5558000: loss = 3.676981210708618\n",
      "step = 5558200: loss = 4.538896560668945\n",
      "step = 5558400: loss = 4.1061859130859375\n",
      "step = 5558600: loss = 3.0177409648895264\n",
      "step = 5558800: loss = 2.351374626159668\n",
      "step = 5559000: loss = 4.033084869384766\n",
      "step = 5559200: loss = 2.5109779834747314\n",
      "step = 5559400: loss = 3.6293249130249023\n",
      "step = 5559600: loss = 3.32079815864563\n",
      "step = 5559800: loss = 3.7926928997039795\n",
      "step = 5560000: loss = 4.262950420379639\n",
      "step = 5560000: Average Return = 2.799999952316284\n",
      "step = 5560200: loss = 3.715139150619507\n",
      "step = 5560400: loss = 4.806708335876465\n",
      "step = 5560600: loss = 4.180427074432373\n",
      "step = 5560800: loss = 4.636449813842773\n",
      "step = 5561000: loss = 3.2196996212005615\n",
      "step = 5561200: loss = 2.6176059246063232\n",
      "step = 5561400: loss = 2.9179821014404297\n",
      "step = 5561600: loss = 2.8941972255706787\n",
      "step = 5561800: loss = 2.1665124893188477\n",
      "step = 5562000: loss = 3.904186725616455\n",
      "step = 5562200: loss = 4.59273099899292\n",
      "step = 5562400: loss = 2.6644608974456787\n",
      "step = 5562600: loss = 4.910582542419434\n",
      "step = 5562800: loss = 4.47182035446167\n",
      "step = 5563000: loss = 4.042662143707275\n",
      "step = 5563200: loss = 4.11199426651001\n",
      "step = 5563400: loss = 4.672529697418213\n",
      "step = 5563600: loss = 4.907427787780762\n",
      "step = 5563800: loss = 4.656213283538818\n",
      "step = 5564000: loss = 3.25949764251709\n",
      "step = 5564200: loss = 3.344869375228882\n",
      "step = 5564400: loss = 2.988574266433716\n",
      "step = 5564600: loss = 3.2141599655151367\n",
      "step = 5564800: loss = 4.539627552032471\n",
      "step = 5565000: loss = 3.966681718826294\n",
      "step = 5565000: Average Return = 3.9000000953674316\n",
      "step = 5565200: loss = 4.844107151031494\n",
      "step = 5565400: loss = 3.1483986377716064\n",
      "step = 5565600: loss = 4.187744140625\n",
      "step = 5565800: loss = 3.569596767425537\n",
      "step = 5566000: loss = 2.5176515579223633\n",
      "step = 5566200: loss = 3.4553117752075195\n",
      "step = 5566400: loss = 5.087168216705322\n",
      "step = 5566600: loss = 4.218647480010986\n",
      "step = 5566800: loss = 3.9455039501190186\n",
      "step = 5567000: loss = 3.702775478363037\n",
      "step = 5567200: loss = 3.6940886974334717\n",
      "step = 5567400: loss = 4.542049884796143\n",
      "step = 5567600: loss = 3.6737852096557617\n",
      "step = 5567800: loss = 3.379507303237915\n",
      "step = 5568000: loss = 3.0844922065734863\n",
      "step = 5568200: loss = 3.0408270359039307\n",
      "step = 5568400: loss = 4.64929723739624\n",
      "step = 5568600: loss = 4.054244518280029\n",
      "step = 5568800: loss = 3.0754759311676025\n",
      "step = 5569000: loss = 3.8280444145202637\n",
      "step = 5569200: loss = 4.2112531661987305\n",
      "step = 5569400: loss = 3.45231294631958\n",
      "step = 5569600: loss = 3.3768420219421387\n",
      "step = 5569800: loss = 4.6618781089782715\n",
      "step = 5570000: loss = 5.245307445526123\n",
      "step = 5570000: Average Return = 2.4000000953674316\n",
      "step = 5570200: loss = 3.5482988357543945\n",
      "step = 5570400: loss = 2.8367106914520264\n",
      "step = 5570600: loss = 3.0398669242858887\n",
      "step = 5570800: loss = 3.4088542461395264\n",
      "step = 5571000: loss = 3.8120405673980713\n",
      "step = 5571200: loss = 3.038548469543457\n",
      "step = 5571400: loss = 4.687601566314697\n",
      "step = 5571600: loss = 2.5226199626922607\n",
      "step = 5571800: loss = 3.4428350925445557\n",
      "step = 5572000: loss = 3.134228467941284\n",
      "step = 5572200: loss = 3.6813266277313232\n",
      "step = 5572400: loss = 3.821122884750366\n",
      "step = 5572600: loss = 4.5613694190979\n",
      "step = 5572800: loss = 4.371157646179199\n",
      "step = 5573000: loss = 4.318578243255615\n",
      "step = 5573200: loss = 3.5945756435394287\n",
      "step = 5573400: loss = 4.931253433227539\n",
      "step = 5573600: loss = 3.2474007606506348\n",
      "step = 5573800: loss = 4.238898277282715\n",
      "step = 5574000: loss = 2.856921434402466\n",
      "step = 5574200: loss = 2.7082438468933105\n",
      "step = 5574400: loss = 4.236430644989014\n",
      "step = 5574600: loss = 2.8775720596313477\n",
      "step = 5574800: loss = 3.4032719135284424\n",
      "step = 5575000: loss = 3.3146069049835205\n",
      "step = 5575000: Average Return = 2.799999952316284\n",
      "step = 5575200: loss = 3.415003776550293\n",
      "step = 5575400: loss = 4.484200477600098\n",
      "step = 5575600: loss = 4.252068519592285\n",
      "step = 5575800: loss = 3.2700414657592773\n",
      "step = 5576000: loss = 4.207374572753906\n",
      "step = 5576200: loss = 4.897465705871582\n",
      "step = 5576400: loss = 3.0151731967926025\n",
      "step = 5576600: loss = 2.2657666206359863\n",
      "step = 5576800: loss = 3.202679395675659\n",
      "step = 5577000: loss = 3.753901958465576\n",
      "step = 5577200: loss = 4.545379638671875\n",
      "step = 5577400: loss = 4.8509745597839355\n",
      "step = 5577600: loss = 4.787970066070557\n",
      "step = 5577800: loss = 3.9872872829437256\n",
      "step = 5578000: loss = 4.02862548828125\n",
      "step = 5578200: loss = 3.1910815238952637\n",
      "step = 5578400: loss = 4.695991516113281\n",
      "step = 5578600: loss = 3.211871862411499\n",
      "step = 5578800: loss = 4.660037040710449\n",
      "step = 5579000: loss = 3.1552038192749023\n",
      "step = 5579200: loss = 4.271755695343018\n",
      "step = 5579400: loss = 4.308284282684326\n",
      "step = 5579600: loss = 3.5296740531921387\n",
      "step = 5579800: loss = 4.725874423980713\n",
      "step = 5580000: loss = 4.412137031555176\n",
      "step = 5580000: Average Return = 3.0999999046325684\n",
      "step = 5580200: loss = 3.5976741313934326\n",
      "step = 5580400: loss = 4.62901496887207\n",
      "step = 5580600: loss = 3.7600789070129395\n",
      "step = 5580800: loss = 3.7637641429901123\n",
      "step = 5581000: loss = 3.813314199447632\n",
      "step = 5581200: loss = 4.077103137969971\n",
      "step = 5581400: loss = 2.8955981731414795\n",
      "step = 5581600: loss = 3.240818500518799\n",
      "step = 5581800: loss = 3.3592529296875\n",
      "step = 5582000: loss = 4.130797863006592\n",
      "step = 5582200: loss = 3.1838772296905518\n",
      "step = 5582400: loss = 4.41546630859375\n",
      "step = 5582600: loss = 4.335168838500977\n",
      "step = 5582800: loss = 3.4618775844573975\n",
      "step = 5583000: loss = 3.3937089443206787\n",
      "step = 5583200: loss = 4.5423760414123535\n",
      "step = 5583400: loss = 4.137412071228027\n",
      "step = 5583600: loss = 2.6241557598114014\n",
      "step = 5583800: loss = 3.6890947818756104\n",
      "step = 5584000: loss = 2.617673397064209\n",
      "step = 5584200: loss = 3.2824418544769287\n",
      "step = 5584400: loss = 3.402332305908203\n",
      "step = 5584600: loss = 3.5174267292022705\n",
      "step = 5584800: loss = 3.668917655944824\n",
      "step = 5585000: loss = 3.533822536468506\n",
      "step = 5585000: Average Return = 3.950000047683716\n",
      "step = 5585200: loss = 5.137000560760498\n",
      "step = 5585400: loss = 3.3462188243865967\n",
      "step = 5585600: loss = 4.546159267425537\n",
      "step = 5585800: loss = 3.5173072814941406\n",
      "step = 5586000: loss = 1.9630074501037598\n",
      "step = 5586200: loss = 3.8083746433258057\n",
      "step = 5586400: loss = 4.150246620178223\n",
      "step = 5586600: loss = 4.009695053100586\n",
      "step = 5586800: loss = 3.8844375610351562\n",
      "step = 5587000: loss = 3.397536516189575\n",
      "step = 5587200: loss = 3.889911413192749\n",
      "step = 5587400: loss = 3.8931963443756104\n",
      "step = 5587600: loss = 5.482170104980469\n",
      "step = 5587800: loss = 3.1342382431030273\n",
      "step = 5588000: loss = 3.7569289207458496\n",
      "step = 5588200: loss = 3.9268224239349365\n",
      "step = 5588400: loss = 3.7703967094421387\n",
      "step = 5588600: loss = 3.6412947177886963\n",
      "step = 5588800: loss = 4.328041076660156\n",
      "step = 5589000: loss = 5.022496700286865\n",
      "step = 5589200: loss = 4.390953063964844\n",
      "step = 5589400: loss = 2.0967886447906494\n",
      "step = 5589600: loss = 2.153059244155884\n",
      "step = 5589800: loss = 4.709439277648926\n",
      "step = 5590000: loss = 3.8329081535339355\n",
      "step = 5590000: Average Return = 3.9000000953674316\n",
      "step = 5590200: loss = 3.6382622718811035\n",
      "step = 5590400: loss = 3.7556209564208984\n",
      "step = 5590600: loss = 4.500808238983154\n",
      "step = 5590800: loss = 3.4783732891082764\n",
      "step = 5591000: loss = 6.035019874572754\n",
      "step = 5591200: loss = 5.542262077331543\n",
      "step = 5591400: loss = 3.875438690185547\n",
      "step = 5591600: loss = 4.530491828918457\n",
      "step = 5591800: loss = 3.9237546920776367\n",
      "step = 5592000: loss = 2.3304054737091064\n",
      "step = 5592200: loss = 2.4286627769470215\n",
      "step = 5592400: loss = 4.324251174926758\n",
      "step = 5592600: loss = 3.6721065044403076\n",
      "step = 5592800: loss = 3.4583632946014404\n",
      "step = 5593000: loss = 3.058872699737549\n",
      "step = 5593200: loss = 3.485912799835205\n",
      "step = 5593400: loss = 4.4087324142456055\n",
      "step = 5593600: loss = 3.0901482105255127\n",
      "step = 5593800: loss = 4.261897087097168\n",
      "step = 5594000: loss = 4.023419380187988\n",
      "step = 5594200: loss = 3.1298372745513916\n",
      "step = 5594400: loss = 3.879164695739746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 5594600: loss = 3.0516183376312256\n",
      "step = 5594800: loss = 4.048835277557373\n",
      "step = 5595000: loss = 3.020983934402466\n",
      "step = 5595000: Average Return = 3.9000000953674316\n",
      "step = 5595200: loss = 5.71762752532959\n",
      "step = 5595400: loss = 3.156559467315674\n",
      "step = 5595600: loss = 4.691064834594727\n",
      "step = 5595800: loss = 3.849257230758667\n",
      "step = 5596000: loss = 4.940438270568848\n",
      "step = 5596200: loss = 4.077723979949951\n",
      "step = 5596400: loss = 4.156989097595215\n",
      "step = 5596600: loss = 3.393066883087158\n",
      "step = 5596800: loss = 4.957149982452393\n",
      "step = 5597000: loss = 4.57788610458374\n",
      "step = 5597200: loss = 5.217546463012695\n",
      "step = 5597400: loss = 2.973196268081665\n",
      "step = 5597600: loss = 4.800825119018555\n",
      "step = 5597800: loss = 4.265101432800293\n",
      "step = 5598000: loss = 4.577101707458496\n",
      "step = 5598200: loss = 3.3291337490081787\n",
      "step = 5598400: loss = 3.669100761413574\n",
      "step = 5598600: loss = 4.123137950897217\n",
      "step = 5598800: loss = 2.9494965076446533\n",
      "step = 5599000: loss = 4.461104869842529\n",
      "step = 5599200: loss = 4.1714653968811035\n",
      "step = 5599400: loss = 3.647017240524292\n",
      "step = 5599600: loss = 5.151060104370117\n",
      "step = 5599800: loss = 2.075105905532837\n",
      "step = 5600000: loss = 3.964803695678711\n",
      "step = 5600000: Average Return = 2.5999999046325684\n",
      "step = 5600200: loss = 3.7829082012176514\n",
      "step = 5600400: loss = 3.7323074340820312\n",
      "step = 5600600: loss = 4.156379222869873\n",
      "step = 5600800: loss = 4.422935485839844\n",
      "step = 5601000: loss = 3.951364278793335\n",
      "step = 5601200: loss = 2.914479970932007\n",
      "step = 5601400: loss = 2.771742582321167\n",
      "step = 5601600: loss = 4.081245422363281\n",
      "step = 5601800: loss = 2.9156999588012695\n",
      "step = 5602000: loss = 4.099532604217529\n",
      "step = 5602200: loss = 4.0042009353637695\n",
      "step = 5602400: loss = 3.5369927883148193\n",
      "step = 5602600: loss = 2.5846164226531982\n",
      "step = 5602800: loss = 3.2825589179992676\n",
      "step = 5603000: loss = 2.908148765563965\n",
      "step = 5603200: loss = 2.473195791244507\n",
      "step = 5603400: loss = 3.3683812618255615\n",
      "step = 5603600: loss = 4.258018970489502\n",
      "step = 5603800: loss = 2.2425343990325928\n",
      "step = 5604000: loss = 3.3168246746063232\n",
      "step = 5604200: loss = 3.6855685710906982\n",
      "step = 5604400: loss = 3.0869805812835693\n",
      "step = 5604600: loss = 4.89990234375\n",
      "step = 5604800: loss = 3.962994337081909\n",
      "step = 5605000: loss = 3.4032678604125977\n",
      "step = 5605000: Average Return = 3.049999952316284\n",
      "step = 5605200: loss = 3.8227148056030273\n",
      "step = 5605400: loss = 3.82010555267334\n",
      "step = 5605600: loss = 3.5811872482299805\n",
      "step = 5605800: loss = 4.411684989929199\n",
      "step = 5606000: loss = 4.824289798736572\n",
      "step = 5606200: loss = 2.4031670093536377\n",
      "step = 5606400: loss = 3.609833002090454\n",
      "step = 5606600: loss = 4.5159711837768555\n",
      "step = 5606800: loss = 3.2613604068756104\n",
      "step = 5607000: loss = 3.53475022315979\n",
      "step = 5607200: loss = 4.128999710083008\n",
      "step = 5607400: loss = 3.3741228580474854\n",
      "step = 5607600: loss = 3.1329259872436523\n",
      "step = 5607800: loss = 4.466073036193848\n",
      "step = 5608000: loss = 2.8427515029907227\n",
      "step = 5608200: loss = 3.55657958984375\n",
      "step = 5608400: loss = 2.8977270126342773\n",
      "step = 5608600: loss = 3.2092833518981934\n",
      "step = 5608800: loss = 3.828338623046875\n",
      "step = 5609000: loss = 4.042101860046387\n",
      "step = 5609200: loss = 3.7866740226745605\n",
      "step = 5609400: loss = 4.340774059295654\n",
      "step = 5609600: loss = 2.836031436920166\n",
      "step = 5609800: loss = 3.3119726181030273\n",
      "step = 5610000: loss = 3.644707441329956\n",
      "step = 5610000: Average Return = 3.5999999046325684\n",
      "step = 5610200: loss = 3.276337146759033\n",
      "step = 5610400: loss = 4.308365345001221\n",
      "step = 5610600: loss = 3.7470104694366455\n",
      "step = 5610800: loss = 5.097100257873535\n",
      "step = 5611000: loss = 5.669490814208984\n",
      "step = 5611200: loss = 3.512096881866455\n",
      "step = 5611400: loss = 3.0342166423797607\n",
      "step = 5611600: loss = 4.352165222167969\n",
      "step = 5611800: loss = 3.828545331954956\n",
      "step = 5612000: loss = 3.489764928817749\n",
      "step = 5612200: loss = 3.9606175422668457\n",
      "step = 5612400: loss = 4.115140914916992\n",
      "step = 5612600: loss = 3.6718783378601074\n",
      "step = 5612800: loss = 5.392086029052734\n",
      "step = 5613000: loss = 4.1491618156433105\n",
      "step = 5613200: loss = 5.083049774169922\n",
      "step = 5613400: loss = 5.07607364654541\n",
      "step = 5613600: loss = 4.575900077819824\n",
      "step = 5613800: loss = 4.739889621734619\n",
      "step = 5614000: loss = 4.699130535125732\n",
      "step = 5614200: loss = 3.76241135597229\n",
      "step = 5614400: loss = 4.375333786010742\n",
      "step = 5614600: loss = 4.037933349609375\n",
      "step = 5614800: loss = 3.914240598678589\n",
      "step = 5615000: loss = 3.949503183364868\n",
      "step = 5615000: Average Return = 2.0\n",
      "step = 5615200: loss = 4.209205150604248\n",
      "step = 5615400: loss = 3.8039870262145996\n",
      "step = 5615600: loss = 3.26704740524292\n",
      "step = 5615800: loss = 3.9207801818847656\n",
      "step = 5616000: loss = 3.206923246383667\n",
      "step = 5616200: loss = 3.8605058193206787\n",
      "step = 5616400: loss = 3.4683821201324463\n",
      "step = 5616600: loss = 3.129830837249756\n",
      "step = 5616800: loss = 2.9874048233032227\n",
      "step = 5617000: loss = 4.619909763336182\n",
      "step = 5617200: loss = 4.339722156524658\n",
      "step = 5617400: loss = 4.6367411613464355\n",
      "step = 5617600: loss = 2.91911244392395\n",
      "step = 5617800: loss = 3.9751031398773193\n",
      "step = 5618000: loss = 3.6305766105651855\n",
      "step = 5618200: loss = 4.567371845245361\n",
      "step = 5618400: loss = 4.351651668548584\n",
      "step = 5618600: loss = 3.8435966968536377\n",
      "step = 5618800: loss = 4.308126926422119\n",
      "step = 5619000: loss = 3.8283233642578125\n",
      "step = 5619200: loss = 4.365634441375732\n",
      "step = 5619400: loss = 3.5481138229370117\n",
      "step = 5619600: loss = 3.2538163661956787\n",
      "step = 5619800: loss = 3.440424680709839\n",
      "step = 5620000: loss = 3.2753496170043945\n",
      "step = 5620000: Average Return = 3.700000047683716\n",
      "step = 5620200: loss = 4.406519889831543\n",
      "step = 5620400: loss = 5.129111289978027\n",
      "step = 5620600: loss = 4.293441295623779\n",
      "step = 5620800: loss = 4.293699741363525\n",
      "step = 5621000: loss = 6.105691909790039\n",
      "step = 5621200: loss = 3.8502984046936035\n",
      "step = 5621400: loss = 2.8479418754577637\n",
      "step = 5621600: loss = 4.069192409515381\n",
      "step = 5621800: loss = 3.2944586277008057\n",
      "step = 5622000: loss = 3.4010026454925537\n",
      "step = 5622200: loss = 2.9537272453308105\n",
      "step = 5622400: loss = 3.461310386657715\n",
      "step = 5622600: loss = 3.147345542907715\n",
      "step = 5622800: loss = 2.704716205596924\n",
      "step = 5623000: loss = 3.3959078788757324\n",
      "step = 5623200: loss = 3.835299491882324\n",
      "step = 5623400: loss = 2.885235548019409\n",
      "step = 5623600: loss = 3.147684335708618\n",
      "step = 5623800: loss = 3.485637664794922\n",
      "step = 5624000: loss = 4.855538368225098\n",
      "step = 5624200: loss = 3.6373510360717773\n",
      "step = 5624400: loss = 3.329683780670166\n",
      "step = 5624600: loss = 4.375141620635986\n",
      "step = 5624800: loss = 5.3075127601623535\n",
      "step = 5625000: loss = 3.8659474849700928\n",
      "step = 5625000: Average Return = 3.3499999046325684\n",
      "step = 5625200: loss = 3.422996759414673\n",
      "step = 5625400: loss = 3.390310049057007\n",
      "step = 5625600: loss = 2.3967556953430176\n",
      "step = 5625800: loss = 5.025304794311523\n",
      "step = 5626000: loss = 3.5394461154937744\n",
      "step = 5626200: loss = 3.2305803298950195\n",
      "step = 5626400: loss = 4.343171119689941\n",
      "step = 5626600: loss = 4.2151384353637695\n",
      "step = 5626800: loss = 3.414083242416382\n",
      "step = 5627000: loss = 3.2889583110809326\n",
      "step = 5627200: loss = 3.6985859870910645\n",
      "step = 5627400: loss = 4.141623020172119\n",
      "step = 5627600: loss = 3.1402904987335205\n",
      "step = 5627800: loss = 3.873297691345215\n",
      "step = 5628000: loss = 3.309798240661621\n",
      "step = 5628200: loss = 4.098907470703125\n",
      "step = 5628400: loss = 3.6849000453948975\n",
      "step = 5628600: loss = 4.0702691078186035\n",
      "step = 5628800: loss = 3.4934561252593994\n",
      "step = 5629000: loss = 2.7879717350006104\n",
      "step = 5629200: loss = 3.0911619663238525\n",
      "step = 5629400: loss = 3.8714239597320557\n",
      "step = 5629600: loss = 5.431368350982666\n",
      "step = 5629800: loss = 2.2759039402008057\n",
      "step = 5630000: loss = 4.1276535987854\n",
      "step = 5630000: Average Return = 5.050000190734863\n",
      "step = 5630200: loss = 2.5108931064605713\n",
      "step = 5630400: loss = 4.658083915710449\n",
      "step = 5630600: loss = 4.543623924255371\n",
      "step = 5630800: loss = 4.013113975524902\n",
      "step = 5631000: loss = 3.463876247406006\n",
      "step = 5631200: loss = 4.003695487976074\n",
      "step = 5631400: loss = 5.673785209655762\n",
      "step = 5631600: loss = 4.715237140655518\n",
      "step = 5631800: loss = 4.48823881149292\n",
      "step = 5632000: loss = 3.236154794692993\n",
      "step = 5632200: loss = 5.060194969177246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 5632400: loss = 3.9353911876678467\n",
      "step = 5632600: loss = 2.834702730178833\n",
      "step = 5632800: loss = 4.0215067863464355\n",
      "step = 5633000: loss = 4.0636982917785645\n",
      "step = 5633200: loss = 3.5898001194000244\n",
      "step = 5633400: loss = 4.097507953643799\n",
      "step = 5633600: loss = 3.466278553009033\n",
      "step = 5633800: loss = 4.661377906799316\n",
      "step = 5634000: loss = 3.7770323753356934\n",
      "step = 5634200: loss = 4.389476776123047\n",
      "step = 5634400: loss = 4.10878324508667\n",
      "step = 5634600: loss = 5.310179233551025\n",
      "step = 5634800: loss = 4.682488441467285\n",
      "step = 5635000: loss = 3.2929842472076416\n",
      "step = 5635000: Average Return = 5.400000095367432\n",
      "step = 5635200: loss = 3.1077828407287598\n",
      "step = 5635400: loss = 4.190389156341553\n",
      "step = 5635600: loss = 4.231508731842041\n",
      "step = 5635800: loss = 4.25864315032959\n",
      "step = 5636000: loss = 4.395023822784424\n",
      "step = 5636200: loss = 4.736698627471924\n",
      "step = 5636400: loss = 3.002823829650879\n",
      "step = 5636600: loss = 3.383260488510132\n",
      "step = 5636800: loss = 4.189484596252441\n",
      "step = 5637000: loss = 3.4637370109558105\n",
      "step = 5637200: loss = 4.4139275550842285\n",
      "step = 5637400: loss = 4.130756378173828\n",
      "step = 5637600: loss = 4.30847692489624\n",
      "step = 5637800: loss = 4.387959003448486\n",
      "step = 5638000: loss = 4.012536525726318\n",
      "step = 5638200: loss = 6.396824836730957\n",
      "step = 5638400: loss = 3.2576394081115723\n",
      "step = 5638600: loss = 3.45809268951416\n",
      "step = 5638800: loss = 4.0484209060668945\n",
      "step = 5639000: loss = 4.021746635437012\n",
      "step = 5639200: loss = 4.451785564422607\n",
      "step = 5639400: loss = 4.213545322418213\n",
      "step = 5639600: loss = 3.4437248706817627\n",
      "step = 5639800: loss = 3.2214622497558594\n",
      "step = 5640000: loss = 3.5564706325531006\n",
      "step = 5640000: Average Return = 3.4000000953674316\n",
      "step = 5640200: loss = 2.9559571743011475\n",
      "step = 5640400: loss = 3.679511308670044\n",
      "step = 5640600: loss = 4.115372657775879\n",
      "step = 5640800: loss = 3.049805164337158\n",
      "step = 5641000: loss = 3.026637554168701\n",
      "step = 5641200: loss = 2.9403581619262695\n",
      "step = 5641400: loss = 4.112407207489014\n",
      "step = 5641600: loss = 4.504613399505615\n",
      "step = 5641800: loss = 4.470438480377197\n",
      "step = 5642000: loss = 3.8597536087036133\n",
      "step = 5642200: loss = 2.9481618404388428\n",
      "step = 5642400: loss = 3.836560010910034\n",
      "step = 5642600: loss = 3.7074596881866455\n",
      "step = 5642800: loss = 4.053678512573242\n",
      "step = 5643000: loss = 3.716852903366089\n",
      "step = 5643200: loss = 6.010370254516602\n",
      "step = 5643400: loss = 4.648437976837158\n",
      "step = 5643600: loss = 3.1287012100219727\n",
      "step = 5643800: loss = 3.8411190509796143\n",
      "step = 5644000: loss = 4.423511981964111\n",
      "step = 5644200: loss = 3.7922816276550293\n",
      "step = 5644400: loss = 3.7913506031036377\n",
      "step = 5644600: loss = 3.355585813522339\n",
      "step = 5644800: loss = 4.3849005699157715\n",
      "step = 5645000: loss = 3.10827374458313\n",
      "step = 5645000: Average Return = 6.25\n",
      "step = 5645200: loss = 3.6718358993530273\n",
      "step = 5645400: loss = 4.430821418762207\n",
      "step = 5645600: loss = 3.6366593837738037\n",
      "step = 5645800: loss = 2.999154567718506\n",
      "step = 5646000: loss = 3.6568145751953125\n",
      "step = 5646200: loss = 2.844269037246704\n",
      "step = 5646400: loss = 2.5165927410125732\n",
      "step = 5646600: loss = 3.720763683319092\n",
      "step = 5646800: loss = 3.972804546356201\n",
      "step = 5647000: loss = 3.4274661540985107\n",
      "step = 5647200: loss = 2.7239654064178467\n",
      "step = 5647400: loss = 3.4525370597839355\n",
      "step = 5647600: loss = 4.936546325683594\n",
      "step = 5647800: loss = 4.301555156707764\n",
      "step = 5648000: loss = 4.634139537811279\n",
      "step = 5648200: loss = 3.6157305240631104\n",
      "step = 5648400: loss = 2.722846031188965\n",
      "step = 5648600: loss = 4.75577449798584\n",
      "step = 5648800: loss = 4.29044771194458\n",
      "step = 5649000: loss = 3.4602203369140625\n",
      "step = 5649200: loss = 2.8385283946990967\n",
      "step = 5649400: loss = 2.7133898735046387\n",
      "step = 5649600: loss = 4.727840900421143\n",
      "step = 5649800: loss = 4.405903339385986\n",
      "step = 5650000: loss = 3.9478206634521484\n",
      "step = 5650000: Average Return = 2.700000047683716\n",
      "step = 5650200: loss = 3.6351985931396484\n",
      "step = 5650400: loss = 2.6509928703308105\n",
      "step = 5650600: loss = 4.110508441925049\n",
      "step = 5650800: loss = 4.491722583770752\n",
      "step = 5651000: loss = 4.690926551818848\n",
      "step = 5651200: loss = 3.798879861831665\n",
      "step = 5651400: loss = 4.721956253051758\n",
      "step = 5651600: loss = 2.992997884750366\n",
      "step = 5651800: loss = 4.104336738586426\n",
      "step = 5652000: loss = 3.6383233070373535\n",
      "step = 5652200: loss = 4.1703314781188965\n",
      "step = 5652400: loss = 2.9741973876953125\n",
      "step = 5652600: loss = 5.153811931610107\n",
      "step = 5652800: loss = 4.286135196685791\n",
      "step = 5653000: loss = 2.843656539916992\n",
      "step = 5653200: loss = 4.267749309539795\n",
      "step = 5653400: loss = 3.3842849731445312\n",
      "step = 5653600: loss = 3.38619065284729\n",
      "step = 5653800: loss = 3.3814568519592285\n",
      "step = 5654000: loss = 3.4622802734375\n",
      "step = 5654200: loss = 2.825793743133545\n",
      "step = 5654400: loss = 3.6693530082702637\n",
      "step = 5654600: loss = 4.108773231506348\n",
      "step = 5654800: loss = 3.356995105743408\n",
      "step = 5655000: loss = 4.843757152557373\n",
      "step = 5655000: Average Return = 4.449999809265137\n",
      "step = 5655200: loss = 3.4252562522888184\n",
      "step = 5655400: loss = 3.2850117683410645\n",
      "step = 5655600: loss = 3.432964324951172\n",
      "step = 5655800: loss = 4.795834541320801\n",
      "step = 5656000: loss = 4.5761260986328125\n",
      "step = 5656200: loss = 2.92073392868042\n",
      "step = 5656400: loss = 4.2680768966674805\n",
      "step = 5656600: loss = 3.390761137008667\n",
      "step = 5656800: loss = 4.155345916748047\n",
      "step = 5657000: loss = 2.7409820556640625\n",
      "step = 5657200: loss = 3.4670000076293945\n",
      "step = 5657400: loss = 4.713884353637695\n",
      "step = 5657600: loss = 3.9398033618927\n",
      "step = 5657800: loss = 4.914064884185791\n",
      "step = 5658000: loss = 4.520301818847656\n",
      "step = 5658200: loss = 4.210230350494385\n",
      "step = 5658400: loss = 4.295226573944092\n",
      "step = 5658600: loss = 4.38606595993042\n",
      "step = 5658800: loss = 3.271472692489624\n",
      "step = 5659000: loss = 5.168185710906982\n",
      "step = 5659200: loss = 5.234259128570557\n",
      "step = 5659400: loss = 4.346944332122803\n",
      "step = 5659600: loss = 4.3804612159729\n",
      "step = 5659800: loss = 2.7482800483703613\n",
      "step = 5660000: loss = 3.480764389038086\n",
      "step = 5660000: Average Return = 3.549999952316284\n",
      "step = 5660200: loss = 4.441286087036133\n",
      "step = 5660400: loss = 3.64719295501709\n",
      "step = 5660600: loss = 2.646388292312622\n",
      "step = 5660800: loss = 3.3245134353637695\n",
      "step = 5661000: loss = 3.689441680908203\n",
      "step = 5661200: loss = 2.692749500274658\n",
      "step = 5661400: loss = 3.747256278991699\n",
      "step = 5661600: loss = 3.64776611328125\n",
      "step = 5661800: loss = 4.899775505065918\n",
      "step = 5662000: loss = 4.366392135620117\n",
      "step = 5662200: loss = 4.781152725219727\n",
      "step = 5662400: loss = 3.369802713394165\n",
      "step = 5662600: loss = 4.469365119934082\n",
      "step = 5662800: loss = 3.8822405338287354\n",
      "step = 5663000: loss = 5.136377334594727\n",
      "step = 5663200: loss = 4.009763717651367\n",
      "step = 5663400: loss = 4.683736801147461\n",
      "step = 5663600: loss = 3.3600542545318604\n",
      "step = 5663800: loss = 3.2912440299987793\n",
      "step = 5664000: loss = 3.3881325721740723\n",
      "step = 5664200: loss = 3.5565996170043945\n",
      "step = 5664400: loss = 5.290224552154541\n",
      "step = 5664600: loss = 3.857802152633667\n",
      "step = 5664800: loss = 3.7426726818084717\n",
      "step = 5665000: loss = 3.9379055500030518\n",
      "step = 5665000: Average Return = 2.25\n",
      "step = 5665200: loss = 3.3173766136169434\n",
      "step = 5665400: loss = 4.158059120178223\n",
      "step = 5665600: loss = 3.5552079677581787\n",
      "step = 5665800: loss = 3.147480010986328\n",
      "step = 5666000: loss = 4.134344577789307\n",
      "step = 5666200: loss = 2.6179604530334473\n",
      "step = 5666400: loss = 2.841522455215454\n",
      "step = 5666600: loss = 4.541708469390869\n",
      "step = 5666800: loss = 3.868783473968506\n",
      "step = 5667000: loss = 4.756464958190918\n",
      "step = 5667200: loss = 3.762815475463867\n",
      "step = 5667400: loss = 3.3087894916534424\n",
      "step = 5667600: loss = 4.018833160400391\n",
      "step = 5667800: loss = 3.0857317447662354\n",
      "step = 5668000: loss = 3.223710536956787\n",
      "step = 5668200: loss = 4.655832290649414\n",
      "step = 5668400: loss = 4.654303550720215\n",
      "step = 5668600: loss = 3.006179094314575\n",
      "step = 5668800: loss = 3.149493932723999\n",
      "step = 5669000: loss = 3.8777928352355957\n",
      "step = 5669200: loss = 3.651974678039551\n",
      "step = 5669400: loss = 4.435968399047852\n",
      "step = 5669600: loss = 3.647066593170166\n",
      "step = 5669800: loss = 3.963452100753784\n",
      "step = 5670000: loss = 3.9677674770355225\n",
      "step = 5670000: Average Return = 3.950000047683716\n",
      "step = 5670200: loss = 4.599336624145508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 5670400: loss = 4.614774227142334\n",
      "step = 5670600: loss = 4.189071178436279\n",
      "step = 5670800: loss = 3.8196911811828613\n",
      "step = 5671000: loss = 4.5907182693481445\n",
      "step = 5671200: loss = 3.415631055831909\n",
      "step = 5671400: loss = 5.6689677238464355\n",
      "step = 5671600: loss = 4.710050106048584\n",
      "step = 5671800: loss = 4.417875289916992\n",
      "step = 5672000: loss = 4.6897077560424805\n",
      "step = 5672200: loss = 3.5205814838409424\n",
      "step = 5672400: loss = 3.6897783279418945\n",
      "step = 5672600: loss = 3.876835823059082\n",
      "step = 5672800: loss = 3.711320638656616\n",
      "step = 5673000: loss = 4.242900848388672\n",
      "step = 5673200: loss = 4.82196569442749\n",
      "step = 5673400: loss = 4.4305338859558105\n",
      "step = 5673600: loss = 5.16572904586792\n",
      "step = 5673800: loss = 4.276946544647217\n",
      "step = 5674000: loss = 3.7817745208740234\n",
      "step = 5674200: loss = 5.453071594238281\n",
      "step = 5674400: loss = 4.07053804397583\n",
      "step = 5674600: loss = 4.03800106048584\n",
      "step = 5674800: loss = 3.5485527515411377\n",
      "step = 5675000: loss = 4.7115936279296875\n",
      "step = 5675000: Average Return = 4.599999904632568\n",
      "step = 5675200: loss = 3.868492841720581\n",
      "step = 5675400: loss = 3.619378089904785\n",
      "step = 5675600: loss = 3.699864387512207\n",
      "step = 5675800: loss = 2.877734661102295\n",
      "step = 5676000: loss = 3.881667375564575\n",
      "step = 5676200: loss = 2.74349308013916\n",
      "step = 5676400: loss = 2.47102427482605\n",
      "step = 5676600: loss = 3.818572521209717\n",
      "step = 5676800: loss = 4.256986141204834\n",
      "step = 5677000: loss = 3.2690086364746094\n",
      "step = 5677200: loss = 3.60269832611084\n",
      "step = 5677400: loss = 4.741261959075928\n",
      "step = 5677600: loss = 3.476050853729248\n",
      "step = 5677800: loss = 3.68656849861145\n",
      "step = 5678000: loss = 4.132254600524902\n",
      "step = 5678200: loss = 4.946188449859619\n",
      "step = 5678400: loss = 3.7827627658843994\n",
      "step = 5678600: loss = 5.132415771484375\n",
      "step = 5678800: loss = 5.160523414611816\n",
      "step = 5679000: loss = 3.234467029571533\n",
      "step = 5679200: loss = 3.709512948989868\n",
      "step = 5679400: loss = 5.029878616333008\n",
      "step = 5679600: loss = 4.0173749923706055\n",
      "step = 5679800: loss = 3.649955987930298\n",
      "step = 5680000: loss = 3.9245765209198\n",
      "step = 5680000: Average Return = 4.949999809265137\n",
      "step = 5680200: loss = 3.1664443016052246\n",
      "step = 5680400: loss = 3.752977132797241\n",
      "step = 5680600: loss = 3.37558650970459\n",
      "step = 5680800: loss = 4.717065334320068\n",
      "step = 5681000: loss = 3.3164281845092773\n",
      "step = 5681200: loss = 2.6378917694091797\n",
      "step = 5681400: loss = 3.3430469036102295\n",
      "step = 5681600: loss = 3.784524440765381\n",
      "step = 5681800: loss = 3.883327007293701\n",
      "step = 5682000: loss = 4.204349994659424\n",
      "step = 5682200: loss = 2.885420083999634\n",
      "step = 5682400: loss = 4.356550693511963\n",
      "step = 5682600: loss = 3.623504638671875\n",
      "step = 5682800: loss = 3.384171724319458\n",
      "step = 5683000: loss = 4.590494155883789\n",
      "step = 5683200: loss = 4.037567615509033\n",
      "step = 5683400: loss = 3.410330057144165\n",
      "step = 5683600: loss = 3.9933106899261475\n",
      "step = 5683800: loss = 3.435056686401367\n",
      "step = 5684000: loss = 4.153886795043945\n",
      "step = 5684200: loss = 4.32666540145874\n",
      "step = 5684400: loss = 3.758430004119873\n",
      "step = 5684600: loss = 3.6563708782196045\n",
      "step = 5684800: loss = 3.183267831802368\n",
      "step = 5685000: loss = 4.047966480255127\n",
      "step = 5685000: Average Return = 5.0\n",
      "step = 5685200: loss = 2.98010516166687\n",
      "step = 5685400: loss = 4.106847763061523\n",
      "step = 5685600: loss = 5.191497802734375\n",
      "step = 5685800: loss = 5.7366623878479\n",
      "step = 5686000: loss = 4.082957744598389\n",
      "step = 5686200: loss = 3.314791202545166\n",
      "step = 5686400: loss = 3.7125637531280518\n",
      "step = 5686600: loss = 4.957379341125488\n",
      "step = 5686800: loss = 3.4782042503356934\n",
      "step = 5687000: loss = 4.002863883972168\n",
      "step = 5687200: loss = 3.719804525375366\n",
      "step = 5687400: loss = 3.1309149265289307\n",
      "step = 5687600: loss = 3.7054443359375\n",
      "step = 5687800: loss = 3.059861421585083\n",
      "step = 5688000: loss = 4.322014808654785\n",
      "step = 5688200: loss = 3.8380675315856934\n",
      "step = 5688400: loss = 2.9504082202911377\n",
      "step = 5688600: loss = 3.7814178466796875\n",
      "step = 5688800: loss = 2.0600764751434326\n",
      "step = 5689000: loss = 3.930610179901123\n",
      "step = 5689200: loss = 3.92075252532959\n",
      "step = 5689400: loss = 2.962993621826172\n",
      "step = 5689600: loss = 2.890428066253662\n",
      "step = 5689800: loss = 2.560587167739868\n",
      "step = 5690000: loss = 4.180600166320801\n",
      "step = 5690000: Average Return = 4.650000095367432\n",
      "step = 5690200: loss = 4.228533744812012\n",
      "step = 5690400: loss = 4.116021156311035\n",
      "step = 5690600: loss = 4.454962253570557\n",
      "step = 5690800: loss = 4.7771897315979\n",
      "step = 5691000: loss = 3.9964988231658936\n",
      "step = 5691200: loss = 4.081358432769775\n",
      "step = 5691400: loss = 5.86762809753418\n",
      "step = 5691600: loss = 3.355867862701416\n",
      "step = 5691800: loss = 3.19089412689209\n",
      "step = 5692000: loss = 4.24592924118042\n",
      "step = 5692200: loss = 4.618706226348877\n",
      "step = 5692400: loss = 3.081887722015381\n",
      "step = 5692600: loss = 4.271613121032715\n",
      "step = 5692800: loss = 3.4488234519958496\n",
      "step = 5693000: loss = 2.5975546836853027\n",
      "step = 5693200: loss = 3.330157995223999\n",
      "step = 5693400: loss = 4.161860942840576\n",
      "step = 5693600: loss = 4.070934295654297\n",
      "step = 5693800: loss = 4.62063455581665\n",
      "step = 5694000: loss = 3.251202344894409\n",
      "step = 5694200: loss = 3.0970349311828613\n",
      "step = 5694400: loss = 5.424068450927734\n",
      "step = 5694600: loss = 4.504554748535156\n",
      "step = 5694800: loss = 3.579396963119507\n",
      "step = 5695000: loss = 5.346080780029297\n",
      "step = 5695000: Average Return = 3.0999999046325684\n",
      "step = 5695200: loss = 3.860926628112793\n",
      "step = 5695400: loss = 4.892548084259033\n",
      "step = 5695600: loss = 3.69994854927063\n",
      "step = 5695800: loss = 4.670510292053223\n",
      "step = 5696000: loss = 3.3052613735198975\n",
      "step = 5696200: loss = 3.6111507415771484\n",
      "step = 5696400: loss = 4.066476821899414\n",
      "step = 5696600: loss = 3.6746232509613037\n",
      "step = 5696800: loss = 3.393052339553833\n",
      "step = 5697000: loss = 4.054664611816406\n",
      "step = 5697200: loss = 4.450301170349121\n",
      "step = 5697400: loss = 2.812457799911499\n",
      "step = 5697600: loss = 3.2641732692718506\n",
      "step = 5697800: loss = 4.8221306800842285\n",
      "step = 5698000: loss = 4.5012617111206055\n",
      "step = 5698200: loss = 3.699971914291382\n",
      "step = 5698400: loss = 4.054147720336914\n",
      "step = 5698600: loss = 4.804488182067871\n",
      "step = 5698800: loss = 4.559442520141602\n",
      "step = 5699000: loss = 4.073480606079102\n",
      "step = 5699200: loss = 3.5875511169433594\n",
      "step = 5699400: loss = 4.895563125610352\n",
      "step = 5699600: loss = 5.521090984344482\n",
      "step = 5699800: loss = 3.7737998962402344\n",
      "step = 5700000: loss = 3.8243889808654785\n",
      "step = 5700000: Average Return = 3.3499999046325684\n",
      "step = 5700200: loss = 3.7389156818389893\n",
      "step = 5700400: loss = 4.091420650482178\n",
      "step = 5700600: loss = 4.616508960723877\n",
      "step = 5700800: loss = 2.9546728134155273\n",
      "step = 5701000: loss = 4.064058303833008\n",
      "step = 5701200: loss = 3.291970729827881\n",
      "step = 5701400: loss = 4.054347991943359\n",
      "step = 5701600: loss = 3.6538631916046143\n",
      "step = 5701800: loss = 2.8819055557250977\n",
      "step = 5702000: loss = 3.74772310256958\n",
      "step = 5702200: loss = 3.046053171157837\n",
      "step = 5702400: loss = 3.6539809703826904\n",
      "step = 5702600: loss = 4.469827651977539\n",
      "step = 5702800: loss = 4.026729583740234\n",
      "step = 5703000: loss = 3.2627196311950684\n",
      "step = 5703200: loss = 4.6236891746521\n",
      "step = 5703400: loss = 3.434117317199707\n",
      "step = 5703600: loss = 3.0486667156219482\n",
      "step = 5703800: loss = 3.0504117012023926\n",
      "step = 5704000: loss = 3.251969337463379\n",
      "step = 5704200: loss = 3.247206449508667\n",
      "step = 5704400: loss = 4.718674659729004\n",
      "step = 5704600: loss = 3.9542198181152344\n",
      "step = 5704800: loss = 4.967288494110107\n",
      "step = 5705000: loss = 4.28523063659668\n",
      "step = 5705000: Average Return = 3.25\n",
      "step = 5705200: loss = 3.0255565643310547\n",
      "step = 5705400: loss = 4.063113212585449\n",
      "step = 5705600: loss = 3.745708465576172\n",
      "step = 5705800: loss = 3.5762197971343994\n",
      "step = 5706000: loss = 2.4607479572296143\n",
      "step = 5706200: loss = 3.82934308052063\n",
      "step = 5706400: loss = 2.6270790100097656\n",
      "step = 5706600: loss = 4.1205339431762695\n",
      "step = 5706800: loss = 3.715470552444458\n",
      "step = 5707000: loss = 3.0860393047332764\n",
      "step = 5707200: loss = 2.4188308715820312\n",
      "step = 5707400: loss = 3.374933958053589\n",
      "step = 5707600: loss = 3.651614189147949\n",
      "step = 5707800: loss = 3.969327688217163\n",
      "step = 5708000: loss = 3.4335217475891113\n",
      "step = 5708200: loss = 3.8205764293670654\n",
      "step = 5708400: loss = 3.392534017562866\n",
      "step = 5708600: loss = 3.7822532653808594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 5708800: loss = 4.946463584899902\n",
      "step = 5709000: loss = 5.025160312652588\n",
      "step = 5709200: loss = 3.275999069213867\n",
      "step = 5709400: loss = 3.80026912689209\n",
      "step = 5709600: loss = 3.8813116550445557\n",
      "step = 5709800: loss = 4.298855304718018\n",
      "step = 5710000: loss = 4.115835666656494\n",
      "step = 5710000: Average Return = 5.199999809265137\n",
      "step = 5710200: loss = 3.837435722351074\n",
      "step = 5710400: loss = 3.3114869594573975\n",
      "step = 5710600: loss = 4.035638809204102\n",
      "step = 5710800: loss = 3.143378257751465\n",
      "step = 5711000: loss = 4.307705402374268\n",
      "step = 5711200: loss = 4.635781288146973\n",
      "step = 5711400: loss = 4.092596530914307\n",
      "step = 5711600: loss = 3.736952066421509\n",
      "step = 5711800: loss = 3.844641923904419\n",
      "step = 5712000: loss = 3.9894018173217773\n",
      "step = 5712200: loss = 4.315438747406006\n",
      "step = 5712400: loss = 3.667684555053711\n",
      "step = 5712600: loss = 3.7317278385162354\n",
      "step = 5712800: loss = 2.1415817737579346\n",
      "step = 5713000: loss = 4.384411334991455\n",
      "step = 5713200: loss = 3.4619412422180176\n",
      "step = 5713400: loss = 4.307148456573486\n",
      "step = 5713600: loss = 4.351674556732178\n",
      "step = 5713800: loss = 4.861359119415283\n",
      "step = 5714000: loss = 3.879903793334961\n",
      "step = 5714200: loss = 3.870124340057373\n",
      "step = 5714400: loss = 3.4587512016296387\n",
      "step = 5714600: loss = 3.1986711025238037\n",
      "step = 5714800: loss = 3.7811927795410156\n",
      "step = 5715000: loss = 4.723718643188477\n",
      "step = 5715000: Average Return = 5.949999809265137\n",
      "step = 5715200: loss = 3.284639835357666\n",
      "step = 5715400: loss = 2.6266560554504395\n",
      "step = 5715600: loss = 3.4955596923828125\n",
      "step = 5715800: loss = 3.3193845748901367\n",
      "step = 5716000: loss = 3.8588383197784424\n",
      "step = 5716200: loss = 3.685023784637451\n",
      "step = 5716400: loss = 3.909116744995117\n",
      "step = 5716600: loss = 3.7946279048919678\n",
      "step = 5716800: loss = 3.039785623550415\n",
      "step = 5717000: loss = 4.037359714508057\n",
      "step = 5717200: loss = 3.4499828815460205\n",
      "step = 5717400: loss = 4.168756484985352\n",
      "step = 5717600: loss = 4.762182235717773\n",
      "step = 5717800: loss = 4.114327430725098\n",
      "step = 5718000: loss = 5.177976608276367\n",
      "step = 5718200: loss = 3.268721580505371\n",
      "step = 5718400: loss = 4.249082565307617\n",
      "step = 5718600: loss = 3.900023937225342\n",
      "step = 5718800: loss = 2.817488670349121\n",
      "step = 5719000: loss = 2.678598642349243\n",
      "step = 5719200: loss = 3.073330879211426\n",
      "step = 5719400: loss = 2.8115193843841553\n",
      "step = 5719600: loss = 4.419801712036133\n",
      "step = 5719800: loss = 3.428981304168701\n",
      "step = 5720000: loss = 3.004409074783325\n",
      "step = 5720000: Average Return = 2.5\n",
      "step = 5720200: loss = 4.173058986663818\n",
      "step = 5720400: loss = 3.254673719406128\n",
      "step = 5720600: loss = 2.869598865509033\n",
      "step = 5720800: loss = 3.2099199295043945\n",
      "step = 5721000: loss = 2.6477394104003906\n",
      "step = 5721200: loss = 4.364376544952393\n",
      "step = 5721400: loss = 4.396550178527832\n",
      "step = 5721600: loss = 2.951503038406372\n",
      "step = 5721800: loss = 2.801295518875122\n",
      "step = 5722000: loss = 3.651362895965576\n",
      "step = 5722200: loss = 5.067394733428955\n",
      "step = 5722400: loss = 3.9069738388061523\n",
      "step = 5722600: loss = 4.164639949798584\n",
      "step = 5722800: loss = 4.348968029022217\n",
      "step = 5723000: loss = 3.810793161392212\n",
      "step = 5723200: loss = 3.8219563961029053\n",
      "step = 5723400: loss = 3.8794572353363037\n",
      "step = 5723600: loss = 4.611936092376709\n",
      "step = 5723800: loss = 2.7242560386657715\n",
      "step = 5724000: loss = 4.912006855010986\n",
      "step = 5724200: loss = 4.351126194000244\n",
      "step = 5724400: loss = 3.4299800395965576\n",
      "step = 5724600: loss = 3.4218432903289795\n",
      "step = 5724800: loss = 2.753680467605591\n",
      "step = 5725000: loss = 4.4921875\n",
      "step = 5725000: Average Return = 4.099999904632568\n",
      "step = 5725200: loss = 4.28665018081665\n",
      "step = 5725400: loss = 3.2077534198760986\n",
      "step = 5725600: loss = 4.754715442657471\n",
      "step = 5725800: loss = 3.0055086612701416\n",
      "step = 5726000: loss = 3.3232481479644775\n",
      "step = 5726200: loss = 3.6426525115966797\n",
      "step = 5726400: loss = 3.4989397525787354\n",
      "step = 5726600: loss = 4.066836833953857\n",
      "step = 5726800: loss = 4.628173351287842\n",
      "step = 5727000: loss = 4.142894744873047\n",
      "step = 5727200: loss = 4.002559661865234\n",
      "step = 5727400: loss = 3.111130952835083\n",
      "step = 5727600: loss = 3.8723275661468506\n",
      "step = 5727800: loss = 3.9610705375671387\n",
      "step = 5728000: loss = 4.65083646774292\n",
      "step = 5728200: loss = 3.851130485534668\n",
      "step = 5728400: loss = 2.952794075012207\n",
      "step = 5728600: loss = 4.898715496063232\n",
      "step = 5728800: loss = 5.122865676879883\n",
      "step = 5729000: loss = 4.465242385864258\n",
      "step = 5729200: loss = 3.900287389755249\n",
      "step = 5729400: loss = 2.297340154647827\n",
      "step = 5729600: loss = 4.3164591789245605\n",
      "step = 5729800: loss = 3.8747377395629883\n",
      "step = 5730000: loss = 5.048323154449463\n",
      "step = 5730000: Average Return = 2.6500000953674316\n",
      "step = 5730200: loss = 4.5056257247924805\n",
      "step = 5730400: loss = 4.426096439361572\n",
      "step = 5730600: loss = 4.24197244644165\n",
      "step = 5730800: loss = 3.2358884811401367\n",
      "step = 5731000: loss = 4.11931848526001\n",
      "step = 5731200: loss = 3.2169604301452637\n",
      "step = 5731400: loss = 4.6533732414245605\n",
      "step = 5731600: loss = 3.3810014724731445\n",
      "step = 5731800: loss = 4.504118919372559\n",
      "step = 5732000: loss = 2.286529302597046\n",
      "step = 5732200: loss = 3.2441182136535645\n",
      "step = 5732400: loss = 3.689148187637329\n",
      "step = 5732600: loss = 3.621026039123535\n",
      "step = 5732800: loss = 4.100452899932861\n",
      "step = 5733000: loss = 2.9820525646209717\n",
      "step = 5733200: loss = 3.924513578414917\n",
      "step = 5733400: loss = 3.5803163051605225\n",
      "step = 5733600: loss = 4.433467864990234\n",
      "step = 5733800: loss = 3.7602453231811523\n",
      "step = 5734000: loss = 3.721442461013794\n",
      "step = 5734200: loss = 4.576354503631592\n",
      "step = 5734400: loss = 4.604397296905518\n",
      "step = 5734600: loss = 3.960038423538208\n",
      "step = 5734800: loss = 3.653107166290283\n",
      "step = 5735000: loss = 4.584223747253418\n",
      "step = 5735000: Average Return = 5.699999809265137\n",
      "step = 5735200: loss = 5.296212196350098\n",
      "step = 5735400: loss = 3.112344980239868\n",
      "step = 5735600: loss = 3.6331100463867188\n",
      "step = 5735800: loss = 4.9322004318237305\n",
      "step = 5736000: loss = 3.69530987739563\n",
      "step = 5736200: loss = 3.495739459991455\n",
      "step = 5736400: loss = 3.342301845550537\n",
      "step = 5736600: loss = 3.2104015350341797\n",
      "step = 5736800: loss = 2.8292229175567627\n",
      "step = 5737000: loss = 3.5340662002563477\n",
      "step = 5737200: loss = 2.916693925857544\n",
      "step = 5737400: loss = 3.771174907684326\n",
      "step = 5737600: loss = 3.6767849922180176\n",
      "step = 5737800: loss = 3.5524072647094727\n",
      "step = 5738000: loss = 2.551246166229248\n",
      "step = 5738200: loss = 4.234283924102783\n",
      "step = 5738400: loss = 3.8786730766296387\n",
      "step = 5738600: loss = 4.265431880950928\n",
      "step = 5738800: loss = 3.907707452774048\n",
      "step = 5739000: loss = 3.703328847885132\n",
      "step = 5739200: loss = 3.8496949672698975\n",
      "step = 5739400: loss = 3.906646966934204\n",
      "step = 5739600: loss = 4.135892868041992\n",
      "step = 5739800: loss = 3.337938070297241\n",
      "step = 5740000: loss = 3.124903440475464\n",
      "step = 5740000: Average Return = 2.799999952316284\n",
      "step = 5740200: loss = 4.892448425292969\n",
      "step = 5740400: loss = 4.73401403427124\n",
      "step = 5740600: loss = 3.49599552154541\n",
      "step = 5740800: loss = 4.558339595794678\n",
      "step = 5741000: loss = 3.540480375289917\n",
      "step = 5741200: loss = 3.1880557537078857\n",
      "step = 5741400: loss = 3.5256829261779785\n",
      "step = 5741600: loss = 3.6010351181030273\n",
      "step = 5741800: loss = 3.758525848388672\n",
      "step = 5742000: loss = 4.552943706512451\n",
      "step = 5742200: loss = 4.392158508300781\n",
      "step = 5742400: loss = 4.844247341156006\n",
      "step = 5742600: loss = 3.8376283645629883\n",
      "step = 5742800: loss = 3.8084557056427\n",
      "step = 5743000: loss = 4.5746002197265625\n",
      "step = 5743200: loss = 4.074223041534424\n",
      "step = 5743400: loss = 5.252280235290527\n",
      "step = 5743600: loss = 3.9873692989349365\n",
      "step = 5743800: loss = 2.9127628803253174\n",
      "step = 5744000: loss = 3.794635772705078\n",
      "step = 5744200: loss = 3.183121919631958\n",
      "step = 5744400: loss = 3.048387289047241\n",
      "step = 5744600: loss = 4.15860652923584\n",
      "step = 5744800: loss = 3.030266761779785\n",
      "step = 5745000: loss = 3.8200340270996094\n",
      "step = 5745000: Average Return = 3.799999952316284\n",
      "step = 5745200: loss = 3.686924457550049\n",
      "step = 5745400: loss = 3.951572895050049\n",
      "step = 5745600: loss = 4.428155899047852\n",
      "step = 5745800: loss = 4.743934154510498\n",
      "step = 5746000: loss = 3.2217772006988525\n",
      "step = 5746200: loss = 5.048064231872559\n",
      "step = 5746400: loss = 4.911350727081299\n",
      "step = 5746600: loss = 3.6180968284606934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 5746800: loss = 3.327305316925049\n",
      "step = 5747000: loss = 4.560074806213379\n",
      "step = 5747200: loss = 4.83725643157959\n",
      "step = 5747400: loss = 5.088313579559326\n",
      "step = 5747600: loss = 3.5518078804016113\n",
      "step = 5747800: loss = 4.093875408172607\n",
      "step = 5748000: loss = 3.9052441120147705\n",
      "step = 5748200: loss = 4.616621971130371\n",
      "step = 5748400: loss = 4.160691261291504\n",
      "step = 5748600: loss = 3.8564600944519043\n",
      "step = 5748800: loss = 3.9738035202026367\n",
      "step = 5749000: loss = 3.0366029739379883\n",
      "step = 5749200: loss = 2.878627300262451\n",
      "step = 5749400: loss = 3.435235023498535\n",
      "step = 5749600: loss = 4.047943115234375\n",
      "step = 5749800: loss = 3.9401888847351074\n",
      "step = 5750000: loss = 4.545394420623779\n",
      "step = 5750000: Average Return = 2.25\n",
      "step = 5750200: loss = 3.5141894817352295\n",
      "step = 5750400: loss = 4.509253025054932\n",
      "step = 5750600: loss = 4.618579387664795\n",
      "step = 5750800: loss = 2.740715503692627\n",
      "step = 5751000: loss = 3.085798978805542\n",
      "step = 5751200: loss = 4.037153720855713\n",
      "step = 5751400: loss = 3.8627917766571045\n",
      "step = 5751600: loss = 3.14794921875\n",
      "step = 5751800: loss = 3.7436938285827637\n",
      "step = 5752000: loss = 4.19478178024292\n",
      "step = 5752200: loss = 4.402320861816406\n",
      "step = 5752400: loss = 4.074509143829346\n",
      "step = 5752600: loss = 4.52786111831665\n",
      "step = 5752800: loss = 3.686447858810425\n",
      "step = 5753000: loss = 2.7011027336120605\n",
      "step = 5753200: loss = 3.9184324741363525\n",
      "step = 5753400: loss = 3.3118157386779785\n",
      "step = 5753600: loss = 3.834463119506836\n",
      "step = 5753800: loss = 3.2954559326171875\n",
      "step = 5754000: loss = 3.84266996383667\n",
      "step = 5754200: loss = 4.05996561050415\n",
      "step = 5754400: loss = 4.1279215812683105\n",
      "step = 5754600: loss = 3.5302789211273193\n",
      "step = 5754800: loss = 4.413971900939941\n",
      "step = 5755000: loss = 4.275958061218262\n",
      "step = 5755000: Average Return = 6.0\n",
      "step = 5755200: loss = 3.820997953414917\n",
      "step = 5755400: loss = 3.494354724884033\n",
      "step = 5755600: loss = 4.271575450897217\n",
      "step = 5755800: loss = 3.2771878242492676\n",
      "step = 5756000: loss = 2.6376795768737793\n",
      "step = 5756200: loss = 4.493659973144531\n",
      "step = 5756400: loss = 3.940284252166748\n",
      "step = 5756600: loss = 3.9327080249786377\n",
      "step = 5756800: loss = 3.032524585723877\n",
      "step = 5757000: loss = 3.7188262939453125\n",
      "step = 5757200: loss = 3.3263397216796875\n",
      "step = 5757400: loss = 4.269486427307129\n",
      "step = 5757600: loss = 3.105318784713745\n",
      "step = 5757800: loss = 5.175242900848389\n",
      "step = 5758000: loss = 3.529797315597534\n",
      "step = 5758200: loss = 4.0984601974487305\n",
      "step = 5758400: loss = 2.8837642669677734\n",
      "step = 5758600: loss = 3.4448165893554688\n",
      "step = 5758800: loss = 3.9722325801849365\n",
      "step = 5759000: loss = 4.740229606628418\n",
      "step = 5759200: loss = 3.681495189666748\n",
      "step = 5759400: loss = 2.990421772003174\n",
      "step = 5759600: loss = 4.52689790725708\n",
      "step = 5759800: loss = 3.998572587966919\n",
      "step = 5760000: loss = 3.27690052986145\n",
      "step = 5760000: Average Return = 3.25\n",
      "step = 5760200: loss = 3.921572208404541\n",
      "step = 5760400: loss = 4.420794486999512\n",
      "step = 5760600: loss = 3.5608043670654297\n",
      "step = 5760800: loss = 4.850732803344727\n",
      "step = 5761000: loss = 5.445626258850098\n",
      "step = 5761200: loss = 4.487272262573242\n",
      "step = 5761400: loss = 4.614933013916016\n",
      "step = 5761600: loss = 2.2896482944488525\n",
      "step = 5761800: loss = 4.8193206787109375\n",
      "step = 5762000: loss = 3.4978585243225098\n",
      "step = 5762200: loss = 3.653290033340454\n",
      "step = 5762400: loss = 3.6017913818359375\n",
      "step = 5762600: loss = 3.0636656284332275\n",
      "step = 5762800: loss = 4.145100116729736\n",
      "step = 5763000: loss = 3.02437162399292\n",
      "step = 5763200: loss = 3.3328661918640137\n",
      "step = 5763400: loss = 3.094390869140625\n",
      "step = 5763600: loss = 2.6370887756347656\n",
      "step = 5763800: loss = 4.516078472137451\n",
      "step = 5764000: loss = 3.062288999557495\n",
      "step = 5764200: loss = 4.735555171966553\n",
      "step = 5764400: loss = 3.1021928787231445\n",
      "step = 5764600: loss = 4.597029685974121\n",
      "step = 5764800: loss = 4.932521820068359\n",
      "step = 5765000: loss = 3.707259178161621\n",
      "step = 5765000: Average Return = 4.150000095367432\n",
      "step = 5765200: loss = 4.5766801834106445\n",
      "step = 5765400: loss = 3.225539207458496\n",
      "step = 5765600: loss = 4.21298360824585\n",
      "step = 5765800: loss = 4.3459320068359375\n",
      "step = 5766000: loss = 2.6149826049804688\n",
      "step = 5766200: loss = 3.564852237701416\n",
      "step = 5766400: loss = 5.7318115234375\n",
      "step = 5766600: loss = 4.848602294921875\n",
      "step = 5766800: loss = 4.0980329513549805\n",
      "step = 5767000: loss = 3.319274425506592\n",
      "step = 5767200: loss = 5.070444107055664\n",
      "step = 5767400: loss = 3.791973114013672\n",
      "step = 5767600: loss = 4.702948570251465\n",
      "step = 5767800: loss = 2.253854751586914\n",
      "step = 5768000: loss = 5.871859073638916\n",
      "step = 5768200: loss = 3.8602261543273926\n",
      "step = 5768400: loss = 3.3935437202453613\n",
      "step = 5768600: loss = 3.8003344535827637\n",
      "step = 5768800: loss = 4.334197521209717\n",
      "step = 5769000: loss = 3.6004257202148438\n",
      "step = 5769200: loss = 3.9129390716552734\n",
      "step = 5769400: loss = 3.8531172275543213\n",
      "step = 5769600: loss = 3.464451789855957\n",
      "step = 5769800: loss = 3.337137460708618\n",
      "step = 5770000: loss = 3.5277066230773926\n",
      "step = 5770000: Average Return = 6.449999809265137\n",
      "step = 5770200: loss = 3.235100269317627\n",
      "step = 5770400: loss = 4.3483405113220215\n",
      "step = 5770600: loss = 3.1944963932037354\n",
      "step = 5770800: loss = 3.347412347793579\n",
      "step = 5771000: loss = 4.437142372131348\n",
      "step = 5771200: loss = 3.4429826736450195\n",
      "step = 5771400: loss = 5.368519306182861\n",
      "step = 5771600: loss = 4.1136274337768555\n",
      "step = 5771800: loss = 1.9580141305923462\n",
      "step = 5772000: loss = 4.013699531555176\n",
      "step = 5772200: loss = 5.178083419799805\n",
      "step = 5772400: loss = 4.335140705108643\n",
      "step = 5772600: loss = 3.854874849319458\n",
      "step = 5772800: loss = 3.8038270473480225\n",
      "step = 5773000: loss = 3.509521722793579\n",
      "step = 5773200: loss = 5.594644546508789\n",
      "step = 5773400: loss = 3.78409481048584\n",
      "step = 5773600: loss = 4.084771633148193\n",
      "step = 5773800: loss = 4.7579874992370605\n",
      "step = 5774000: loss = 4.648901462554932\n",
      "step = 5774200: loss = 4.184760570526123\n",
      "step = 5774400: loss = 3.17631459236145\n",
      "step = 5774600: loss = 4.4156107902526855\n",
      "step = 5774800: loss = 3.763904094696045\n",
      "step = 5775000: loss = 3.5542314052581787\n",
      "step = 5775000: Average Return = 4.099999904632568\n",
      "step = 5775200: loss = 3.1915409564971924\n",
      "step = 5775400: loss = 4.5365495681762695\n",
      "step = 5775600: loss = 3.7868587970733643\n",
      "step = 5775800: loss = 3.699329137802124\n",
      "step = 5776000: loss = 3.8981871604919434\n",
      "step = 5776200: loss = 3.114779233932495\n",
      "step = 5776400: loss = 4.535816669464111\n",
      "step = 5776600: loss = 3.7716526985168457\n",
      "step = 5776800: loss = 2.9311091899871826\n",
      "step = 5777000: loss = 3.1866984367370605\n",
      "step = 5777200: loss = 4.882274150848389\n",
      "step = 5777400: loss = 3.2411632537841797\n",
      "step = 5777600: loss = 3.607060432434082\n",
      "step = 5777800: loss = 3.2586216926574707\n",
      "step = 5778000: loss = 3.201662302017212\n",
      "step = 5778200: loss = 3.690335512161255\n",
      "step = 5778400: loss = 4.10443639755249\n",
      "step = 5778600: loss = 2.7031092643737793\n",
      "step = 5778800: loss = 4.365172863006592\n",
      "step = 5779000: loss = 2.6958415508270264\n",
      "step = 5779200: loss = 4.425553798675537\n",
      "step = 5779400: loss = 4.496570110321045\n",
      "step = 5779600: loss = 4.284396648406982\n",
      "step = 5779800: loss = 3.588580846786499\n",
      "step = 5780000: loss = 4.286092281341553\n",
      "step = 5780000: Average Return = 3.450000047683716\n",
      "step = 5780200: loss = 5.315489292144775\n",
      "step = 5780400: loss = 3.2000913619995117\n",
      "step = 5780600: loss = 4.612063407897949\n",
      "step = 5780800: loss = 3.9278793334960938\n",
      "step = 5781000: loss = 3.6284284591674805\n",
      "step = 5781200: loss = 4.474246978759766\n",
      "step = 5781400: loss = 4.287102699279785\n",
      "step = 5781600: loss = 3.9579975605010986\n",
      "step = 5781800: loss = 3.908172845840454\n",
      "step = 5782000: loss = 3.8117852210998535\n",
      "step = 5782200: loss = 3.408215284347534\n",
      "step = 5782400: loss = 2.7020318508148193\n",
      "step = 5782600: loss = 4.231107711791992\n",
      "step = 5782800: loss = 4.984234809875488\n",
      "step = 5783000: loss = 3.234321117401123\n",
      "step = 5783200: loss = 3.2385027408599854\n",
      "step = 5783400: loss = 4.172784805297852\n",
      "step = 5783600: loss = 4.032146453857422\n",
      "step = 5783800: loss = 2.9765560626983643\n",
      "step = 5784000: loss = 3.7003700733184814\n",
      "step = 5784200: loss = 4.414549350738525\n",
      "step = 5784400: loss = 4.040215969085693\n",
      "step = 5784600: loss = 4.495087146759033\n",
      "step = 5784800: loss = 3.611917018890381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 5785000: loss = 3.352288246154785\n",
      "step = 5785000: Average Return = 1.25\n",
      "step = 5785200: loss = 3.639214277267456\n",
      "step = 5785400: loss = 3.489718198776245\n",
      "step = 5785600: loss = 3.8622212409973145\n",
      "step = 5785800: loss = 4.048272609710693\n",
      "step = 5786000: loss = 4.48587703704834\n",
      "step = 5786200: loss = 3.2675485610961914\n",
      "step = 5786400: loss = 3.6965339183807373\n",
      "step = 5786600: loss = 4.4484992027282715\n",
      "step = 5786800: loss = 3.7235636711120605\n",
      "step = 5787000: loss = 2.746854543685913\n",
      "step = 5787200: loss = 3.634321928024292\n",
      "step = 5787400: loss = 1.738061785697937\n",
      "step = 5787600: loss = 4.0896501541137695\n",
      "step = 5787800: loss = 4.68234920501709\n",
      "step = 5788000: loss = 3.9516406059265137\n",
      "step = 5788200: loss = 3.295618772506714\n",
      "step = 5788400: loss = 3.712158441543579\n",
      "step = 5788600: loss = 3.36344051361084\n",
      "step = 5788800: loss = 4.504976272583008\n",
      "step = 5789000: loss = 3.466320037841797\n",
      "step = 5789200: loss = 2.8246960639953613\n",
      "step = 5789400: loss = 4.240894794464111\n",
      "step = 5789600: loss = 3.5583982467651367\n",
      "step = 5789800: loss = 3.4243297576904297\n",
      "step = 5790000: loss = 3.3994719982147217\n",
      "step = 5790000: Average Return = 2.049999952316284\n",
      "step = 5790200: loss = 6.818985462188721\n",
      "step = 5790400: loss = 5.236037254333496\n",
      "step = 5790600: loss = 4.019247531890869\n",
      "step = 5790800: loss = 5.059010982513428\n",
      "step = 5791000: loss = 3.273513078689575\n",
      "step = 5791200: loss = 4.033642292022705\n",
      "step = 5791400: loss = 3.7161471843719482\n",
      "step = 5791600: loss = 4.808722496032715\n",
      "step = 5791800: loss = 3.794739246368408\n",
      "step = 5792000: loss = 3.321047306060791\n",
      "step = 5792200: loss = 3.228933572769165\n",
      "step = 5792400: loss = 4.298288345336914\n",
      "step = 5792600: loss = 3.574150562286377\n",
      "step = 5792800: loss = 4.644093036651611\n",
      "step = 5793000: loss = 4.179498195648193\n",
      "step = 5793200: loss = 3.586862087249756\n",
      "step = 5793400: loss = 5.564186096191406\n",
      "step = 5793600: loss = 4.1087541580200195\n",
      "step = 5793800: loss = 4.492959022521973\n",
      "step = 5794000: loss = 3.3777453899383545\n",
      "step = 5794200: loss = 4.641368865966797\n",
      "step = 5794400: loss = 3.8235106468200684\n",
      "step = 5794600: loss = 3.555715322494507\n",
      "step = 5794800: loss = 6.053414344787598\n",
      "step = 5795000: loss = 4.508381366729736\n",
      "step = 5795000: Average Return = 5.25\n",
      "step = 5795200: loss = 4.637836933135986\n",
      "step = 5795400: loss = 4.1081037521362305\n",
      "step = 5795600: loss = 4.490190505981445\n",
      "step = 5795800: loss = 4.019587516784668\n",
      "step = 5796000: loss = 4.093232154846191\n",
      "step = 5796200: loss = 4.841557025909424\n",
      "step = 5796400: loss = 2.9927830696105957\n",
      "step = 5796600: loss = 3.4184083938598633\n",
      "step = 5796800: loss = 3.4577646255493164\n",
      "step = 5797000: loss = 4.308495044708252\n",
      "step = 5797200: loss = 3.998976945877075\n",
      "step = 5797400: loss = 4.731417179107666\n",
      "step = 5797600: loss = 3.388474702835083\n",
      "step = 5797800: loss = 4.780173301696777\n",
      "step = 5798000: loss = 2.963689088821411\n",
      "step = 5798200: loss = 3.6958372592926025\n",
      "step = 5798400: loss = 3.6131155490875244\n",
      "step = 5798600: loss = 3.9128172397613525\n",
      "step = 5798800: loss = 4.4730143547058105\n",
      "step = 5799000: loss = 3.520475149154663\n",
      "step = 5799200: loss = 3.788547992706299\n",
      "step = 5799400: loss = 3.7827322483062744\n",
      "step = 5799600: loss = 3.50659441947937\n",
      "step = 5799800: loss = 3.704516887664795\n",
      "step = 5800000: loss = 3.7091224193573\n",
      "step = 5800000: Average Return = 3.200000047683716\n",
      "step = 5800200: loss = 3.3307223320007324\n",
      "step = 5800400: loss = 3.376141309738159\n",
      "step = 5800600: loss = 2.912043809890747\n",
      "step = 5800800: loss = 3.7269716262817383\n",
      "step = 5801000: loss = 4.443411827087402\n",
      "step = 5801200: loss = 4.803588390350342\n",
      "step = 5801400: loss = 3.870985746383667\n",
      "step = 5801600: loss = 3.2748043537139893\n",
      "step = 5801800: loss = 2.8704912662506104\n",
      "step = 5802000: loss = 3.211240768432617\n",
      "step = 5802200: loss = 3.3478591442108154\n",
      "step = 5802400: loss = 3.4423303604125977\n",
      "step = 5802600: loss = 4.211055755615234\n",
      "step = 5802800: loss = 4.246390342712402\n",
      "step = 5803000: loss = 3.99757981300354\n",
      "step = 5803200: loss = 3.5446324348449707\n",
      "step = 5803400: loss = 3.0239627361297607\n",
      "step = 5803600: loss = 4.102251052856445\n",
      "step = 5803800: loss = 3.8024187088012695\n",
      "step = 5804000: loss = 3.695768356323242\n",
      "step = 5804200: loss = 3.2283010482788086\n",
      "step = 5804400: loss = 2.2500531673431396\n",
      "step = 5804600: loss = 4.88633918762207\n",
      "step = 5804800: loss = 3.61190128326416\n",
      "step = 5805000: loss = 4.572258472442627\n",
      "step = 5805000: Average Return = 2.700000047683716\n",
      "step = 5805200: loss = 4.503117084503174\n",
      "step = 5805400: loss = 3.7739500999450684\n",
      "step = 5805600: loss = 3.5268707275390625\n",
      "step = 5805800: loss = 4.22016716003418\n",
      "step = 5806000: loss = 3.1187798976898193\n",
      "step = 5806200: loss = 3.871246337890625\n",
      "step = 5806400: loss = 4.658369541168213\n",
      "step = 5806600: loss = 5.3136725425720215\n",
      "step = 5806800: loss = 3.2614781856536865\n",
      "step = 5807000: loss = 3.9866180419921875\n",
      "step = 5807200: loss = 4.743887901306152\n",
      "step = 5807400: loss = 2.69922137260437\n",
      "step = 5807600: loss = 3.6944706439971924\n",
      "step = 5807800: loss = 3.190129518508911\n",
      "step = 5808000: loss = 3.598634958267212\n",
      "step = 5808200: loss = 2.9669909477233887\n",
      "step = 5808400: loss = 4.163620471954346\n",
      "step = 5808600: loss = 4.232065677642822\n",
      "step = 5808800: loss = 3.7706146240234375\n",
      "step = 5809000: loss = 4.158326148986816\n",
      "step = 5809200: loss = 2.856282949447632\n",
      "step = 5809400: loss = 2.9345195293426514\n",
      "step = 5809600: loss = 3.802349805831909\n",
      "step = 5809800: loss = 4.254139423370361\n",
      "step = 5810000: loss = 4.76065731048584\n",
      "step = 5810000: Average Return = 3.25\n",
      "step = 5810200: loss = 3.7798454761505127\n",
      "step = 5810400: loss = 2.9355533123016357\n",
      "step = 5810600: loss = 4.023576736450195\n",
      "step = 5810800: loss = 3.4737820625305176\n",
      "step = 5811000: loss = 4.819967746734619\n",
      "step = 5811200: loss = 4.353512763977051\n",
      "step = 5811400: loss = 5.708607196807861\n",
      "step = 5811600: loss = 3.6747307777404785\n",
      "step = 5811800: loss = 4.637308120727539\n",
      "step = 5812000: loss = 2.8820908069610596\n",
      "step = 5812200: loss = 3.107125759124756\n",
      "step = 5812400: loss = 3.403186321258545\n",
      "step = 5812600: loss = 3.4175236225128174\n",
      "step = 5812800: loss = 3.9862565994262695\n",
      "step = 5813000: loss = 4.430339336395264\n",
      "step = 5813200: loss = 4.698502063751221\n",
      "step = 5813400: loss = 3.469061851501465\n",
      "step = 5813600: loss = 3.6954381465911865\n",
      "step = 5813800: loss = 3.717200517654419\n",
      "step = 5814000: loss = 4.5840983390808105\n",
      "step = 5814200: loss = 4.301413059234619\n",
      "step = 5814400: loss = 3.763935089111328\n",
      "step = 5814600: loss = 3.596571683883667\n",
      "step = 5814800: loss = 3.536142110824585\n",
      "step = 5815000: loss = 3.8653390407562256\n",
      "step = 5815000: Average Return = 3.5\n",
      "step = 5815200: loss = 3.8834831714630127\n",
      "step = 5815400: loss = 2.9647655487060547\n",
      "step = 5815600: loss = 4.358088970184326\n",
      "step = 5815800: loss = 3.2224154472351074\n",
      "step = 5816000: loss = 4.361999034881592\n",
      "step = 5816200: loss = 3.700507164001465\n",
      "step = 5816400: loss = 3.316847562789917\n",
      "step = 5816600: loss = 3.7282958030700684\n",
      "step = 5816800: loss = 4.487124443054199\n",
      "step = 5817000: loss = 3.8963232040405273\n",
      "step = 5817200: loss = 3.8046531677246094\n",
      "step = 5817400: loss = 4.697573661804199\n",
      "step = 5817600: loss = 4.607685565948486\n",
      "step = 5817800: loss = 3.6439919471740723\n",
      "step = 5818000: loss = 2.7737224102020264\n",
      "step = 5818200: loss = 3.8653957843780518\n",
      "step = 5818400: loss = 4.418097019195557\n",
      "step = 5818600: loss = 2.332303047180176\n",
      "step = 5818800: loss = 3.8173351287841797\n",
      "step = 5819000: loss = 3.3781025409698486\n",
      "step = 5819200: loss = 4.6421966552734375\n",
      "step = 5819400: loss = 3.970496416091919\n",
      "step = 5819600: loss = 5.238950252532959\n",
      "step = 5819800: loss = 3.9179234504699707\n",
      "step = 5820000: loss = 4.855384826660156\n",
      "step = 5820000: Average Return = 3.6500000953674316\n",
      "step = 5820200: loss = 3.443150520324707\n",
      "step = 5820400: loss = 5.287955284118652\n",
      "step = 5820600: loss = 3.11407470703125\n",
      "step = 5820800: loss = 4.131673336029053\n",
      "step = 5821000: loss = 5.028281211853027\n",
      "step = 5821200: loss = 5.251504898071289\n",
      "step = 5821400: loss = 5.179849624633789\n",
      "step = 5821600: loss = 3.1265087127685547\n",
      "step = 5821800: loss = 4.619625568389893\n",
      "step = 5822000: loss = 3.569161891937256\n",
      "step = 5822200: loss = 4.625256061553955\n",
      "step = 5822400: loss = 4.15180778503418\n",
      "step = 5822600: loss = 4.16883659362793\n",
      "step = 5822800: loss = 3.761918783187866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 5823000: loss = 5.135826110839844\n",
      "step = 5823200: loss = 3.670297861099243\n",
      "step = 5823400: loss = 3.4714291095733643\n",
      "step = 5823600: loss = 3.922626495361328\n",
      "step = 5823800: loss = 4.56736421585083\n",
      "step = 5824000: loss = 3.2673180103302\n",
      "step = 5824200: loss = 3.5676698684692383\n",
      "step = 5824400: loss = 3.684152126312256\n",
      "step = 5824600: loss = 3.081987142562866\n",
      "step = 5824800: loss = 3.691106081008911\n",
      "step = 5825000: loss = 4.542796611785889\n",
      "step = 5825000: Average Return = 4.349999904632568\n",
      "step = 5825200: loss = 4.715836524963379\n",
      "step = 5825400: loss = 2.9960951805114746\n",
      "step = 5825600: loss = 3.098189115524292\n",
      "step = 5825800: loss = 4.252899169921875\n",
      "step = 5826000: loss = 4.50484561920166\n",
      "step = 5826200: loss = 3.1625893115997314\n",
      "step = 5826400: loss = 2.837305784225464\n",
      "step = 5826600: loss = 4.514016628265381\n",
      "step = 5826800: loss = 4.338817119598389\n",
      "step = 5827000: loss = 4.250669002532959\n",
      "step = 5827200: loss = 3.1708767414093018\n",
      "step = 5827400: loss = 3.417017698287964\n",
      "step = 5827600: loss = 3.940826892852783\n",
      "step = 5827800: loss = 3.4477555751800537\n",
      "step = 5828000: loss = 3.309001922607422\n",
      "step = 5828200: loss = 3.922166585922241\n",
      "step = 5828400: loss = 4.788036346435547\n",
      "step = 5828600: loss = 4.551321506500244\n",
      "step = 5828800: loss = 4.37077522277832\n",
      "step = 5829000: loss = 4.782162666320801\n",
      "step = 5829200: loss = 4.4674906730651855\n",
      "step = 5829400: loss = 4.197865962982178\n",
      "step = 5829600: loss = 4.886684894561768\n",
      "step = 5829800: loss = 4.1791534423828125\n",
      "step = 5830000: loss = 4.101760387420654\n",
      "step = 5830000: Average Return = 4.150000095367432\n",
      "step = 5830200: loss = 4.566414833068848\n",
      "step = 5830400: loss = 3.2104711532592773\n",
      "step = 5830600: loss = 4.899138450622559\n",
      "step = 5830800: loss = 3.4941256046295166\n",
      "step = 5831000: loss = 3.677615165710449\n",
      "step = 5831200: loss = 3.9615871906280518\n",
      "step = 5831400: loss = 3.8443870544433594\n",
      "step = 5831600: loss = 4.454787731170654\n",
      "step = 5831800: loss = 3.805936098098755\n",
      "step = 5832000: loss = 4.825075626373291\n",
      "step = 5832200: loss = 4.479187488555908\n",
      "step = 5832400: loss = 4.197452068328857\n",
      "step = 5832600: loss = 3.335238218307495\n",
      "step = 5832800: loss = 3.538663148880005\n",
      "step = 5833000: loss = 4.692773342132568\n",
      "step = 5833200: loss = 3.8334767818450928\n",
      "step = 5833400: loss = 3.5988094806671143\n",
      "step = 5833600: loss = 4.3927435874938965\n",
      "step = 5833800: loss = 4.262910842895508\n",
      "step = 5834000: loss = 4.841963768005371\n",
      "step = 5834200: loss = 3.735161066055298\n",
      "step = 5834400: loss = 4.616652965545654\n",
      "step = 5834600: loss = 4.437150955200195\n",
      "step = 5834800: loss = 4.634524345397949\n",
      "step = 5835000: loss = 3.9999167919158936\n",
      "step = 5835000: Average Return = 3.8499999046325684\n",
      "step = 5835200: loss = 2.7803902626037598\n",
      "step = 5835400: loss = 3.4766361713409424\n",
      "step = 5835600: loss = 4.833173751831055\n",
      "step = 5835800: loss = 3.538996458053589\n",
      "step = 5836000: loss = 5.281193733215332\n",
      "step = 5836200: loss = 3.4772136211395264\n",
      "step = 5836400: loss = 3.9177606105804443\n",
      "step = 5836600: loss = 3.0954232215881348\n",
      "step = 5836800: loss = 3.7676689624786377\n",
      "step = 5837000: loss = 4.239846229553223\n",
      "step = 5837200: loss = 4.138130187988281\n",
      "step = 5837400: loss = 4.374329566955566\n",
      "step = 5837600: loss = 3.4524896144866943\n",
      "step = 5837800: loss = 2.4062583446502686\n",
      "step = 5838000: loss = 4.360511302947998\n",
      "step = 5838200: loss = 4.173731803894043\n",
      "step = 5838400: loss = 3.9887378215789795\n",
      "step = 5838600: loss = 4.163180828094482\n",
      "step = 5838800: loss = 5.320243835449219\n",
      "step = 5839000: loss = 3.782944917678833\n",
      "step = 5839200: loss = 3.5605928897857666\n",
      "step = 5839400: loss = 3.8735721111297607\n",
      "step = 5839600: loss = 4.208024024963379\n",
      "step = 5839800: loss = 3.934957504272461\n",
      "step = 5840000: loss = 4.0839362144470215\n",
      "step = 5840000: Average Return = 2.450000047683716\n",
      "step = 5840200: loss = 3.132500648498535\n",
      "step = 5840400: loss = 3.953342914581299\n",
      "step = 5840600: loss = 2.7609245777130127\n",
      "step = 5840800: loss = 3.5660948753356934\n",
      "step = 5841000: loss = 4.079060077667236\n",
      "step = 5841200: loss = 3.139913320541382\n",
      "step = 5841400: loss = 4.034051418304443\n",
      "step = 5841600: loss = 4.149309158325195\n",
      "step = 5841800: loss = 5.043031692504883\n",
      "step = 5842000: loss = 3.9884254932403564\n",
      "step = 5842200: loss = 5.151921272277832\n",
      "step = 5842400: loss = 4.322789669036865\n",
      "step = 5842600: loss = 4.389947891235352\n",
      "step = 5842800: loss = 3.456456184387207\n",
      "step = 5843000: loss = 3.7472612857818604\n",
      "step = 5843200: loss = 4.827934741973877\n",
      "step = 5843400: loss = 5.29072904586792\n",
      "step = 5843600: loss = 3.508265256881714\n",
      "step = 5843800: loss = 3.7160305976867676\n",
      "step = 5844000: loss = 4.187906265258789\n",
      "step = 5844200: loss = 5.035498142242432\n",
      "step = 5844400: loss = 2.677987813949585\n",
      "step = 5844600: loss = 4.014457702636719\n",
      "step = 5844800: loss = 3.637927770614624\n",
      "step = 5845000: loss = 3.5676684379577637\n",
      "step = 5845000: Average Return = 4.599999904632568\n",
      "step = 5845200: loss = 3.7718162536621094\n",
      "step = 5845400: loss = 4.058473587036133\n",
      "step = 5845600: loss = 2.748891592025757\n",
      "step = 5845800: loss = 4.025981903076172\n",
      "step = 5846000: loss = 3.414356231689453\n",
      "step = 5846200: loss = 4.701631546020508\n",
      "step = 5846400: loss = 4.68535041809082\n",
      "step = 5846600: loss = 3.512700080871582\n",
      "step = 5846800: loss = 3.669936180114746\n",
      "step = 5847000: loss = 4.337465763092041\n",
      "step = 5847200: loss = 3.6372172832489014\n",
      "step = 5847400: loss = 3.263367176055908\n",
      "step = 5847600: loss = 2.9199512004852295\n",
      "step = 5847800: loss = 4.22199821472168\n",
      "step = 5848000: loss = 4.685640811920166\n",
      "step = 5848200: loss = 3.268204927444458\n",
      "step = 5848400: loss = 2.3656134605407715\n",
      "step = 5848600: loss = 4.164390563964844\n",
      "step = 5848800: loss = 2.856379747390747\n",
      "step = 5849000: loss = 3.841000556945801\n",
      "step = 5849200: loss = 4.515867710113525\n",
      "step = 5849400: loss = 3.6700620651245117\n",
      "step = 5849600: loss = 2.7010607719421387\n",
      "step = 5849800: loss = 3.9862782955169678\n",
      "step = 5850000: loss = 3.3809731006622314\n",
      "step = 5850000: Average Return = 5.449999809265137\n",
      "step = 5850200: loss = 3.8714911937713623\n",
      "step = 5850400: loss = 3.4854323863983154\n",
      "step = 5850600: loss = 4.4578046798706055\n",
      "step = 5850800: loss = 3.84586238861084\n",
      "step = 5851000: loss = 3.923269033432007\n",
      "step = 5851200: loss = 3.519334316253662\n",
      "step = 5851400: loss = 3.9130055904388428\n",
      "step = 5851600: loss = 4.056510925292969\n",
      "step = 5851800: loss = 2.571706771850586\n",
      "step = 5852000: loss = 3.622767210006714\n",
      "step = 5852200: loss = 3.6958346366882324\n",
      "step = 5852400: loss = 3.6829161643981934\n",
      "step = 5852600: loss = 4.3500871658325195\n",
      "step = 5852800: loss = 4.38812255859375\n",
      "step = 5853000: loss = 4.0750017166137695\n",
      "step = 5853200: loss = 4.616771221160889\n",
      "step = 5853400: loss = 4.282967567443848\n",
      "step = 5853600: loss = 4.937658786773682\n",
      "step = 5853800: loss = 3.1724789142608643\n",
      "step = 5854000: loss = 3.688852548599243\n",
      "step = 5854200: loss = 4.570960521697998\n",
      "step = 5854400: loss = 3.3166441917419434\n",
      "step = 5854600: loss = 4.63563871383667\n",
      "step = 5854800: loss = 4.222692012786865\n",
      "step = 5855000: loss = 4.893281936645508\n",
      "step = 5855000: Average Return = 2.799999952316284\n",
      "step = 5855200: loss = 3.7368810176849365\n",
      "step = 5855400: loss = 3.669711112976074\n",
      "step = 5855600: loss = 4.116735935211182\n",
      "step = 5855800: loss = 4.338622093200684\n",
      "step = 5856000: loss = 4.8675856590271\n",
      "step = 5856200: loss = 4.321500301361084\n",
      "step = 5856400: loss = 3.5815858840942383\n",
      "step = 5856600: loss = 3.0109245777130127\n",
      "step = 5856800: loss = 4.607388019561768\n",
      "step = 5857000: loss = 3.0691728591918945\n",
      "step = 5857200: loss = 3.683411121368408\n",
      "step = 5857400: loss = 3.4509682655334473\n",
      "step = 5857600: loss = 3.336045503616333\n",
      "step = 5857800: loss = 4.195146560668945\n",
      "step = 5858000: loss = 3.83811092376709\n",
      "step = 5858200: loss = 3.949697494506836\n",
      "step = 5858400: loss = 4.226842403411865\n",
      "step = 5858600: loss = 3.0837113857269287\n",
      "step = 5858800: loss = 2.4657704830169678\n",
      "step = 5859000: loss = 3.1744039058685303\n",
      "step = 5859200: loss = 4.188066482543945\n",
      "step = 5859400: loss = 3.7105696201324463\n",
      "step = 5859600: loss = 4.169892311096191\n",
      "step = 5859800: loss = 4.792938232421875\n",
      "step = 5860000: loss = 3.963021755218506\n",
      "step = 5860000: Average Return = 3.049999952316284\n",
      "step = 5860200: loss = 3.125788927078247\n",
      "step = 5860400: loss = 3.6753780841827393\n",
      "step = 5860600: loss = 5.10781717300415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 5860800: loss = 4.3877410888671875\n",
      "step = 5861000: loss = 2.83622670173645\n",
      "step = 5861200: loss = 4.331722736358643\n",
      "step = 5861400: loss = 4.117626190185547\n",
      "step = 5861600: loss = 5.135347843170166\n",
      "step = 5861800: loss = 4.872943878173828\n",
      "step = 5862000: loss = 4.0148749351501465\n",
      "step = 5862200: loss = 5.103529453277588\n",
      "step = 5862400: loss = 4.464245319366455\n",
      "step = 5862600: loss = 3.0807859897613525\n",
      "step = 5862800: loss = 4.913724422454834\n",
      "step = 5863000: loss = 3.099670886993408\n",
      "step = 5863200: loss = 3.6289095878601074\n",
      "step = 5863400: loss = 3.5165891647338867\n",
      "step = 5863600: loss = 4.844245433807373\n",
      "step = 5863800: loss = 4.018368721008301\n",
      "step = 5864000: loss = 3.0784642696380615\n",
      "step = 5864200: loss = 3.788891553878784\n",
      "step = 5864400: loss = 4.861663341522217\n",
      "step = 5864600: loss = 4.668313980102539\n",
      "step = 5864800: loss = 4.438282012939453\n",
      "step = 5865000: loss = 4.241632461547852\n",
      "step = 5865000: Average Return = 3.549999952316284\n",
      "step = 5865200: loss = 3.5183262825012207\n",
      "step = 5865400: loss = 4.220775127410889\n",
      "step = 5865600: loss = 3.673450231552124\n",
      "step = 5865800: loss = 4.030281066894531\n",
      "step = 5866000: loss = 2.686154842376709\n",
      "step = 5866200: loss = 3.46889066696167\n",
      "step = 5866400: loss = 4.270076274871826\n",
      "step = 5866600: loss = 3.7471673488616943\n",
      "step = 5866800: loss = 4.320116996765137\n",
      "step = 5867000: loss = 4.546169281005859\n",
      "step = 5867200: loss = 4.029491424560547\n",
      "step = 5867400: loss = 3.9234182834625244\n",
      "step = 5867600: loss = 4.129037857055664\n",
      "step = 5867800: loss = 4.916013717651367\n",
      "step = 5868000: loss = 3.7789127826690674\n",
      "step = 5868200: loss = 2.964272975921631\n",
      "step = 5868400: loss = 3.854872703552246\n",
      "step = 5868600: loss = 4.691769123077393\n",
      "step = 5868800: loss = 3.2816710472106934\n",
      "step = 5869000: loss = 4.031814098358154\n",
      "step = 5869200: loss = 4.0496063232421875\n",
      "step = 5869400: loss = 4.92446756362915\n",
      "step = 5869600: loss = 3.5478177070617676\n",
      "step = 5869800: loss = 4.320471286773682\n",
      "step = 5870000: loss = 5.380307674407959\n",
      "step = 5870000: Average Return = 3.5999999046325684\n",
      "step = 5870200: loss = 3.318103313446045\n",
      "step = 5870400: loss = 3.1340672969818115\n",
      "step = 5870600: loss = 3.709784984588623\n",
      "step = 5870800: loss = 3.7840771675109863\n",
      "step = 5871000: loss = 3.4970998764038086\n",
      "step = 5871200: loss = 2.630186080932617\n",
      "step = 5871400: loss = 4.542806625366211\n",
      "step = 5871600: loss = 3.533200263977051\n",
      "step = 5871800: loss = 4.101611137390137\n",
      "step = 5872000: loss = 4.0280632972717285\n",
      "step = 5872200: loss = 3.6198103427886963\n",
      "step = 5872400: loss = 5.164350509643555\n",
      "step = 5872600: loss = 4.253072738647461\n",
      "step = 5872800: loss = 4.632544994354248\n",
      "step = 5873000: loss = 3.397064208984375\n",
      "step = 5873200: loss = 3.589585542678833\n",
      "step = 5873400: loss = 3.3118231296539307\n",
      "step = 5873600: loss = 3.887699842453003\n",
      "step = 5873800: loss = 3.1526663303375244\n",
      "step = 5874000: loss = 3.4981372356414795\n",
      "step = 5874200: loss = 3.6153531074523926\n",
      "step = 5874400: loss = 3.981144666671753\n",
      "step = 5874600: loss = 3.8786046504974365\n",
      "step = 5874800: loss = 2.8175697326660156\n",
      "step = 5875000: loss = 4.115437984466553\n",
      "step = 5875000: Average Return = 4.900000095367432\n",
      "step = 5875200: loss = 3.9293649196624756\n",
      "step = 5875400: loss = 4.089991569519043\n",
      "step = 5875600: loss = 3.7886831760406494\n",
      "step = 5875800: loss = 4.109830856323242\n",
      "step = 5876000: loss = 3.353566884994507\n",
      "step = 5876200: loss = 2.595160484313965\n",
      "step = 5876400: loss = 4.112069129943848\n",
      "step = 5876600: loss = 3.335129976272583\n",
      "step = 5876800: loss = 3.415898561477661\n",
      "step = 5877000: loss = 3.0649962425231934\n",
      "step = 5877200: loss = 3.642507553100586\n",
      "step = 5877400: loss = 3.419373035430908\n",
      "step = 5877600: loss = 3.9243111610412598\n",
      "step = 5877800: loss = 3.300576686859131\n",
      "step = 5878000: loss = 4.1996169090271\n",
      "step = 5878200: loss = 2.98750901222229\n",
      "step = 5878400: loss = 3.5770134925842285\n",
      "step = 5878600: loss = 4.91176176071167\n",
      "step = 5878800: loss = 3.794135570526123\n",
      "step = 5879000: loss = 3.634976625442505\n",
      "step = 5879200: loss = 4.6190948486328125\n",
      "step = 5879400: loss = 4.224996089935303\n",
      "step = 5879600: loss = 5.135124206542969\n",
      "step = 5879800: loss = 3.1238536834716797\n",
      "step = 5880000: loss = 4.2348246574401855\n",
      "step = 5880000: Average Return = 2.549999952316284\n",
      "step = 5880200: loss = 3.360652446746826\n",
      "step = 5880400: loss = 4.206028461456299\n",
      "step = 5880600: loss = 3.899217128753662\n",
      "step = 5880800: loss = 2.7154088020324707\n",
      "step = 5881000: loss = 3.604966640472412\n",
      "step = 5881200: loss = 4.468570232391357\n",
      "step = 5881400: loss = 3.8717784881591797\n",
      "step = 5881600: loss = 4.22415018081665\n",
      "step = 5881800: loss = 2.9863505363464355\n",
      "step = 5882000: loss = 2.4864320755004883\n",
      "step = 5882200: loss = 4.450398921966553\n",
      "step = 5882400: loss = 4.1098222732543945\n",
      "step = 5882600: loss = 3.330902099609375\n",
      "step = 5882800: loss = 3.363145112991333\n",
      "step = 5883000: loss = 4.557470798492432\n",
      "step = 5883200: loss = 4.156910419464111\n",
      "step = 5883400: loss = 3.364006280899048\n",
      "step = 5883600: loss = 3.96819806098938\n",
      "step = 5883800: loss = 3.9646530151367188\n",
      "step = 5884000: loss = 4.664688587188721\n",
      "step = 5884200: loss = 5.730270862579346\n",
      "step = 5884400: loss = 4.290191173553467\n",
      "step = 5884600: loss = 2.894104480743408\n",
      "step = 5884800: loss = 4.142642498016357\n",
      "step = 5885000: loss = 3.93782639503479\n",
      "step = 5885000: Average Return = 3.1500000953674316\n",
      "step = 5885200: loss = 3.3359901905059814\n",
      "step = 5885400: loss = 4.124085426330566\n",
      "step = 5885600: loss = 2.454619884490967\n",
      "step = 5885800: loss = 4.718225955963135\n",
      "step = 5886000: loss = 4.201578617095947\n",
      "step = 5886200: loss = 3.3656370639801025\n",
      "step = 5886400: loss = 4.998199939727783\n",
      "step = 5886600: loss = 2.2267794609069824\n",
      "step = 5886800: loss = 3.281079053878784\n",
      "step = 5887000: loss = 3.478830575942993\n",
      "step = 5887200: loss = 3.243845224380493\n",
      "step = 5887400: loss = 3.344045877456665\n",
      "step = 5887600: loss = 4.091427326202393\n",
      "step = 5887800: loss = 5.003218650817871\n",
      "step = 5888000: loss = 4.317725658416748\n",
      "step = 5888200: loss = 4.6238532066345215\n",
      "step = 5888400: loss = 2.7721712589263916\n",
      "step = 5888600: loss = 4.523219585418701\n",
      "step = 5888800: loss = 3.599330425262451\n",
      "step = 5889000: loss = 2.5108723640441895\n",
      "step = 5889200: loss = 3.610316753387451\n",
      "step = 5889400: loss = 3.467804193496704\n",
      "step = 5889600: loss = 4.604257583618164\n",
      "step = 5889800: loss = 4.310150623321533\n",
      "step = 5890000: loss = 3.5808677673339844\n",
      "step = 5890000: Average Return = 5.5\n",
      "step = 5890200: loss = 3.027937650680542\n",
      "step = 5890400: loss = 4.239534378051758\n",
      "step = 5890600: loss = 3.1348137855529785\n",
      "step = 5890800: loss = 3.4022016525268555\n",
      "step = 5891000: loss = 3.678297281265259\n",
      "step = 5891200: loss = 4.657201290130615\n",
      "step = 5891400: loss = 3.8365867137908936\n",
      "step = 5891600: loss = 4.5480170249938965\n",
      "step = 5891800: loss = 4.503897666931152\n",
      "step = 5892000: loss = 3.1737492084503174\n",
      "step = 5892200: loss = 4.235474586486816\n",
      "step = 5892400: loss = 4.477075576782227\n",
      "step = 5892600: loss = 6.221586227416992\n",
      "step = 5892800: loss = 3.1340324878692627\n",
      "step = 5893000: loss = 2.5857601165771484\n",
      "step = 5893200: loss = 3.9385271072387695\n",
      "step = 5893400: loss = 3.3208062648773193\n",
      "step = 5893600: loss = 3.5027995109558105\n",
      "step = 5893800: loss = 3.7970738410949707\n",
      "step = 5894000: loss = 2.639800548553467\n",
      "step = 5894200: loss = 3.439751625061035\n",
      "step = 5894400: loss = 4.336369514465332\n",
      "step = 5894600: loss = 4.446547508239746\n",
      "step = 5894800: loss = 4.547926425933838\n",
      "step = 5895000: loss = 3.6738762855529785\n",
      "step = 5895000: Average Return = 3.950000047683716\n",
      "step = 5895200: loss = 4.987712860107422\n",
      "step = 5895400: loss = 5.088490009307861\n",
      "step = 5895600: loss = 4.3355393409729\n",
      "step = 5895800: loss = 5.153400897979736\n",
      "step = 5896000: loss = 4.578223705291748\n",
      "step = 5896200: loss = 3.0095348358154297\n",
      "step = 5896400: loss = 4.19183874130249\n",
      "step = 5896600: loss = 3.9656548500061035\n",
      "step = 5896800: loss = 4.104307651519775\n",
      "step = 5897000: loss = 3.5883126258850098\n",
      "step = 5897200: loss = 5.70770263671875\n",
      "step = 5897400: loss = 5.006060600280762\n",
      "step = 5897600: loss = 3.294095277786255\n",
      "step = 5897800: loss = 4.821499347686768\n",
      "step = 5898000: loss = 4.556271076202393\n",
      "step = 5898200: loss = 3.88553524017334\n",
      "step = 5898400: loss = 4.629001617431641\n",
      "step = 5898600: loss = 3.0994045734405518\n",
      "step = 5898800: loss = 4.178972244262695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 5899000: loss = 3.5102458000183105\n",
      "step = 5899200: loss = 3.826949119567871\n",
      "step = 5899400: loss = 4.102674961090088\n",
      "step = 5899600: loss = 3.8427844047546387\n",
      "step = 5899800: loss = 3.9962193965911865\n",
      "step = 5900000: loss = 4.2103118896484375\n",
      "step = 5900000: Average Return = 5.25\n",
      "step = 5900200: loss = 3.639965534210205\n",
      "step = 5900400: loss = 2.7950527667999268\n",
      "step = 5900600: loss = 4.134454250335693\n",
      "step = 5900800: loss = 3.7410271167755127\n",
      "step = 5901000: loss = 5.359184265136719\n",
      "step = 5901200: loss = 3.648467540740967\n",
      "step = 5901400: loss = 3.8631510734558105\n",
      "step = 5901600: loss = 3.5109825134277344\n",
      "step = 5901800: loss = 3.465287208557129\n",
      "step = 5902000: loss = 3.8869099617004395\n",
      "step = 5902200: loss = 4.153110027313232\n",
      "step = 5902400: loss = 4.243819713592529\n",
      "step = 5902600: loss = 4.848134517669678\n",
      "step = 5902800: loss = 4.4456634521484375\n",
      "step = 5903000: loss = 4.148304462432861\n",
      "step = 5903200: loss = 3.283128023147583\n",
      "step = 5903400: loss = 3.5226190090179443\n",
      "step = 5903600: loss = 3.5916566848754883\n",
      "step = 5903800: loss = 3.3286516666412354\n",
      "step = 5904000: loss = 3.3729443550109863\n",
      "step = 5904200: loss = 3.561861991882324\n",
      "step = 5904400: loss = 4.485270023345947\n",
      "step = 5904600: loss = 4.21535587310791\n",
      "step = 5904800: loss = 4.914007663726807\n",
      "step = 5905000: loss = 3.7118122577667236\n",
      "step = 5905000: Average Return = 3.4000000953674316\n",
      "step = 5905200: loss = 5.586112976074219\n",
      "step = 5905400: loss = 4.041638374328613\n",
      "step = 5905600: loss = 4.49321985244751\n",
      "step = 5905800: loss = 3.115487575531006\n",
      "step = 5906000: loss = 3.2879278659820557\n",
      "step = 5906200: loss = 4.232750415802002\n",
      "step = 5906400: loss = 4.145390510559082\n",
      "step = 5906600: loss = 3.210056781768799\n",
      "step = 5906800: loss = 4.2284698486328125\n",
      "step = 5907000: loss = 3.581813335418701\n",
      "step = 5907200: loss = 3.059189796447754\n",
      "step = 5907400: loss = 4.092260837554932\n",
      "step = 5907600: loss = 3.0080130100250244\n",
      "step = 5907800: loss = 4.209514141082764\n",
      "step = 5908000: loss = 4.138076305389404\n",
      "step = 5908200: loss = 2.9792873859405518\n",
      "step = 5908400: loss = 3.509641408920288\n",
      "step = 5908600: loss = 4.032547950744629\n",
      "step = 5908800: loss = 3.4693410396575928\n",
      "step = 5909000: loss = 3.4866271018981934\n",
      "step = 5909200: loss = 3.8590147495269775\n",
      "step = 5909400: loss = 2.8226962089538574\n",
      "step = 5909600: loss = 3.6042933464050293\n",
      "step = 5909800: loss = 4.255278587341309\n",
      "step = 5910000: loss = 4.458240032196045\n",
      "step = 5910000: Average Return = 3.1500000953674316\n",
      "step = 5910200: loss = 3.472262144088745\n",
      "step = 5910400: loss = 4.295894145965576\n",
      "step = 5910600: loss = 4.395383358001709\n",
      "step = 5910800: loss = 3.97051739692688\n",
      "step = 5911000: loss = 3.923776865005493\n",
      "step = 5911200: loss = 3.7991247177124023\n",
      "step = 5911400: loss = 3.8782918453216553\n",
      "step = 5911600: loss = 4.813755512237549\n",
      "step = 5911800: loss = 3.599423408508301\n",
      "step = 5912000: loss = 3.5657756328582764\n",
      "step = 5912200: loss = 4.330636978149414\n",
      "step = 5912400: loss = 3.5171263217926025\n",
      "step = 5912600: loss = 3.0641300678253174\n",
      "step = 5912800: loss = 4.301974296569824\n",
      "step = 5913000: loss = 2.727409601211548\n",
      "step = 5913200: loss = 4.76652193069458\n",
      "step = 5913400: loss = 4.5015692710876465\n",
      "step = 5913600: loss = 3.8863914012908936\n",
      "step = 5913800: loss = 3.324995279312134\n",
      "step = 5914000: loss = 4.0204339027404785\n",
      "step = 5914200: loss = 4.740972995758057\n",
      "step = 5914400: loss = 4.477616310119629\n",
      "step = 5914600: loss = 4.189181327819824\n",
      "step = 5914800: loss = 4.109476566314697\n",
      "step = 5915000: loss = 2.5645337104797363\n",
      "step = 5915000: Average Return = 2.950000047683716\n",
      "step = 5915200: loss = 4.290594577789307\n",
      "step = 5915400: loss = 3.524975538253784\n",
      "step = 5915600: loss = 4.3010711669921875\n",
      "step = 5915800: loss = 3.8807525634765625\n",
      "step = 5916000: loss = 3.7287206649780273\n",
      "step = 5916200: loss = 3.4991307258605957\n",
      "step = 5916400: loss = 3.623833656311035\n",
      "step = 5916600: loss = 2.925372362136841\n",
      "step = 5916800: loss = 3.2693235874176025\n",
      "step = 5917000: loss = 4.712882041931152\n",
      "step = 5917200: loss = 4.590223789215088\n",
      "step = 5917400: loss = 4.158483028411865\n",
      "step = 5917600: loss = 3.6192283630371094\n",
      "step = 5917800: loss = 3.160088539123535\n",
      "step = 5918000: loss = 3.8552088737487793\n",
      "step = 5918200: loss = 4.177389144897461\n",
      "step = 5918400: loss = 4.248648166656494\n",
      "step = 5918600: loss = 3.4597043991088867\n",
      "step = 5918800: loss = 3.718860387802124\n",
      "step = 5919000: loss = 4.632932186126709\n",
      "step = 5919200: loss = 3.0893003940582275\n",
      "step = 5919400: loss = 4.477413654327393\n",
      "step = 5919600: loss = 3.7188048362731934\n",
      "step = 5919800: loss = 3.873187780380249\n",
      "step = 5920000: loss = 3.5871095657348633\n",
      "step = 5920000: Average Return = 3.549999952316284\n",
      "step = 5920200: loss = 3.220137596130371\n",
      "step = 5920400: loss = 4.926521301269531\n",
      "step = 5920600: loss = 2.858785390853882\n",
      "step = 5920800: loss = 4.259466648101807\n",
      "step = 5921000: loss = 3.758572816848755\n",
      "step = 5921200: loss = 4.081505298614502\n",
      "step = 5921400: loss = 2.6064255237579346\n",
      "step = 5921600: loss = 5.083229064941406\n",
      "step = 5921800: loss = 2.661442279815674\n",
      "step = 5922000: loss = 4.2150492668151855\n",
      "step = 5922200: loss = 4.253618240356445\n",
      "step = 5922400: loss = 3.1301896572113037\n",
      "step = 5922600: loss = 4.805733680725098\n",
      "step = 5922800: loss = 2.419243335723877\n",
      "step = 5923000: loss = 4.664273738861084\n",
      "step = 5923200: loss = 2.435352325439453\n",
      "step = 5923400: loss = 2.8085403442382812\n",
      "step = 5923600: loss = 2.9128496646881104\n",
      "step = 5923800: loss = 4.215712070465088\n",
      "step = 5924000: loss = 4.6871337890625\n",
      "step = 5924200: loss = 2.946577310562134\n",
      "step = 5924400: loss = 3.681471824645996\n",
      "step = 5924600: loss = 3.9530882835388184\n",
      "step = 5924800: loss = 4.477412700653076\n",
      "step = 5925000: loss = 4.971743106842041\n",
      "step = 5925000: Average Return = 3.5\n",
      "step = 5925200: loss = 4.497872352600098\n",
      "step = 5925400: loss = 2.4352688789367676\n",
      "step = 5925600: loss = 3.085289239883423\n",
      "step = 5925800: loss = 4.184305191040039\n",
      "step = 5926000: loss = 2.9165289402008057\n",
      "step = 5926200: loss = 4.421752452850342\n",
      "step = 5926400: loss = 4.878512859344482\n",
      "step = 5926600: loss = 3.6757097244262695\n",
      "step = 5926800: loss = 4.028234004974365\n",
      "step = 5927000: loss = 6.3180832862854\n",
      "step = 5927200: loss = 5.111504077911377\n",
      "step = 5927400: loss = 5.261028289794922\n",
      "step = 5927600: loss = 2.5375802516937256\n",
      "step = 5927800: loss = 4.4351725578308105\n",
      "step = 5928000: loss = 4.342548847198486\n",
      "step = 5928200: loss = 3.644507646560669\n",
      "step = 5928400: loss = 4.2303009033203125\n",
      "step = 5928600: loss = 3.736945390701294\n",
      "step = 5928800: loss = 5.171241283416748\n",
      "step = 5929000: loss = 3.812866449356079\n",
      "step = 5929200: loss = 3.382242441177368\n",
      "step = 5929400: loss = 3.0452306270599365\n",
      "step = 5929600: loss = 3.1201601028442383\n",
      "step = 5929800: loss = 3.7906737327575684\n",
      "step = 5930000: loss = 4.073625087738037\n",
      "step = 5930000: Average Return = 3.25\n",
      "step = 5930200: loss = 3.9875171184539795\n",
      "step = 5930400: loss = 3.4018654823303223\n",
      "step = 5930600: loss = 4.871596336364746\n",
      "step = 5930800: loss = 3.913583993911743\n",
      "step = 5931000: loss = 4.02017068862915\n",
      "step = 5931200: loss = 3.500539779663086\n",
      "step = 5931400: loss = 4.381421089172363\n",
      "step = 5931600: loss = 4.888999938964844\n",
      "step = 5931800: loss = 4.238285541534424\n",
      "step = 5932000: loss = 3.338740825653076\n",
      "step = 5932200: loss = 4.047338008880615\n",
      "step = 5932400: loss = 4.013273239135742\n",
      "step = 5932600: loss = 4.9154744148254395\n",
      "step = 5932800: loss = 3.841370105743408\n",
      "step = 5933000: loss = 2.969853401184082\n",
      "step = 5933200: loss = 5.649819374084473\n",
      "step = 5933400: loss = 3.8575780391693115\n",
      "step = 5933600: loss = 4.632586479187012\n",
      "step = 5933800: loss = 3.6021292209625244\n",
      "step = 5934000: loss = 4.206245422363281\n",
      "step = 5934200: loss = 3.410315990447998\n",
      "step = 5934400: loss = 4.209097862243652\n",
      "step = 5934600: loss = 4.195632457733154\n",
      "step = 5934800: loss = 3.5078957080841064\n",
      "step = 5935000: loss = 3.5947751998901367\n",
      "step = 5935000: Average Return = 4.0\n",
      "step = 5935200: loss = 4.644958972930908\n",
      "step = 5935400: loss = 4.422447681427002\n",
      "step = 5935600: loss = 4.2876410484313965\n",
      "step = 5935800: loss = 3.9201509952545166\n",
      "step = 5936000: loss = 3.008098602294922\n",
      "step = 5936200: loss = 3.841820478439331\n",
      "step = 5936400: loss = 4.402265548706055\n",
      "step = 5936600: loss = 3.940216541290283\n",
      "step = 5936800: loss = 4.509477615356445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 5937000: loss = 4.162618160247803\n",
      "step = 5937200: loss = 3.0465643405914307\n",
      "step = 5937400: loss = 2.8952441215515137\n",
      "step = 5937600: loss = 2.649448871612549\n",
      "step = 5937800: loss = 3.53291916847229\n",
      "step = 5938000: loss = 3.7650887966156006\n",
      "step = 5938200: loss = 3.5263421535491943\n",
      "step = 5938400: loss = 3.060511827468872\n",
      "step = 5938600: loss = 2.6655402183532715\n",
      "step = 5938800: loss = 4.041779518127441\n",
      "step = 5939000: loss = 3.4050467014312744\n",
      "step = 5939200: loss = 3.694695234298706\n",
      "step = 5939400: loss = 3.2386324405670166\n",
      "step = 5939600: loss = 3.517268657684326\n",
      "step = 5939800: loss = 3.6998705863952637\n",
      "step = 5940000: loss = 4.905467987060547\n",
      "step = 5940000: Average Return = 3.299999952316284\n",
      "step = 5940200: loss = 3.230567455291748\n",
      "step = 5940400: loss = 3.6785223484039307\n",
      "step = 5940600: loss = 3.9328057765960693\n",
      "step = 5940800: loss = 3.744997978210449\n",
      "step = 5941000: loss = 3.615773916244507\n",
      "step = 5941200: loss = 3.6778721809387207\n",
      "step = 5941400: loss = 3.1400158405303955\n",
      "step = 5941600: loss = 4.305392742156982\n",
      "step = 5941800: loss = 3.328151226043701\n",
      "step = 5942000: loss = 4.904416561126709\n",
      "step = 5942200: loss = 4.078491687774658\n",
      "step = 5942400: loss = 3.1909334659576416\n",
      "step = 5942600: loss = 3.564314126968384\n",
      "step = 5942800: loss = 4.626835346221924\n",
      "step = 5943000: loss = 3.6363561153411865\n",
      "step = 5943200: loss = 3.834181547164917\n",
      "step = 5943400: loss = 3.050596237182617\n",
      "step = 5943600: loss = 2.8564953804016113\n",
      "step = 5943800: loss = 3.2325329780578613\n",
      "step = 5944000: loss = 3.6538994312286377\n",
      "step = 5944200: loss = 3.7393245697021484\n",
      "step = 5944400: loss = 3.5486297607421875\n",
      "step = 5944600: loss = 4.6874189376831055\n",
      "step = 5944800: loss = 2.016178846359253\n",
      "step = 5945000: loss = 3.9506728649139404\n",
      "step = 5945000: Average Return = 3.049999952316284\n",
      "step = 5945200: loss = 4.637111663818359\n",
      "step = 5945400: loss = 3.29073166847229\n",
      "step = 5945600: loss = 4.677648067474365\n",
      "step = 5945800: loss = 3.3675386905670166\n",
      "step = 5946000: loss = 4.89847993850708\n",
      "step = 5946200: loss = 4.191389560699463\n",
      "step = 5946400: loss = 3.794250011444092\n",
      "step = 5946600: loss = 3.5022168159484863\n",
      "step = 5946800: loss = 4.056732177734375\n",
      "step = 5947000: loss = 3.8356218338012695\n",
      "step = 5947200: loss = 5.019729137420654\n",
      "step = 5947400: loss = 5.137039661407471\n",
      "step = 5947600: loss = 2.867837429046631\n",
      "step = 5947800: loss = 4.552401542663574\n",
      "step = 5948000: loss = 4.103841781616211\n",
      "step = 5948200: loss = 4.015338897705078\n",
      "step = 5948400: loss = 4.08333683013916\n",
      "step = 5948600: loss = 3.0533995628356934\n",
      "step = 5948800: loss = 4.294132709503174\n",
      "step = 5949000: loss = 3.4812660217285156\n",
      "step = 5949200: loss = 3.2788190841674805\n",
      "step = 5949400: loss = 3.679166555404663\n",
      "step = 5949600: loss = 4.284988880157471\n",
      "step = 5949800: loss = 2.9628145694732666\n",
      "step = 5950000: loss = 2.581639051437378\n",
      "step = 5950000: Average Return = 3.049999952316284\n",
      "step = 5950200: loss = 2.5056252479553223\n",
      "step = 5950400: loss = 2.612560987472534\n",
      "step = 5950600: loss = 5.33465576171875\n",
      "step = 5950800: loss = 3.4348552227020264\n",
      "step = 5951000: loss = 3.9056179523468018\n",
      "step = 5951200: loss = 4.247581958770752\n",
      "step = 5951400: loss = 3.913289785385132\n",
      "step = 5951600: loss = 4.1142120361328125\n",
      "step = 5951800: loss = 4.410106182098389\n",
      "step = 5952000: loss = 4.708286762237549\n",
      "step = 5952200: loss = 3.6661078929901123\n",
      "step = 5952400: loss = 3.48709774017334\n",
      "step = 5952600: loss = 4.4807658195495605\n",
      "step = 5952800: loss = 4.751181125640869\n",
      "step = 5953000: loss = 4.051912307739258\n",
      "step = 5953200: loss = 4.178277969360352\n",
      "step = 5953400: loss = 3.7457194328308105\n",
      "step = 5953600: loss = 4.4052839279174805\n",
      "step = 5953800: loss = 3.4687821865081787\n",
      "step = 5954000: loss = 3.0515637397766113\n",
      "step = 5954200: loss = 3.381547451019287\n",
      "step = 5954400: loss = 4.979647636413574\n",
      "step = 5954600: loss = 6.125032901763916\n",
      "step = 5954800: loss = 5.226860046386719\n",
      "step = 5955000: loss = 4.129745006561279\n",
      "step = 5955000: Average Return = 3.4000000953674316\n",
      "step = 5955200: loss = 3.877875328063965\n",
      "step = 5955400: loss = 3.914144277572632\n",
      "step = 5955600: loss = 4.334595203399658\n",
      "step = 5955800: loss = 4.251350402832031\n",
      "step = 5956000: loss = 3.348018169403076\n",
      "step = 5956200: loss = 3.0044665336608887\n",
      "step = 5956400: loss = 4.79714298248291\n",
      "step = 5956600: loss = 3.753885507583618\n",
      "step = 5956800: loss = 3.337158203125\n",
      "step = 5957000: loss = 3.287368059158325\n",
      "step = 5957200: loss = 3.6099355220794678\n",
      "step = 5957400: loss = 2.8594253063201904\n",
      "step = 5957600: loss = 3.891759157180786\n",
      "step = 5957800: loss = 3.5773003101348877\n",
      "step = 5958000: loss = 3.302402973175049\n",
      "step = 5958200: loss = 3.4156885147094727\n",
      "step = 5958400: loss = 5.229276180267334\n",
      "step = 5958600: loss = 3.9693663120269775\n",
      "step = 5958800: loss = 3.2976908683776855\n",
      "step = 5959000: loss = 4.172273635864258\n",
      "step = 5959200: loss = 3.435739755630493\n",
      "step = 5959400: loss = 3.877824068069458\n",
      "step = 5959600: loss = 3.5367064476013184\n",
      "step = 5959800: loss = 3.5266032218933105\n",
      "step = 5960000: loss = 3.8718481063842773\n",
      "step = 5960000: Average Return = 3.299999952316284\n",
      "step = 5960200: loss = 3.2557082176208496\n",
      "step = 5960400: loss = 4.542876720428467\n",
      "step = 5960600: loss = 4.883264064788818\n",
      "step = 5960800: loss = 2.512748956680298\n",
      "step = 5961000: loss = 2.9708092212677\n",
      "step = 5961200: loss = 3.441439390182495\n",
      "step = 5961400: loss = 4.362003803253174\n",
      "step = 5961600: loss = 4.1034836769104\n",
      "step = 5961800: loss = 3.510906934738159\n",
      "step = 5962000: loss = 3.8814990520477295\n",
      "step = 5962200: loss = 4.553713321685791\n",
      "step = 5962400: loss = 2.8094704151153564\n",
      "step = 5962600: loss = 3.441128969192505\n",
      "step = 5962800: loss = 4.49787712097168\n",
      "step = 5963000: loss = 3.713865280151367\n",
      "step = 5963200: loss = 4.51570463180542\n",
      "step = 5963400: loss = 2.9230778217315674\n",
      "step = 5963600: loss = 3.196348190307617\n",
      "step = 5963800: loss = 2.9538936614990234\n",
      "step = 5964000: loss = 4.719421863555908\n",
      "step = 5964200: loss = 3.8357677459716797\n",
      "step = 5964400: loss = 5.204132556915283\n",
      "step = 5964600: loss = 4.287636756896973\n",
      "step = 5964800: loss = 3.565706968307495\n",
      "step = 5965000: loss = 3.0185775756835938\n",
      "step = 5965000: Average Return = 3.6500000953674316\n",
      "step = 5965200: loss = 3.9117612838745117\n",
      "step = 5965400: loss = 4.640568733215332\n",
      "step = 5965600: loss = 4.088602066040039\n",
      "step = 5965800: loss = 3.2546229362487793\n",
      "step = 5966000: loss = 3.802886962890625\n",
      "step = 5966200: loss = 4.739689350128174\n",
      "step = 5966400: loss = 3.603790521621704\n",
      "step = 5966600: loss = 3.8496251106262207\n",
      "step = 5966800: loss = 4.688991069793701\n",
      "step = 5967000: loss = 4.038822650909424\n",
      "step = 5967200: loss = 3.6403660774230957\n",
      "step = 5967400: loss = 4.270316123962402\n",
      "step = 5967600: loss = 2.4296398162841797\n",
      "step = 5967800: loss = 4.172385215759277\n",
      "step = 5968000: loss = 3.649973154067993\n",
      "step = 5968200: loss = 4.1090192794799805\n",
      "step = 5968400: loss = 4.2730326652526855\n",
      "step = 5968600: loss = 3.580491304397583\n",
      "step = 5968800: loss = 4.097496032714844\n",
      "step = 5969000: loss = 3.377087116241455\n",
      "step = 5969200: loss = 3.0770463943481445\n",
      "step = 5969400: loss = 2.8398537635803223\n",
      "step = 5969600: loss = 3.3279478549957275\n",
      "step = 5969800: loss = 4.506180286407471\n",
      "step = 5970000: loss = 3.106821298599243\n",
      "step = 5970000: Average Return = 2.4000000953674316\n",
      "step = 5970200: loss = 4.105943202972412\n",
      "step = 5970400: loss = 4.335979461669922\n",
      "step = 5970600: loss = 3.7900302410125732\n",
      "step = 5970800: loss = 3.769136905670166\n",
      "step = 5971000: loss = 4.423877239227295\n",
      "step = 5971200: loss = 4.966506004333496\n",
      "step = 5971400: loss = 3.070491313934326\n",
      "step = 5971600: loss = 3.6646578311920166\n",
      "step = 5971800: loss = 3.684774160385132\n",
      "step = 5972000: loss = 4.206700801849365\n",
      "step = 5972200: loss = 4.659811019897461\n",
      "step = 5972400: loss = 4.241039752960205\n",
      "step = 5972600: loss = 3.7253963947296143\n",
      "step = 5972800: loss = 4.225861549377441\n",
      "step = 5973000: loss = 4.091441631317139\n",
      "step = 5973200: loss = 3.9281346797943115\n",
      "step = 5973400: loss = 4.731459617614746\n",
      "step = 5973600: loss = 3.3127858638763428\n",
      "step = 5973800: loss = 3.7166380882263184\n",
      "step = 5974000: loss = 4.514277935028076\n",
      "step = 5974200: loss = 4.064008712768555\n",
      "step = 5974400: loss = 4.020333290100098\n",
      "step = 5974600: loss = 3.047450542449951\n",
      "step = 5974800: loss = 3.9995315074920654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 5975000: loss = 3.6874570846557617\n",
      "step = 5975000: Average Return = 2.25\n",
      "step = 5975200: loss = 3.821345329284668\n",
      "step = 5975400: loss = 3.2756872177124023\n",
      "step = 5975600: loss = 4.969371318817139\n",
      "step = 5975800: loss = 3.6989495754241943\n",
      "step = 5976000: loss = 3.089092969894409\n",
      "step = 5976200: loss = 4.440823078155518\n",
      "step = 5976400: loss = 3.447418212890625\n",
      "step = 5976600: loss = 4.6992902755737305\n",
      "step = 5976800: loss = 3.591278076171875\n",
      "step = 5977000: loss = 3.575265407562256\n",
      "step = 5977200: loss = 3.2909111976623535\n",
      "step = 5977400: loss = 3.570498466491699\n",
      "step = 5977600: loss = 3.43176531791687\n",
      "step = 5977800: loss = 3.184279680252075\n",
      "step = 5978000: loss = 3.250838041305542\n",
      "step = 5978200: loss = 4.3274078369140625\n",
      "step = 5978400: loss = 2.714406728744507\n",
      "step = 5978600: loss = 4.3384690284729\n",
      "step = 5978800: loss = 3.3966164588928223\n",
      "step = 5979000: loss = 3.292375087738037\n",
      "step = 5979200: loss = 4.3337249755859375\n",
      "step = 5979400: loss = 3.3397397994995117\n",
      "step = 5979600: loss = 4.272394180297852\n",
      "step = 5979800: loss = 5.297188758850098\n",
      "step = 5980000: loss = 4.760763645172119\n",
      "step = 5980000: Average Return = 4.199999809265137\n",
      "step = 5980200: loss = 3.108013868331909\n",
      "step = 5980400: loss = 3.3987345695495605\n",
      "step = 5980600: loss = 3.9876537322998047\n",
      "step = 5980800: loss = 5.377973556518555\n",
      "step = 5981000: loss = 2.8668859004974365\n",
      "step = 5981200: loss = 3.6680047512054443\n",
      "step = 5981400: loss = 4.2878522872924805\n",
      "step = 5981600: loss = 3.857239246368408\n",
      "step = 5981800: loss = 3.1793150901794434\n",
      "step = 5982000: loss = 5.081232070922852\n",
      "step = 5982200: loss = 3.4187541007995605\n",
      "step = 5982400: loss = 5.008382320404053\n",
      "step = 5982600: loss = 4.670297145843506\n",
      "step = 5982800: loss = 4.2561750411987305\n",
      "step = 5983000: loss = 3.401245594024658\n",
      "step = 5983200: loss = 4.053349494934082\n",
      "step = 5983400: loss = 5.485367298126221\n",
      "step = 5983600: loss = 2.7282562255859375\n",
      "step = 5983800: loss = 3.7429356575012207\n",
      "step = 5984000: loss = 4.4272613525390625\n",
      "step = 5984200: loss = 4.26027250289917\n",
      "step = 5984400: loss = 3.882056713104248\n",
      "step = 5984600: loss = 4.115123748779297\n",
      "step = 5984800: loss = 4.209606647491455\n",
      "step = 5985000: loss = 3.807756185531616\n",
      "step = 5985000: Average Return = 3.8499999046325684\n",
      "step = 5985200: loss = 2.4878289699554443\n",
      "step = 5985400: loss = 3.5347251892089844\n",
      "step = 5985600: loss = 3.474360227584839\n",
      "step = 5985800: loss = 4.202214241027832\n",
      "step = 5986000: loss = 3.2127771377563477\n",
      "step = 5986200: loss = 3.3773112297058105\n",
      "step = 5986400: loss = 4.5072550773620605\n",
      "step = 5986600: loss = 4.261180400848389\n",
      "step = 5986800: loss = 3.1623735427856445\n",
      "step = 5987000: loss = 3.2076404094696045\n",
      "step = 5987200: loss = 4.06805944442749\n",
      "step = 5987400: loss = 3.392634153366089\n",
      "step = 5987600: loss = 3.3288824558258057\n",
      "step = 5987800: loss = 5.003961563110352\n",
      "step = 5988000: loss = 4.138142108917236\n",
      "step = 5988200: loss = 2.9689760208129883\n",
      "step = 5988400: loss = 4.272238254547119\n",
      "step = 5988600: loss = 5.411007404327393\n",
      "step = 5988800: loss = 3.91861891746521\n",
      "step = 5989000: loss = 2.3423564434051514\n",
      "step = 5989200: loss = 4.070846080780029\n",
      "step = 5989400: loss = 3.9374465942382812\n",
      "step = 5989600: loss = 3.7315566539764404\n",
      "step = 5989800: loss = 4.982638835906982\n",
      "step = 5990000: loss = 3.6680519580841064\n",
      "step = 5990000: Average Return = 3.799999952316284\n",
      "step = 5990200: loss = 5.098809242248535\n",
      "step = 5990400: loss = 5.781422138214111\n",
      "step = 5990600: loss = 2.321425199508667\n",
      "step = 5990800: loss = 3.453974723815918\n",
      "step = 5991000: loss = 3.504171133041382\n",
      "step = 5991200: loss = 4.746405601501465\n",
      "step = 5991400: loss = 3.5900144577026367\n",
      "step = 5991600: loss = 3.999037981033325\n",
      "step = 5991800: loss = 4.506891250610352\n",
      "step = 5992000: loss = 4.067014694213867\n",
      "step = 5992200: loss = 5.113579750061035\n",
      "step = 5992400: loss = 3.8903050422668457\n",
      "step = 5992600: loss = 4.644476890563965\n",
      "step = 5992800: loss = 3.8692431449890137\n",
      "step = 5993000: loss = 3.7377264499664307\n",
      "step = 5993200: loss = 4.3861260414123535\n",
      "step = 5993400: loss = 4.843811511993408\n",
      "step = 5993600: loss = 4.2975969314575195\n",
      "step = 5993800: loss = 4.746427059173584\n",
      "step = 5994000: loss = 3.8766069412231445\n",
      "step = 5994200: loss = 5.11335563659668\n",
      "step = 5994400: loss = 3.7137105464935303\n",
      "step = 5994600: loss = 4.3733391761779785\n",
      "step = 5994800: loss = 2.9498651027679443\n",
      "step = 5995000: loss = 2.900447368621826\n",
      "step = 5995000: Average Return = 6.050000190734863\n",
      "step = 5995200: loss = 4.161416053771973\n",
      "step = 5995400: loss = 3.0130691528320312\n",
      "step = 5995600: loss = 3.4856033325195312\n",
      "step = 5995800: loss = 3.287632465362549\n",
      "step = 5996000: loss = 2.711196184158325\n",
      "step = 5996200: loss = 3.9511024951934814\n",
      "step = 5996400: loss = 3.2534942626953125\n",
      "step = 5996600: loss = 3.5689449310302734\n",
      "step = 5996800: loss = 4.347309112548828\n",
      "step = 5997000: loss = 3.593646764755249\n",
      "step = 5997200: loss = 4.48619270324707\n",
      "step = 5997400: loss = 3.310528516769409\n",
      "step = 5997600: loss = 4.653896331787109\n",
      "step = 5997800: loss = 4.553860187530518\n",
      "step = 5998000: loss = 3.300832748413086\n",
      "step = 5998200: loss = 4.047815322875977\n",
      "step = 5998400: loss = 3.1203300952911377\n",
      "step = 5998600: loss = 4.492151260375977\n",
      "step = 5998800: loss = 3.510988712310791\n",
      "step = 5999000: loss = 2.684004068374634\n",
      "step = 5999200: loss = 4.079392433166504\n",
      "step = 5999400: loss = 4.258665561676025\n",
      "step = 5999600: loss = 2.9104607105255127\n",
      "step = 5999800: loss = 3.735260486602783\n",
      "step = 6000000: loss = 4.701468467712402\n",
      "step = 6000000: Average Return = 5.0\n",
      "step = 6000200: loss = 3.2816405296325684\n",
      "step = 6000400: loss = 3.189051389694214\n",
      "step = 6000600: loss = 3.6817338466644287\n",
      "step = 6000800: loss = 3.353563070297241\n",
      "step = 6001000: loss = 4.624991416931152\n",
      "step = 6001200: loss = 4.733282566070557\n",
      "step = 6001400: loss = 4.392327785491943\n",
      "step = 6001600: loss = 3.7601354122161865\n",
      "step = 6001800: loss = 5.287775993347168\n",
      "step = 6002000: loss = 3.3719778060913086\n",
      "step = 6002200: loss = 4.073973178863525\n",
      "step = 6002400: loss = 2.9821200370788574\n",
      "step = 6002600: loss = 4.0731401443481445\n",
      "step = 6002800: loss = 3.194119453430176\n",
      "step = 6003000: loss = 4.1007490158081055\n",
      "step = 6003200: loss = 3.853996992111206\n",
      "step = 6003400: loss = 3.480984687805176\n",
      "step = 6003600: loss = 2.706077814102173\n",
      "step = 6003800: loss = 3.21469783782959\n",
      "step = 6004000: loss = 3.047123670578003\n",
      "step = 6004200: loss = 3.1296417713165283\n",
      "step = 6004400: loss = 4.590606689453125\n",
      "step = 6004600: loss = 3.726987838745117\n",
      "step = 6004800: loss = 4.379336357116699\n",
      "step = 6005000: loss = 4.074461460113525\n",
      "step = 6005000: Average Return = 2.700000047683716\n",
      "step = 6005200: loss = 3.42232346534729\n",
      "step = 6005400: loss = 2.947026491165161\n",
      "step = 6005600: loss = 4.70393180847168\n",
      "step = 6005800: loss = 2.604867696762085\n",
      "step = 6006000: loss = 3.241834878921509\n",
      "step = 6006200: loss = 3.7299141883850098\n",
      "step = 6006400: loss = 4.275993347167969\n",
      "step = 6006600: loss = 2.7149641513824463\n",
      "step = 6006800: loss = 4.113092422485352\n",
      "step = 6007000: loss = 3.717862367630005\n",
      "step = 6007200: loss = 5.227700233459473\n",
      "step = 6007400: loss = 4.546794414520264\n",
      "step = 6007600: loss = 3.6797568798065186\n",
      "step = 6007800: loss = 3.9986448287963867\n",
      "step = 6008000: loss = 3.967116594314575\n",
      "step = 6008200: loss = 4.143954277038574\n",
      "step = 6008400: loss = 3.3475005626678467\n",
      "step = 6008600: loss = 5.048488616943359\n",
      "step = 6008800: loss = 5.146074295043945\n",
      "step = 6009000: loss = 3.2502944469451904\n",
      "step = 6009200: loss = 4.166428089141846\n",
      "step = 6009400: loss = 4.076344013214111\n",
      "step = 6009600: loss = 3.1970977783203125\n",
      "step = 6009800: loss = 4.931860446929932\n",
      "step = 6010000: loss = 4.663013935089111\n",
      "step = 6010000: Average Return = 5.599999904632568\n",
      "step = 6010200: loss = 4.861732482910156\n",
      "step = 6010400: loss = 4.218428134918213\n",
      "step = 6010600: loss = 4.95542049407959\n",
      "step = 6010800: loss = 3.4504270553588867\n",
      "step = 6011000: loss = 5.867959976196289\n",
      "step = 6011200: loss = 4.4531755447387695\n",
      "step = 6011400: loss = 4.070493221282959\n",
      "step = 6011600: loss = 4.072906017303467\n",
      "step = 6011800: loss = 2.7647833824157715\n",
      "step = 6012000: loss = 4.5437726974487305\n",
      "step = 6012200: loss = 3.899149179458618\n",
      "step = 6012400: loss = 3.5553441047668457\n",
      "step = 6012600: loss = 3.9557669162750244\n",
      "step = 6012800: loss = 3.838613271713257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 6013000: loss = 3.114093542098999\n",
      "step = 6013200: loss = 4.196486473083496\n",
      "step = 6013400: loss = 3.2439281940460205\n",
      "step = 6013600: loss = 4.078822612762451\n",
      "step = 6013800: loss = 2.7100932598114014\n",
      "step = 6014000: loss = 4.7249274253845215\n",
      "step = 6014200: loss = 4.338990211486816\n",
      "step = 6014400: loss = 3.2847344875335693\n",
      "step = 6014600: loss = 4.329941272735596\n",
      "step = 6014800: loss = 3.895545482635498\n",
      "step = 6015000: loss = 3.2477715015411377\n",
      "step = 6015000: Average Return = 3.9000000953674316\n",
      "step = 6015200: loss = 3.6893835067749023\n",
      "step = 6015400: loss = 3.871044158935547\n",
      "step = 6015600: loss = 3.199728012084961\n",
      "step = 6015800: loss = 2.286133050918579\n",
      "step = 6016000: loss = 5.354238033294678\n",
      "step = 6016200: loss = 3.969841241836548\n",
      "step = 6016400: loss = 4.427669525146484\n",
      "step = 6016600: loss = 3.4800896644592285\n",
      "step = 6016800: loss = 3.324286937713623\n",
      "step = 6017000: loss = 3.9026927947998047\n",
      "step = 6017200: loss = 3.3222594261169434\n",
      "step = 6017400: loss = 3.865349531173706\n",
      "step = 6017600: loss = 3.7169463634490967\n",
      "step = 6017800: loss = 4.302671432495117\n",
      "step = 6018000: loss = 3.725809335708618\n",
      "step = 6018200: loss = 5.193432331085205\n",
      "step = 6018400: loss = 4.613519668579102\n",
      "step = 6018600: loss = 5.168542385101318\n",
      "step = 6018800: loss = 4.513094425201416\n",
      "step = 6019000: loss = 4.175356864929199\n",
      "step = 6019200: loss = 3.973562002182007\n",
      "step = 6019400: loss = 3.4552955627441406\n",
      "step = 6019600: loss = 3.7637877464294434\n",
      "step = 6019800: loss = 4.290488243103027\n",
      "step = 6020000: loss = 4.0048065185546875\n",
      "step = 6020000: Average Return = 2.549999952316284\n",
      "step = 6020200: loss = 3.4304211139678955\n",
      "step = 6020400: loss = 4.627774238586426\n",
      "step = 6020600: loss = 3.3993029594421387\n",
      "step = 6020800: loss = 4.625800609588623\n",
      "step = 6021000: loss = 3.6630778312683105\n",
      "step = 6021200: loss = 6.126681804656982\n",
      "step = 6021400: loss = 3.9218907356262207\n",
      "step = 6021600: loss = 3.7578673362731934\n",
      "step = 6021800: loss = 4.584698677062988\n",
      "step = 6022000: loss = 4.61030912399292\n",
      "step = 6022200: loss = 4.743095397949219\n",
      "step = 6022400: loss = 3.320032835006714\n",
      "step = 6022600: loss = 4.841043949127197\n",
      "step = 6022800: loss = 4.225968360900879\n",
      "step = 6023000: loss = 4.270638465881348\n",
      "step = 6023200: loss = 3.2883574962615967\n",
      "step = 6023400: loss = 3.597867965698242\n",
      "step = 6023600: loss = 5.880155086517334\n",
      "step = 6023800: loss = 2.5910332202911377\n",
      "step = 6024000: loss = 4.654540538787842\n",
      "step = 6024200: loss = 3.3341591358184814\n",
      "step = 6024400: loss = 3.23395037651062\n",
      "step = 6024600: loss = 3.6064512729644775\n",
      "step = 6024800: loss = 4.298399448394775\n",
      "step = 6025000: loss = 2.923218250274658\n",
      "step = 6025000: Average Return = 3.1500000953674316\n",
      "step = 6025200: loss = 4.110836505889893\n",
      "step = 6025400: loss = 3.776459217071533\n",
      "step = 6025600: loss = 2.0817792415618896\n",
      "step = 6025800: loss = 2.635762929916382\n",
      "step = 6026000: loss = 3.8792669773101807\n",
      "step = 6026200: loss = 4.01017427444458\n",
      "step = 6026400: loss = 4.504555702209473\n",
      "step = 6026600: loss = 3.7383549213409424\n",
      "step = 6026800: loss = 4.462934970855713\n",
      "step = 6027000: loss = 4.261597633361816\n",
      "step = 6027200: loss = 4.212327003479004\n",
      "step = 6027400: loss = 4.445185661315918\n",
      "step = 6027600: loss = 4.281006813049316\n",
      "step = 6027800: loss = 3.056732177734375\n",
      "step = 6028000: loss = 4.925154685974121\n",
      "step = 6028200: loss = 4.604924201965332\n",
      "step = 6028400: loss = 3.366069793701172\n",
      "step = 6028600: loss = 2.8489155769348145\n",
      "step = 6028800: loss = 3.4599854946136475\n",
      "step = 6029000: loss = 3.7259063720703125\n",
      "step = 6029200: loss = 3.6312496662139893\n",
      "step = 6029400: loss = 2.499922275543213\n",
      "step = 6029600: loss = 4.693441867828369\n",
      "step = 6029800: loss = 4.9687418937683105\n",
      "step = 6030000: loss = 3.95979642868042\n",
      "step = 6030000: Average Return = 4.099999904632568\n",
      "step = 6030200: loss = 4.414509296417236\n",
      "step = 6030400: loss = 3.752852201461792\n",
      "step = 6030600: loss = 3.75166654586792\n",
      "step = 6030800: loss = 3.887460947036743\n",
      "step = 6031000: loss = 3.982736825942993\n",
      "step = 6031200: loss = 2.848301649093628\n",
      "step = 6031400: loss = 4.634155750274658\n",
      "step = 6031600: loss = 4.079799652099609\n",
      "step = 6031800: loss = 4.456843852996826\n",
      "step = 6032000: loss = 4.40171480178833\n",
      "step = 6032200: loss = 3.8287267684936523\n",
      "step = 6032400: loss = 3.1271793842315674\n",
      "step = 6032600: loss = 2.8130528926849365\n",
      "step = 6032800: loss = 4.549375534057617\n",
      "step = 6033000: loss = 4.48895263671875\n",
      "step = 6033200: loss = 2.96586012840271\n",
      "step = 6033400: loss = 4.133668899536133\n",
      "step = 6033600: loss = 4.231921672821045\n",
      "step = 6033800: loss = 3.595808982849121\n",
      "step = 6034000: loss = 3.4356276988983154\n",
      "step = 6034200: loss = 3.637331962585449\n",
      "step = 6034400: loss = 3.6548681259155273\n",
      "step = 6034600: loss = 3.51987886428833\n",
      "step = 6034800: loss = 4.0614423751831055\n",
      "step = 6035000: loss = 3.227947950363159\n",
      "step = 6035000: Average Return = 2.950000047683716\n",
      "step = 6035200: loss = 3.154602527618408\n",
      "step = 6035400: loss = 3.235166549682617\n",
      "step = 6035600: loss = 4.248865127563477\n",
      "step = 6035800: loss = 4.389156341552734\n",
      "step = 6036000: loss = 3.3656506538391113\n",
      "step = 6036200: loss = 3.8545005321502686\n",
      "step = 6036400: loss = 5.041914463043213\n",
      "step = 6036600: loss = 4.294204235076904\n",
      "step = 6036800: loss = 4.25677490234375\n",
      "step = 6037000: loss = 4.77627420425415\n",
      "step = 6037200: loss = 2.8703866004943848\n",
      "step = 6037400: loss = 3.080559730529785\n",
      "step = 6037600: loss = 2.8993890285491943\n",
      "step = 6037800: loss = 4.280120372772217\n",
      "step = 6038000: loss = 5.00040864944458\n",
      "step = 6038200: loss = 3.4325501918792725\n",
      "step = 6038400: loss = 4.17413330078125\n",
      "step = 6038600: loss = 2.040774345397949\n",
      "step = 6038800: loss = 4.871950149536133\n",
      "step = 6039000: loss = 2.9555771350860596\n",
      "step = 6039200: loss = 4.49321174621582\n",
      "step = 6039400: loss = 3.5108931064605713\n",
      "step = 6039600: loss = 5.261832237243652\n",
      "step = 6039800: loss = 4.8402276039123535\n",
      "step = 6040000: loss = 2.986595392227173\n",
      "step = 6040000: Average Return = 3.450000047683716\n",
      "step = 6040200: loss = 3.235875129699707\n",
      "step = 6040400: loss = 3.7302989959716797\n",
      "step = 6040600: loss = 3.6826865673065186\n",
      "step = 6040800: loss = 3.5920770168304443\n",
      "step = 6041000: loss = 4.461554050445557\n",
      "step = 6041200: loss = 3.6929807662963867\n",
      "step = 6041400: loss = 3.8533520698547363\n",
      "step = 6041600: loss = 4.226047992706299\n",
      "step = 6041800: loss = 3.9772448539733887\n",
      "step = 6042000: loss = 3.466473340988159\n",
      "step = 6042200: loss = 3.046813488006592\n",
      "step = 6042400: loss = 3.6182432174682617\n",
      "step = 6042600: loss = 4.536350727081299\n",
      "step = 6042800: loss = 3.622389078140259\n",
      "step = 6043000: loss = 3.212695837020874\n",
      "step = 6043200: loss = 4.2263102531433105\n",
      "step = 6043400: loss = 4.906050205230713\n",
      "step = 6043600: loss = 2.8212673664093018\n",
      "step = 6043800: loss = 4.04679012298584\n",
      "step = 6044000: loss = 4.628026485443115\n",
      "step = 6044200: loss = 4.815378189086914\n",
      "step = 6044400: loss = 4.8232645988464355\n",
      "step = 6044600: loss = 4.035618305206299\n",
      "step = 6044800: loss = 3.968181610107422\n",
      "step = 6045000: loss = 4.103775978088379\n",
      "step = 6045000: Average Return = 3.25\n",
      "step = 6045200: loss = 4.424919605255127\n",
      "step = 6045400: loss = 4.441440105438232\n",
      "step = 6045600: loss = 4.366945743560791\n",
      "step = 6045800: loss = 3.3538637161254883\n",
      "step = 6046000: loss = 3.275230884552002\n",
      "step = 6046200: loss = 5.351294994354248\n",
      "step = 6046400: loss = 3.476160764694214\n",
      "step = 6046600: loss = 3.659662961959839\n",
      "step = 6046800: loss = 4.12715482711792\n",
      "step = 6047000: loss = 4.363767623901367\n",
      "step = 6047200: loss = 4.307053565979004\n",
      "step = 6047400: loss = 4.428140640258789\n",
      "step = 6047600: loss = 4.451234817504883\n",
      "step = 6047800: loss = 3.4337551593780518\n",
      "step = 6048000: loss = 3.729550361633301\n",
      "step = 6048200: loss = 2.508770227432251\n",
      "step = 6048400: loss = 3.6498496532440186\n",
      "step = 6048600: loss = 2.732212781906128\n",
      "step = 6048800: loss = 3.419182300567627\n",
      "step = 6049000: loss = 4.5729498863220215\n",
      "step = 6049200: loss = 3.501978874206543\n",
      "step = 6049400: loss = 2.737333297729492\n",
      "step = 6049600: loss = 2.8411526679992676\n",
      "step = 6049800: loss = 3.1011016368865967\n",
      "step = 6050000: loss = 4.680506706237793\n",
      "step = 6050000: Average Return = 4.949999809265137\n",
      "step = 6050200: loss = 2.576815366744995\n",
      "step = 6050400: loss = 4.576563835144043\n",
      "step = 6050600: loss = 4.438073635101318\n",
      "step = 6050800: loss = 3.8155431747436523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 6051000: loss = 3.9245495796203613\n",
      "step = 6051200: loss = 5.603734016418457\n",
      "step = 6051400: loss = 3.956665515899658\n",
      "step = 6051600: loss = 4.533477783203125\n",
      "step = 6051800: loss = 3.192484140396118\n",
      "step = 6052000: loss = 4.31875467300415\n",
      "step = 6052200: loss = 4.4511919021606445\n",
      "step = 6052400: loss = 3.2609453201293945\n",
      "step = 6052600: loss = 2.839890480041504\n",
      "step = 6052800: loss = 4.283290863037109\n",
      "step = 6053000: loss = 4.756802082061768\n",
      "step = 6053200: loss = 5.020773410797119\n",
      "step = 6053400: loss = 3.03115177154541\n",
      "step = 6053600: loss = 3.8237693309783936\n",
      "step = 6053800: loss = 4.295290946960449\n",
      "step = 6054000: loss = 5.325100421905518\n",
      "step = 6054200: loss = 3.95975923538208\n",
      "step = 6054400: loss = 3.614377975463867\n",
      "step = 6054600: loss = 4.1776957511901855\n",
      "step = 6054800: loss = 3.853131055831909\n",
      "step = 6055000: loss = 2.586747884750366\n",
      "step = 6055000: Average Return = 4.800000190734863\n",
      "step = 6055200: loss = 4.670959949493408\n",
      "step = 6055400: loss = 4.1111016273498535\n",
      "step = 6055600: loss = 4.079522609710693\n",
      "step = 6055800: loss = 4.977626800537109\n",
      "step = 6056000: loss = 3.7624261379241943\n",
      "step = 6056200: loss = 3.912175178527832\n",
      "step = 6056400: loss = 4.36305046081543\n",
      "step = 6056600: loss = 4.0888872146606445\n",
      "step = 6056800: loss = 4.306933879852295\n",
      "step = 6057000: loss = 4.068605422973633\n",
      "step = 6057200: loss = 2.79927921295166\n",
      "step = 6057400: loss = 4.006592273712158\n",
      "step = 6057600: loss = 4.467691898345947\n",
      "step = 6057800: loss = 3.282315492630005\n",
      "step = 6058000: loss = 4.017237663269043\n",
      "step = 6058200: loss = 2.275484561920166\n",
      "step = 6058400: loss = 3.953286647796631\n",
      "step = 6058600: loss = 3.4802520275115967\n",
      "step = 6058800: loss = 4.036041736602783\n",
      "step = 6059000: loss = 3.923506498336792\n",
      "step = 6059200: loss = 3.503237247467041\n",
      "step = 6059400: loss = 3.4649596214294434\n",
      "step = 6059600: loss = 3.674560546875\n",
      "step = 6059800: loss = 4.325960159301758\n",
      "step = 6060000: loss = 4.2611284255981445\n",
      "step = 6060000: Average Return = 5.199999809265137\n",
      "step = 6060200: loss = 3.1415812969207764\n",
      "step = 6060400: loss = 3.652996063232422\n",
      "step = 6060600: loss = 2.9901933670043945\n",
      "step = 6060800: loss = 4.684358596801758\n",
      "step = 6061000: loss = 4.090796947479248\n",
      "step = 6061200: loss = 3.1474273204803467\n",
      "step = 6061400: loss = 3.613906145095825\n",
      "step = 6061600: loss = 3.537864923477173\n",
      "step = 6061800: loss = 4.457034587860107\n",
      "step = 6062000: loss = 3.5731515884399414\n",
      "step = 6062200: loss = 4.013810157775879\n",
      "step = 6062400: loss = 3.993692636489868\n",
      "step = 6062600: loss = 3.882874011993408\n",
      "step = 6062800: loss = 4.332545280456543\n",
      "step = 6063000: loss = 3.128037452697754\n",
      "step = 6063200: loss = 3.883516788482666\n",
      "step = 6063400: loss = 2.8252480030059814\n",
      "step = 6063600: loss = 4.0398077964782715\n",
      "step = 6063800: loss = 2.852952241897583\n",
      "step = 6064000: loss = 3.4735941886901855\n",
      "step = 6064200: loss = 3.8494646549224854\n",
      "step = 6064400: loss = 3.151050090789795\n",
      "step = 6064600: loss = 3.614500045776367\n",
      "step = 6064800: loss = 3.1261327266693115\n",
      "step = 6065000: loss = 2.7394859790802\n",
      "step = 6065000: Average Return = 3.9000000953674316\n",
      "step = 6065200: loss = 4.432227611541748\n",
      "step = 6065400: loss = 2.380382776260376\n",
      "step = 6065600: loss = 3.228257417678833\n",
      "step = 6065800: loss = 4.048542022705078\n",
      "step = 6066000: loss = 2.892852783203125\n",
      "step = 6066200: loss = 4.2166900634765625\n",
      "step = 6066400: loss = 4.03076696395874\n",
      "step = 6066600: loss = 4.086058139801025\n",
      "step = 6066800: loss = 4.748733043670654\n",
      "step = 6067000: loss = 4.529392719268799\n",
      "step = 6067200: loss = 3.6279497146606445\n",
      "step = 6067400: loss = 3.8161470890045166\n",
      "step = 6067600: loss = 2.7935922145843506\n",
      "step = 6067800: loss = 4.203582286834717\n",
      "step = 6068000: loss = 4.138923168182373\n",
      "step = 6068200: loss = 2.6833717823028564\n",
      "step = 6068400: loss = 4.015444755554199\n",
      "step = 6068600: loss = 3.593519926071167\n",
      "step = 6068800: loss = 3.066160202026367\n",
      "step = 6069000: loss = 2.8222856521606445\n",
      "step = 6069200: loss = 3.983597993850708\n",
      "step = 6069400: loss = 1.8742650747299194\n",
      "step = 6069600: loss = 3.343449592590332\n",
      "step = 6069800: loss = 3.8423702716827393\n",
      "step = 6070000: loss = 2.532951831817627\n",
      "step = 6070000: Average Return = 4.199999809265137\n",
      "step = 6070200: loss = 4.345605850219727\n",
      "step = 6070400: loss = 2.565755844116211\n",
      "step = 6070600: loss = 3.0609562397003174\n",
      "step = 6070800: loss = 3.40856671333313\n",
      "step = 6071000: loss = 4.127444744110107\n",
      "step = 6071200: loss = 4.482290744781494\n",
      "step = 6071400: loss = 3.9715614318847656\n",
      "step = 6071600: loss = 5.172801494598389\n",
      "step = 6071800: loss = 3.715259313583374\n",
      "step = 6072000: loss = 4.041534423828125\n",
      "step = 6072200: loss = 4.653636932373047\n",
      "step = 6072400: loss = 3.4600040912628174\n",
      "step = 6072600: loss = 4.0589823722839355\n",
      "step = 6072800: loss = 3.654744863510132\n",
      "step = 6073000: loss = 3.8638548851013184\n",
      "step = 6073200: loss = 3.7146267890930176\n",
      "step = 6073400: loss = 3.034485340118408\n",
      "step = 6073600: loss = 2.9014928340911865\n",
      "step = 6073800: loss = 3.781106472015381\n",
      "step = 6074000: loss = 4.420284748077393\n",
      "step = 6074200: loss = 3.8724846839904785\n",
      "step = 6074400: loss = 3.454681873321533\n",
      "step = 6074600: loss = 4.31071138381958\n",
      "step = 6074800: loss = 2.976006507873535\n",
      "step = 6075000: loss = 3.271045207977295\n",
      "step = 6075000: Average Return = 3.6500000953674316\n",
      "step = 6075200: loss = 4.247302055358887\n",
      "step = 6075400: loss = 3.0866520404815674\n",
      "step = 6075600: loss = 4.002416133880615\n",
      "step = 6075800: loss = 5.113221168518066\n",
      "step = 6076000: loss = 3.589555501937866\n",
      "step = 6076200: loss = 3.487308979034424\n",
      "step = 6076400: loss = 4.327277183532715\n",
      "step = 6076600: loss = 4.751850605010986\n",
      "step = 6076800: loss = 3.8242881298065186\n",
      "step = 6077000: loss = 4.655817031860352\n",
      "step = 6077200: loss = 3.8310585021972656\n",
      "step = 6077400: loss = 3.0344011783599854\n",
      "step = 6077600: loss = 4.486922740936279\n",
      "step = 6077800: loss = 3.3871030807495117\n",
      "step = 6078000: loss = 3.420583724975586\n",
      "step = 6078200: loss = 4.529779434204102\n",
      "step = 6078400: loss = 4.097968101501465\n",
      "step = 6078600: loss = 4.84130859375\n",
      "step = 6078800: loss = 4.033362865447998\n",
      "step = 6079000: loss = 4.657442092895508\n",
      "step = 6079200: loss = 5.952486038208008\n",
      "step = 6079400: loss = 3.183008909225464\n",
      "step = 6079600: loss = 3.906553268432617\n",
      "step = 6079800: loss = 4.419181823730469\n",
      "step = 6080000: loss = 3.676133394241333\n",
      "step = 6080000: Average Return = 3.0\n",
      "step = 6080200: loss = 3.910452127456665\n",
      "step = 6080400: loss = 3.8075060844421387\n",
      "step = 6080600: loss = 3.5471696853637695\n",
      "step = 6080800: loss = 4.5949788093566895\n",
      "step = 6081000: loss = 4.855119228363037\n",
      "step = 6081200: loss = 2.612079381942749\n",
      "step = 6081400: loss = 4.023252964019775\n",
      "step = 6081600: loss = 3.784034252166748\n",
      "step = 6081800: loss = 4.143823623657227\n",
      "step = 6082000: loss = 3.057546377182007\n",
      "step = 6082200: loss = 4.815124988555908\n",
      "step = 6082400: loss = 3.8968141078948975\n",
      "step = 6082600: loss = 2.7435150146484375\n",
      "step = 6082800: loss = 3.5675947666168213\n",
      "step = 6083000: loss = 3.845855712890625\n",
      "step = 6083200: loss = 3.23500657081604\n",
      "step = 6083400: loss = 3.0071706771850586\n",
      "step = 6083600: loss = 4.641567707061768\n",
      "step = 6083800: loss = 4.308085918426514\n",
      "step = 6084000: loss = 3.2618534564971924\n",
      "step = 6084200: loss = 5.062082290649414\n",
      "step = 6084400: loss = 3.3151695728302\n",
      "step = 6084600: loss = 4.934146404266357\n",
      "step = 6084800: loss = 4.185089111328125\n",
      "step = 6085000: loss = 4.717602729797363\n",
      "step = 6085000: Average Return = 2.950000047683716\n",
      "step = 6085200: loss = 2.4872493743896484\n",
      "step = 6085400: loss = 3.268373727798462\n",
      "step = 6085600: loss = 4.225980281829834\n",
      "step = 6085800: loss = 3.3923048973083496\n",
      "step = 6086000: loss = 3.193538188934326\n",
      "step = 6086200: loss = 4.158812046051025\n",
      "step = 6086400: loss = 4.319661617279053\n",
      "step = 6086600: loss = 4.004880905151367\n",
      "step = 6086800: loss = 3.3618977069854736\n",
      "step = 6087000: loss = 2.5194199085235596\n",
      "step = 6087200: loss = 4.915274620056152\n",
      "step = 6087400: loss = 5.125527381896973\n",
      "step = 6087600: loss = 4.188209533691406\n",
      "step = 6087800: loss = 3.5923919677734375\n",
      "step = 6088000: loss = 3.3205111026763916\n",
      "step = 6088200: loss = 2.5876638889312744\n",
      "step = 6088400: loss = 3.915357828140259\n",
      "step = 6088600: loss = 3.179593324661255\n",
      "step = 6088800: loss = 3.169605016708374\n",
      "step = 6089000: loss = 3.196575164794922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 6089200: loss = 2.8918793201446533\n",
      "step = 6089400: loss = 5.064356803894043\n",
      "step = 6089600: loss = 3.816328763961792\n",
      "step = 6089800: loss = 3.81308650970459\n",
      "step = 6090000: loss = 4.135964870452881\n",
      "step = 6090000: Average Return = 3.049999952316284\n",
      "step = 6090200: loss = 3.635676860809326\n",
      "step = 6090400: loss = 3.212181568145752\n",
      "step = 6090600: loss = 3.2876415252685547\n",
      "step = 6090800: loss = 3.7100670337677\n",
      "step = 6091000: loss = 3.372633934020996\n",
      "step = 6091200: loss = 4.250221252441406\n",
      "step = 6091400: loss = 4.246022701263428\n",
      "step = 6091600: loss = 3.7671525478363037\n",
      "step = 6091800: loss = 3.2099151611328125\n",
      "step = 6092000: loss = 5.059747695922852\n",
      "step = 6092200: loss = 4.043881893157959\n",
      "step = 6092400: loss = 4.084870338439941\n",
      "step = 6092600: loss = 3.4468843936920166\n",
      "step = 6092800: loss = 4.839926242828369\n",
      "step = 6093000: loss = 4.076248645782471\n",
      "step = 6093200: loss = 4.22814416885376\n",
      "step = 6093400: loss = 3.512852191925049\n",
      "step = 6093600: loss = 4.157465934753418\n",
      "step = 6093800: loss = 1.9123094081878662\n",
      "step = 6094000: loss = 4.1010942459106445\n",
      "step = 6094200: loss = 2.4679131507873535\n",
      "step = 6094400: loss = 3.5862677097320557\n",
      "step = 6094600: loss = 4.146287441253662\n",
      "step = 6094800: loss = 3.5561277866363525\n",
      "step = 6095000: loss = 4.71492338180542\n",
      "step = 6095000: Average Return = 2.1500000953674316\n",
      "step = 6095200: loss = 3.416642189025879\n",
      "step = 6095400: loss = 3.9983134269714355\n",
      "step = 6095600: loss = 3.1522057056427\n",
      "step = 6095800: loss = 4.606766700744629\n",
      "step = 6096000: loss = 3.4171152114868164\n",
      "step = 6096200: loss = 2.7562201023101807\n",
      "step = 6096400: loss = 3.5126664638519287\n",
      "step = 6096600: loss = 3.268554210662842\n",
      "step = 6096800: loss = 3.2644805908203125\n",
      "step = 6097000: loss = 4.038679599761963\n",
      "step = 6097200: loss = 4.324999809265137\n",
      "step = 6097400: loss = 3.8257358074188232\n",
      "step = 6097600: loss = 4.551764965057373\n",
      "step = 6097800: loss = 3.692469596862793\n",
      "step = 6098000: loss = 3.632720470428467\n",
      "step = 6098200: loss = 2.6108386516571045\n",
      "step = 6098400: loss = 2.9558610916137695\n",
      "step = 6098600: loss = 3.755607843399048\n",
      "step = 6098800: loss = 4.64679479598999\n",
      "step = 6099000: loss = 4.224222183227539\n",
      "step = 6099200: loss = 3.867556571960449\n",
      "step = 6099400: loss = 3.2285313606262207\n",
      "step = 6099600: loss = 4.078795909881592\n",
      "step = 6099800: loss = 2.5974276065826416\n",
      "step = 6100000: loss = 4.974813938140869\n",
      "step = 6100000: Average Return = 5.449999809265137\n",
      "step = 6100200: loss = 4.894852638244629\n",
      "step = 6100400: loss = 4.538753032684326\n",
      "step = 6100600: loss = 2.2620511054992676\n",
      "step = 6100800: loss = 4.256861209869385\n",
      "step = 6101000: loss = 3.358164072036743\n",
      "step = 6101200: loss = 3.1711297035217285\n",
      "step = 6101400: loss = 4.116206645965576\n",
      "step = 6101600: loss = 3.619032621383667\n",
      "step = 6101800: loss = 3.995795249938965\n",
      "step = 6102000: loss = 2.9476025104522705\n",
      "step = 6102200: loss = 3.1149306297302246\n",
      "step = 6102400: loss = 3.392781972885132\n",
      "step = 6102600: loss = 3.6804893016815186\n",
      "step = 6102800: loss = 4.440022945404053\n",
      "step = 6103000: loss = 3.513740062713623\n",
      "step = 6103200: loss = 4.166139602661133\n",
      "step = 6103400: loss = 3.8182079792022705\n",
      "step = 6103600: loss = 4.14845609664917\n",
      "step = 6103800: loss = 5.4370222091674805\n",
      "step = 6104000: loss = 4.133572578430176\n",
      "step = 6104200: loss = 3.198622465133667\n",
      "step = 6104400: loss = 4.552761077880859\n",
      "step = 6104600: loss = 4.322932720184326\n",
      "step = 6104800: loss = 2.783153533935547\n",
      "step = 6105000: loss = 3.1554880142211914\n",
      "step = 6105000: Average Return = 2.299999952316284\n",
      "step = 6105200: loss = 3.808394193649292\n",
      "step = 6105400: loss = 2.428387403488159\n",
      "step = 6105600: loss = 3.817035675048828\n",
      "step = 6105800: loss = 5.773496150970459\n",
      "step = 6106000: loss = 4.58962345123291\n",
      "step = 6106200: loss = 3.864915132522583\n",
      "step = 6106400: loss = 3.7129063606262207\n",
      "step = 6106600: loss = 3.4858086109161377\n",
      "step = 6106800: loss = 4.268531799316406\n",
      "step = 6107000: loss = 4.044404983520508\n",
      "step = 6107200: loss = 3.4173848628997803\n",
      "step = 6107400: loss = 5.2260966300964355\n",
      "step = 6107600: loss = 3.3370418548583984\n",
      "step = 6107800: loss = 3.6389224529266357\n",
      "step = 6108000: loss = 3.471353769302368\n",
      "step = 6108200: loss = 4.16014289855957\n",
      "step = 6108400: loss = 3.193159341812134\n",
      "step = 6108600: loss = 3.001335620880127\n",
      "step = 6108800: loss = 3.8771069049835205\n",
      "step = 6109000: loss = 4.0628862380981445\n",
      "step = 6109200: loss = 3.7124791145324707\n",
      "step = 6109400: loss = 3.208794116973877\n",
      "step = 6109600: loss = 3.6608026027679443\n",
      "step = 6109800: loss = 4.0707268714904785\n",
      "step = 6110000: loss = 3.1390318870544434\n",
      "step = 6110000: Average Return = 3.299999952316284\n",
      "step = 6110200: loss = 4.718349933624268\n",
      "step = 6110400: loss = 3.8153889179229736\n",
      "step = 6110600: loss = 4.454809665679932\n",
      "step = 6110800: loss = 4.748398303985596\n",
      "step = 6111000: loss = 4.429468631744385\n",
      "step = 6111200: loss = 3.0259664058685303\n",
      "step = 6111400: loss = 3.288774251937866\n",
      "step = 6111600: loss = 4.578718662261963\n",
      "step = 6111800: loss = 3.860250234603882\n",
      "step = 6112000: loss = 3.9812920093536377\n",
      "step = 6112200: loss = 4.251903533935547\n",
      "step = 6112400: loss = 4.431385517120361\n",
      "step = 6112600: loss = 3.723167657852173\n",
      "step = 6112800: loss = 3.7238152027130127\n",
      "step = 6113000: loss = 4.332935810089111\n",
      "step = 6113200: loss = 3.773905038833618\n",
      "step = 6113400: loss = 3.5348901748657227\n",
      "step = 6113600: loss = 3.9974327087402344\n",
      "step = 6113800: loss = 3.2875072956085205\n",
      "step = 6114000: loss = 3.852935791015625\n",
      "step = 6114200: loss = 2.9717509746551514\n",
      "step = 6114400: loss = 4.5067572593688965\n",
      "step = 6114600: loss = 4.5230712890625\n",
      "step = 6114800: loss = 4.566959857940674\n",
      "step = 6115000: loss = 3.6442763805389404\n",
      "step = 6115000: Average Return = 4.0\n",
      "step = 6115200: loss = 4.102591514587402\n",
      "step = 6115400: loss = 4.428930759429932\n",
      "step = 6115600: loss = 3.809215545654297\n",
      "step = 6115800: loss = 2.777491331100464\n",
      "step = 6116000: loss = 4.404857158660889\n",
      "step = 6116200: loss = 4.36681604385376\n",
      "step = 6116400: loss = 4.584146022796631\n",
      "step = 6116600: loss = 3.53398060798645\n",
      "step = 6116800: loss = 3.211332082748413\n",
      "step = 6117000: loss = 4.594291687011719\n",
      "step = 6117200: loss = 3.08779239654541\n",
      "step = 6117400: loss = 3.4846129417419434\n",
      "step = 6117600: loss = 2.9165050983428955\n",
      "step = 6117800: loss = 3.4973299503326416\n",
      "step = 6118000: loss = 4.450845241546631\n",
      "step = 6118200: loss = 3.875736713409424\n",
      "step = 6118400: loss = 3.764561176300049\n",
      "step = 6118600: loss = 3.3642385005950928\n",
      "step = 6118800: loss = 3.449671745300293\n",
      "step = 6119000: loss = 3.3462319374084473\n",
      "step = 6119200: loss = 5.422835350036621\n",
      "step = 6119400: loss = 4.3302507400512695\n",
      "step = 6119600: loss = 2.250272512435913\n",
      "step = 6119800: loss = 3.7716643810272217\n",
      "step = 6120000: loss = 3.7446751594543457\n",
      "step = 6120000: Average Return = 2.549999952316284\n",
      "step = 6120200: loss = 3.357327699661255\n",
      "step = 6120400: loss = 3.555985927581787\n",
      "step = 6120600: loss = 3.972903251647949\n",
      "step = 6120800: loss = 5.192040920257568\n",
      "step = 6121000: loss = 3.5099704265594482\n",
      "step = 6121200: loss = 3.8866283893585205\n",
      "step = 6121400: loss = 3.5703306198120117\n",
      "step = 6121600: loss = 4.288490295410156\n",
      "step = 6121800: loss = 3.9692928791046143\n",
      "step = 6122000: loss = 3.6703035831451416\n",
      "step = 6122200: loss = 4.634888648986816\n",
      "step = 6122400: loss = 4.171255588531494\n",
      "step = 6122600: loss = 3.97282075881958\n",
      "step = 6122800: loss = 4.018343925476074\n",
      "step = 6123000: loss = 2.6776411533355713\n",
      "step = 6123200: loss = 4.244514465332031\n",
      "step = 6123400: loss = 4.575684070587158\n",
      "step = 6123600: loss = 4.141920566558838\n",
      "step = 6123800: loss = 3.5321145057678223\n",
      "step = 6124000: loss = 2.7570903301239014\n",
      "step = 6124200: loss = 3.4983325004577637\n",
      "step = 6124400: loss = 2.9195339679718018\n",
      "step = 6124600: loss = 4.0591721534729\n",
      "step = 6124800: loss = 3.98266339302063\n",
      "step = 6125000: loss = 4.430709362030029\n",
      "step = 6125000: Average Return = 4.349999904632568\n",
      "step = 6125200: loss = 2.2395341396331787\n",
      "step = 6125400: loss = 4.364210605621338\n",
      "step = 6125600: loss = 3.727189302444458\n",
      "step = 6125800: loss = 3.582014799118042\n",
      "step = 6126000: loss = 3.6103601455688477\n",
      "step = 6126200: loss = 3.5615971088409424\n",
      "step = 6126400: loss = 3.6284306049346924\n",
      "step = 6126600: loss = 3.00083065032959\n",
      "step = 6126800: loss = 2.574781656265259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 6127000: loss = 4.384853839874268\n",
      "step = 6127200: loss = 2.8115105628967285\n",
      "step = 6127400: loss = 2.4887306690216064\n",
      "step = 6127600: loss = 4.565280437469482\n",
      "step = 6127800: loss = 4.560878276824951\n",
      "step = 6128000: loss = 3.450871229171753\n",
      "step = 6128200: loss = 3.5771148204803467\n",
      "step = 6128400: loss = 3.273026704788208\n",
      "step = 6128600: loss = 2.915370464324951\n",
      "step = 6128800: loss = 3.995617389678955\n",
      "step = 6129000: loss = 4.767911434173584\n",
      "step = 6129200: loss = 3.848619222640991\n",
      "step = 6129400: loss = 4.453217506408691\n",
      "step = 6129600: loss = 4.231109142303467\n",
      "step = 6129800: loss = 4.049312114715576\n",
      "step = 6130000: loss = 3.017827033996582\n",
      "step = 6130000: Average Return = 3.450000047683716\n",
      "step = 6130200: loss = 5.240169525146484\n",
      "step = 6130400: loss = 3.0847549438476562\n",
      "step = 6130600: loss = 4.314776420593262\n",
      "step = 6130800: loss = 3.926656484603882\n",
      "step = 6131000: loss = 3.815477132797241\n",
      "step = 6131200: loss = 2.654468059539795\n",
      "step = 6131400: loss = 3.7071921825408936\n",
      "step = 6131600: loss = 4.379350662231445\n",
      "step = 6131800: loss = 2.8669159412384033\n",
      "step = 6132000: loss = 4.4475250244140625\n",
      "step = 6132200: loss = 3.8105297088623047\n",
      "step = 6132400: loss = 4.184555530548096\n",
      "step = 6132600: loss = 3.655501127243042\n",
      "step = 6132800: loss = 3.624080181121826\n",
      "step = 6133000: loss = 3.17313289642334\n",
      "step = 6133200: loss = 4.469115734100342\n",
      "step = 6133400: loss = 3.133615732192993\n",
      "step = 6133600: loss = 2.9639830589294434\n",
      "step = 6133800: loss = 3.0058488845825195\n",
      "step = 6134000: loss = 2.567359447479248\n",
      "step = 6134200: loss = 3.981327533721924\n",
      "step = 6134400: loss = 3.1578667163848877\n",
      "step = 6134600: loss = 3.139549732208252\n",
      "step = 6134800: loss = 3.865415573120117\n",
      "step = 6135000: loss = 4.112278461456299\n",
      "step = 6135000: Average Return = 3.25\n",
      "step = 6135200: loss = 5.5077362060546875\n",
      "step = 6135400: loss = 3.7403552532196045\n",
      "step = 6135600: loss = 3.68597149848938\n",
      "step = 6135800: loss = 4.210512161254883\n",
      "step = 6136000: loss = 4.799107551574707\n",
      "step = 6136200: loss = 4.025651931762695\n",
      "step = 6136400: loss = 3.5886385440826416\n",
      "step = 6136600: loss = 3.167083263397217\n",
      "step = 6136800: loss = 2.965068817138672\n",
      "step = 6137000: loss = 4.675723075866699\n",
      "step = 6137200: loss = 4.476199150085449\n",
      "step = 6137400: loss = 3.3600151538848877\n",
      "step = 6137600: loss = 3.841813802719116\n",
      "step = 6137800: loss = 4.497163772583008\n",
      "step = 6138000: loss = 3.979675769805908\n",
      "step = 6138200: loss = 4.438868999481201\n",
      "step = 6138400: loss = 4.914638996124268\n",
      "step = 6138600: loss = 3.35231614112854\n",
      "step = 6138800: loss = 2.731311082839966\n",
      "step = 6139000: loss = 2.761826753616333\n",
      "step = 6139200: loss = 4.044333457946777\n",
      "step = 6139400: loss = 3.998189687728882\n",
      "step = 6139600: loss = 5.088457107543945\n",
      "step = 6139800: loss = 2.769131660461426\n",
      "step = 6140000: loss = 4.5151824951171875\n",
      "step = 6140000: Average Return = 3.3499999046325684\n",
      "step = 6140200: loss = 3.1343963146209717\n",
      "step = 6140400: loss = 3.3591384887695312\n",
      "step = 6140600: loss = 3.7924437522888184\n",
      "step = 6140800: loss = 3.0413622856140137\n",
      "step = 6141000: loss = 2.986847400665283\n",
      "step = 6141200: loss = 3.446401357650757\n",
      "step = 6141400: loss = 3.767472982406616\n",
      "step = 6141600: loss = 3.0274951457977295\n",
      "step = 6141800: loss = 4.404305458068848\n",
      "step = 6142000: loss = 4.709956169128418\n",
      "step = 6142200: loss = 4.1572418212890625\n",
      "step = 6142400: loss = 5.164315223693848\n",
      "step = 6142600: loss = 4.569456577301025\n",
      "step = 6142800: loss = 3.23646879196167\n",
      "step = 6143000: loss = 4.369448184967041\n",
      "step = 6143200: loss = 4.298407554626465\n",
      "step = 6143400: loss = 4.955827236175537\n",
      "step = 6143600: loss = 3.457697868347168\n",
      "step = 6143800: loss = 4.791231155395508\n",
      "step = 6144000: loss = 3.170483350753784\n",
      "step = 6144200: loss = 3.481459617614746\n",
      "step = 6144400: loss = 3.846547842025757\n",
      "step = 6144600: loss = 3.4953856468200684\n",
      "step = 6144800: loss = 3.519242525100708\n",
      "step = 6145000: loss = 4.033830165863037\n",
      "step = 6145000: Average Return = 2.4000000953674316\n",
      "step = 6145200: loss = 4.186267375946045\n",
      "step = 6145400: loss = 3.9990153312683105\n",
      "step = 6145600: loss = 4.222906589508057\n",
      "step = 6145800: loss = 4.464341163635254\n",
      "step = 6146000: loss = 4.119782447814941\n",
      "step = 6146200: loss = 4.531620502471924\n",
      "step = 6146400: loss = 4.66402530670166\n",
      "step = 6146600: loss = 5.473644733428955\n",
      "step = 6146800: loss = 4.701197624206543\n",
      "step = 6147000: loss = 4.6164774894714355\n",
      "step = 6147200: loss = 4.196224212646484\n",
      "step = 6147400: loss = 5.05426025390625\n",
      "step = 6147600: loss = 4.293691158294678\n",
      "step = 6147800: loss = 3.9337358474731445\n",
      "step = 6148000: loss = 3.4200432300567627\n",
      "step = 6148200: loss = 4.069552421569824\n",
      "step = 6148400: loss = 3.529938220977783\n",
      "step = 6148600: loss = 3.7260327339172363\n",
      "step = 6148800: loss = 3.8457064628601074\n",
      "step = 6149000: loss = 3.570280075073242\n",
      "step = 6149200: loss = 3.918855905532837\n",
      "step = 6149400: loss = 3.8349850177764893\n",
      "step = 6149600: loss = 3.4019830226898193\n",
      "step = 6149800: loss = 3.983126163482666\n",
      "step = 6150000: loss = 3.3550736904144287\n",
      "step = 6150000: Average Return = 2.049999952316284\n",
      "step = 6150200: loss = 4.380668640136719\n",
      "step = 6150400: loss = 4.737728595733643\n",
      "step = 6150600: loss = 4.689372539520264\n",
      "step = 6150800: loss = 2.875077724456787\n",
      "step = 6151000: loss = 2.344555377960205\n",
      "step = 6151200: loss = 3.538217067718506\n",
      "step = 6151400: loss = 4.0770697593688965\n",
      "step = 6151600: loss = 3.8154749870300293\n",
      "step = 6151800: loss = 4.996212482452393\n",
      "step = 6152000: loss = 3.883889675140381\n",
      "step = 6152200: loss = 4.715956687927246\n",
      "step = 6152400: loss = 2.564983367919922\n",
      "step = 6152600: loss = 2.858109712600708\n",
      "step = 6152800: loss = 2.895111560821533\n",
      "step = 6153000: loss = 4.605113983154297\n",
      "step = 6153200: loss = 2.895038366317749\n",
      "step = 6153400: loss = 3.4555511474609375\n",
      "step = 6153600: loss = 3.4932568073272705\n",
      "step = 6153800: loss = 4.363417148590088\n",
      "step = 6154000: loss = 4.198214054107666\n",
      "step = 6154200: loss = 4.373130798339844\n",
      "step = 6154400: loss = 3.7108166217803955\n",
      "step = 6154600: loss = 3.665414333343506\n",
      "step = 6154800: loss = 4.201162815093994\n",
      "step = 6155000: loss = 3.704878568649292\n",
      "step = 6155000: Average Return = 5.199999809265137\n",
      "step = 6155200: loss = 4.301198482513428\n",
      "step = 6155400: loss = 4.072665214538574\n",
      "step = 6155600: loss = 3.9540300369262695\n",
      "step = 6155800: loss = 4.517810821533203\n",
      "step = 6156000: loss = 4.015108585357666\n",
      "step = 6156200: loss = 3.9826531410217285\n",
      "step = 6156400: loss = 3.032038450241089\n",
      "step = 6156600: loss = 4.350587844848633\n",
      "step = 6156800: loss = 3.5184648036956787\n",
      "step = 6157000: loss = 2.682185649871826\n",
      "step = 6157200: loss = 3.104383707046509\n",
      "step = 6157400: loss = 4.431126594543457\n",
      "step = 6157600: loss = 3.3798482418060303\n",
      "step = 6157800: loss = 2.2321245670318604\n",
      "step = 6158000: loss = 3.382042169570923\n",
      "step = 6158200: loss = 3.049274206161499\n",
      "step = 6158400: loss = 2.1298651695251465\n",
      "step = 6158600: loss = 2.913902521133423\n",
      "step = 6158800: loss = 3.4570438861846924\n",
      "step = 6159000: loss = 3.002171277999878\n",
      "step = 6159200: loss = 4.469058990478516\n",
      "step = 6159400: loss = 3.201240062713623\n",
      "step = 6159600: loss = 3.9524266719818115\n",
      "step = 6159800: loss = 2.7353999614715576\n",
      "step = 6160000: loss = 3.6960582733154297\n",
      "step = 6160000: Average Return = 4.650000095367432\n",
      "step = 6160200: loss = 3.812432050704956\n",
      "step = 6160400: loss = 3.8180530071258545\n",
      "step = 6160600: loss = 4.348139762878418\n",
      "step = 6160800: loss = 3.695953369140625\n",
      "step = 6161000: loss = 2.460498809814453\n",
      "step = 6161200: loss = 3.537457227706909\n",
      "step = 6161400: loss = 2.7734532356262207\n",
      "step = 6161600: loss = 3.8919384479522705\n",
      "step = 6161800: loss = 3.0262255668640137\n",
      "step = 6162000: loss = 3.0112414360046387\n",
      "step = 6162200: loss = 2.609623670578003\n",
      "step = 6162400: loss = 3.285156726837158\n",
      "step = 6162600: loss = 3.570490598678589\n",
      "step = 6162800: loss = 3.2431325912475586\n",
      "step = 6163000: loss = 3.4932212829589844\n",
      "step = 6163200: loss = 4.002425670623779\n",
      "step = 6163400: loss = 4.069822788238525\n",
      "step = 6163600: loss = 3.8402934074401855\n",
      "step = 6163800: loss = 4.608223915100098\n",
      "step = 6164000: loss = 4.372201442718506\n",
      "step = 6164200: loss = 3.9432249069213867\n",
      "step = 6164400: loss = 3.7483184337615967\n",
      "step = 6164600: loss = 3.7978715896606445\n",
      "step = 6164800: loss = 3.3113620281219482\n",
      "step = 6165000: loss = 3.2870278358459473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 6165000: Average Return = 2.5999999046325684\n",
      "step = 6165200: loss = 3.048265218734741\n",
      "step = 6165400: loss = 3.843017101287842\n",
      "step = 6165600: loss = 4.124693393707275\n",
      "step = 6165800: loss = 3.2514865398406982\n",
      "step = 6166000: loss = 3.257331371307373\n",
      "step = 6166200: loss = 3.549659252166748\n",
      "step = 6166400: loss = 3.793633222579956\n",
      "step = 6166600: loss = 4.1421122550964355\n",
      "step = 6166800: loss = 5.1637163162231445\n",
      "step = 6167000: loss = 4.166290283203125\n",
      "step = 6167200: loss = 3.5749449729919434\n",
      "step = 6167400: loss = 2.9537813663482666\n",
      "step = 6167600: loss = 3.1096153259277344\n",
      "step = 6167800: loss = 4.204716205596924\n",
      "step = 6168000: loss = 3.787400484085083\n",
      "step = 6168200: loss = 3.457592010498047\n",
      "step = 6168400: loss = 3.210583448410034\n",
      "step = 6168600: loss = 4.3390045166015625\n",
      "step = 6168800: loss = 3.495750665664673\n",
      "step = 6169000: loss = 3.1071038246154785\n",
      "step = 6169200: loss = 4.999271869659424\n",
      "step = 6169400: loss = 3.864469528198242\n",
      "step = 6169600: loss = 3.9799797534942627\n",
      "step = 6169800: loss = 3.161417245864868\n",
      "step = 6170000: loss = 2.7627880573272705\n",
      "step = 6170000: Average Return = 3.1500000953674316\n",
      "step = 6170200: loss = 2.682640314102173\n",
      "step = 6170400: loss = 3.8317906856536865\n",
      "step = 6170600: loss = 3.644721269607544\n",
      "step = 6170800: loss = 3.035736560821533\n",
      "step = 6171000: loss = 3.4703967571258545\n",
      "step = 6171200: loss = 5.274672508239746\n",
      "step = 6171400: loss = 3.752159833908081\n",
      "step = 6171600: loss = 3.433934211730957\n",
      "step = 6171800: loss = 4.069602012634277\n",
      "step = 6172000: loss = 3.752061605453491\n",
      "step = 6172200: loss = 4.381072044372559\n",
      "step = 6172400: loss = 4.233922481536865\n",
      "step = 6172600: loss = 4.166940689086914\n",
      "step = 6172800: loss = 3.5470166206359863\n",
      "step = 6173000: loss = 3.7402684688568115\n",
      "step = 6173200: loss = 3.181234359741211\n",
      "step = 6173400: loss = 3.787388324737549\n",
      "step = 6173600: loss = 3.9692254066467285\n",
      "step = 6173800: loss = 3.5309770107269287\n",
      "step = 6174000: loss = 3.919752359390259\n",
      "step = 6174200: loss = 4.208223819732666\n",
      "step = 6174400: loss = 3.3334872722625732\n",
      "step = 6174600: loss = 3.68273663520813\n",
      "step = 6174800: loss = 3.3806707859039307\n",
      "step = 6175000: loss = 3.6238508224487305\n",
      "step = 6175000: Average Return = 2.5\n",
      "step = 6175200: loss = 2.3888580799102783\n",
      "step = 6175400: loss = 2.609818696975708\n",
      "step = 6175600: loss = 2.8027901649475098\n",
      "step = 6175800: loss = 5.004716396331787\n",
      "step = 6176000: loss = 3.17141056060791\n",
      "step = 6176200: loss = 3.1483635902404785\n",
      "step = 6176400: loss = 4.459917068481445\n",
      "step = 6176600: loss = 2.1536595821380615\n",
      "step = 6176800: loss = 3.321904420852661\n",
      "step = 6177000: loss = 4.281625747680664\n",
      "step = 6177200: loss = 4.067059516906738\n",
      "step = 6177400: loss = 3.3600640296936035\n",
      "step = 6177600: loss = 4.494628429412842\n",
      "step = 6177800: loss = 3.2661333084106445\n",
      "step = 6178000: loss = 2.4276490211486816\n",
      "step = 6178200: loss = 3.5261800289154053\n",
      "step = 6178400: loss = 3.241511106491089\n",
      "step = 6178600: loss = 3.047595739364624\n",
      "step = 6178800: loss = 5.410765171051025\n",
      "step = 6179000: loss = 4.264346599578857\n",
      "step = 6179200: loss = 5.1607890129089355\n",
      "step = 6179400: loss = 3.2094404697418213\n",
      "step = 6179600: loss = 5.161492824554443\n",
      "step = 6179800: loss = 4.629445552825928\n",
      "step = 6180000: loss = 2.552629232406616\n",
      "step = 6180000: Average Return = 4.849999904632568\n",
      "step = 6180200: loss = 3.4473464488983154\n",
      "step = 6180400: loss = 3.6920833587646484\n",
      "step = 6180600: loss = 3.24294114112854\n",
      "step = 6180800: loss = 3.6992454528808594\n",
      "step = 6181000: loss = 3.4432549476623535\n",
      "step = 6181200: loss = 4.719927787780762\n",
      "step = 6181400: loss = 3.929173469543457\n",
      "step = 6181600: loss = 4.4779953956604\n",
      "step = 6181800: loss = 2.523282527923584\n",
      "step = 6182000: loss = 4.952746868133545\n",
      "step = 6182200: loss = 5.373879432678223\n",
      "step = 6182400: loss = 4.902993202209473\n",
      "step = 6182600: loss = 5.197659969329834\n",
      "step = 6182800: loss = 4.214838981628418\n",
      "step = 6183000: loss = 4.421842098236084\n",
      "step = 6183200: loss = 4.119128227233887\n",
      "step = 6183400: loss = 3.858165740966797\n",
      "step = 6183600: loss = 4.902342796325684\n",
      "step = 6183800: loss = 4.018161296844482\n",
      "step = 6184000: loss = 3.5164525508880615\n",
      "step = 6184200: loss = 4.393106460571289\n",
      "step = 6184400: loss = 4.536426067352295\n",
      "step = 6184600: loss = 4.583176612854004\n",
      "step = 6184800: loss = 3.2391512393951416\n",
      "step = 6185000: loss = 4.784986972808838\n",
      "step = 6185000: Average Return = 3.8499999046325684\n",
      "step = 6185200: loss = 3.442537546157837\n",
      "step = 6185400: loss = 3.6229677200317383\n",
      "step = 6185600: loss = 4.78881311416626\n",
      "step = 6185800: loss = 5.217170715332031\n",
      "step = 6186000: loss = 3.558112621307373\n",
      "step = 6186200: loss = 2.4687891006469727\n",
      "step = 6186400: loss = 4.141449928283691\n",
      "step = 6186600: loss = 2.4026451110839844\n",
      "step = 6186800: loss = 4.601528644561768\n",
      "step = 6187000: loss = 4.070353984832764\n",
      "step = 6187200: loss = 4.028539180755615\n",
      "step = 6187400: loss = 3.2044477462768555\n",
      "step = 6187600: loss = 3.826737642288208\n",
      "step = 6187800: loss = 3.391012191772461\n",
      "step = 6188000: loss = 4.517176628112793\n",
      "step = 6188200: loss = 3.1446919441223145\n",
      "step = 6188400: loss = 5.730560779571533\n",
      "step = 6188600: loss = 4.005172252655029\n",
      "step = 6188800: loss = 3.6020267009735107\n",
      "step = 6189000: loss = 3.135319232940674\n",
      "step = 6189200: loss = 4.787547588348389\n",
      "step = 6189400: loss = 3.7270097732543945\n",
      "step = 6189600: loss = 3.10748291015625\n",
      "step = 6189800: loss = 3.9023211002349854\n",
      "step = 6190000: loss = 3.6289117336273193\n",
      "step = 6190000: Average Return = 2.549999952316284\n",
      "step = 6190200: loss = 3.4094200134277344\n",
      "step = 6190400: loss = 4.16376256942749\n",
      "step = 6190600: loss = 3.2511467933654785\n",
      "step = 6190800: loss = 4.15360689163208\n",
      "step = 6191000: loss = 3.9922900199890137\n",
      "step = 6191200: loss = 4.461451530456543\n",
      "step = 6191400: loss = 2.927110433578491\n",
      "step = 6191600: loss = 4.4182515144348145\n",
      "step = 6191800: loss = 3.7417376041412354\n",
      "step = 6192000: loss = 2.408057689666748\n",
      "step = 6192200: loss = 4.419663906097412\n",
      "step = 6192400: loss = 3.6163089275360107\n",
      "step = 6192600: loss = 3.7158820629119873\n",
      "step = 6192800: loss = 5.076869964599609\n",
      "step = 6193000: loss = 2.646357297897339\n",
      "step = 6193200: loss = 3.946932315826416\n",
      "step = 6193400: loss = 3.8188304901123047\n",
      "step = 6193600: loss = 4.781763076782227\n",
      "step = 6193800: loss = 4.33632755279541\n",
      "step = 6194000: loss = 5.001228332519531\n",
      "step = 6194200: loss = 3.6534106731414795\n",
      "step = 6194400: loss = 3.9486448764801025\n",
      "step = 6194600: loss = 3.7984840869903564\n",
      "step = 6194800: loss = 4.065009593963623\n",
      "step = 6195000: loss = 3.324282169342041\n",
      "step = 6195000: Average Return = 3.25\n",
      "step = 6195200: loss = 2.7922754287719727\n",
      "step = 6195400: loss = 3.3286995887756348\n",
      "step = 6195600: loss = 4.367796421051025\n",
      "step = 6195800: loss = 4.403389930725098\n",
      "step = 6196000: loss = 4.318142414093018\n",
      "step = 6196200: loss = 4.883662700653076\n",
      "step = 6196400: loss = 3.1668975353240967\n",
      "step = 6196600: loss = 2.391045093536377\n",
      "step = 6196800: loss = 2.889500141143799\n",
      "step = 6197000: loss = 4.02334451675415\n",
      "step = 6197200: loss = 4.652416706085205\n",
      "step = 6197400: loss = 2.9946398735046387\n",
      "step = 6197600: loss = 3.5199427604675293\n",
      "step = 6197800: loss = 4.295151233673096\n",
      "step = 6198000: loss = 3.1034419536590576\n",
      "step = 6198200: loss = 4.106015682220459\n",
      "step = 6198400: loss = 3.357217311859131\n",
      "step = 6198600: loss = 4.807583332061768\n",
      "step = 6198800: loss = 3.009185791015625\n",
      "step = 6199000: loss = 3.731498956680298\n",
      "step = 6199200: loss = 4.263368606567383\n",
      "step = 6199400: loss = 5.060232639312744\n",
      "step = 6199600: loss = 5.173174858093262\n",
      "step = 6199800: loss = 3.894235134124756\n",
      "step = 6200000: loss = 3.781564950942993\n",
      "step = 6200000: Average Return = 5.050000190734863\n",
      "step = 6200200: loss = 2.818546772003174\n",
      "step = 6200400: loss = 4.660823822021484\n",
      "step = 6200600: loss = 4.3043389320373535\n",
      "step = 6200800: loss = 3.9870476722717285\n",
      "step = 6201000: loss = 3.284039258956909\n",
      "step = 6201200: loss = 3.506725311279297\n",
      "step = 6201400: loss = 3.1422526836395264\n",
      "step = 6201600: loss = 3.3515238761901855\n",
      "step = 6201800: loss = 3.383312225341797\n",
      "step = 6202000: loss = 3.548048973083496\n",
      "step = 6202200: loss = 5.160642147064209\n",
      "step = 6202400: loss = 3.6202831268310547\n",
      "step = 6202600: loss = 3.904827117919922\n",
      "step = 6202800: loss = 3.456638813018799\n",
      "step = 6203000: loss = 3.2177484035491943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 6203200: loss = 2.8066136837005615\n",
      "step = 6203400: loss = 2.500626564025879\n",
      "step = 6203600: loss = 3.3008482456207275\n",
      "step = 6203800: loss = 3.022624969482422\n",
      "step = 6204000: loss = 3.3540754318237305\n",
      "step = 6204200: loss = 2.151890516281128\n",
      "step = 6204400: loss = 4.246521949768066\n",
      "step = 6204600: loss = 3.946556329727173\n",
      "step = 6204800: loss = 3.419358253479004\n",
      "step = 6205000: loss = 3.445030450820923\n",
      "step = 6205000: Average Return = 3.049999952316284\n",
      "step = 6205200: loss = 4.091609954833984\n",
      "step = 6205400: loss = 3.880375385284424\n",
      "step = 6205600: loss = 3.9764440059661865\n",
      "step = 6205800: loss = 2.068904399871826\n",
      "step = 6206000: loss = 4.093026638031006\n",
      "step = 6206200: loss = 3.7861697673797607\n",
      "step = 6206400: loss = 5.086103916168213\n",
      "step = 6206600: loss = 3.841996908187866\n",
      "step = 6206800: loss = 2.8344552516937256\n",
      "step = 6207000: loss = 4.4210100173950195\n",
      "step = 6207200: loss = 4.5352396965026855\n",
      "step = 6207400: loss = 2.514918804168701\n",
      "step = 6207600: loss = 3.6073756217956543\n",
      "step = 6207800: loss = 3.9059746265411377\n",
      "step = 6208000: loss = 3.2051143646240234\n",
      "step = 6208200: loss = 2.775555372238159\n",
      "step = 6208400: loss = 3.3867204189300537\n",
      "step = 6208600: loss = 3.003849983215332\n",
      "step = 6208800: loss = 3.7880070209503174\n",
      "step = 6209000: loss = 3.810145854949951\n",
      "step = 6209200: loss = 4.398977279663086\n",
      "step = 6209400: loss = 4.756633758544922\n",
      "step = 6209600: loss = 5.067023277282715\n",
      "step = 6209800: loss = 3.401667356491089\n",
      "step = 6210000: loss = 4.499395847320557\n",
      "step = 6210000: Average Return = 3.25\n",
      "step = 6210200: loss = 3.33024525642395\n",
      "step = 6210400: loss = 4.296748638153076\n",
      "step = 6210600: loss = 4.338155269622803\n",
      "step = 6210800: loss = 4.153366565704346\n",
      "step = 6211000: loss = 4.141510963439941\n",
      "step = 6211200: loss = 2.9953973293304443\n",
      "step = 6211400: loss = 4.15355110168457\n",
      "step = 6211600: loss = 4.370519161224365\n",
      "step = 6211800: loss = 3.480973958969116\n",
      "step = 6212000: loss = 3.9213035106658936\n",
      "step = 6212200: loss = 3.3326821327209473\n",
      "step = 6212400: loss = 3.6811399459838867\n",
      "step = 6212600: loss = 3.4291772842407227\n",
      "step = 6212800: loss = 3.3179521560668945\n",
      "step = 6213000: loss = 4.27066707611084\n",
      "step = 6213200: loss = 4.222382068634033\n",
      "step = 6213400: loss = 3.4948906898498535\n",
      "step = 6213600: loss = 4.362841606140137\n",
      "step = 6213800: loss = 4.4013848304748535\n",
      "step = 6214000: loss = 5.136865139007568\n",
      "step = 6214200: loss = 3.546055793762207\n",
      "step = 6214400: loss = 4.332198619842529\n",
      "step = 6214600: loss = 3.3333587646484375\n",
      "step = 6214800: loss = 2.9948768615722656\n",
      "step = 6215000: loss = 4.508988380432129\n",
      "step = 6215000: Average Return = 3.299999952316284\n",
      "step = 6215200: loss = 4.908951759338379\n",
      "step = 6215400: loss = 3.2525525093078613\n",
      "step = 6215600: loss = 2.949723958969116\n",
      "step = 6215800: loss = 3.784396171569824\n",
      "step = 6216000: loss = 3.856679916381836\n",
      "step = 6216200: loss = 3.600128412246704\n",
      "step = 6216400: loss = 5.0605340003967285\n",
      "step = 6216600: loss = 3.5959670543670654\n",
      "step = 6216800: loss = 4.98197078704834\n",
      "step = 6217000: loss = 4.381670951843262\n",
      "step = 6217200: loss = 3.5517308712005615\n",
      "step = 6217400: loss = 2.313504219055176\n",
      "step = 6217600: loss = 2.8204152584075928\n",
      "step = 6217800: loss = 3.9873321056365967\n",
      "step = 6218000: loss = 3.8509135246276855\n",
      "step = 6218200: loss = 3.3954102993011475\n",
      "step = 6218400: loss = 3.1571202278137207\n",
      "step = 6218600: loss = 3.664822816848755\n",
      "step = 6218800: loss = 2.968377113342285\n",
      "step = 6219000: loss = 3.8154914379119873\n",
      "step = 6219200: loss = 4.201507568359375\n",
      "step = 6219400: loss = 3.376182794570923\n",
      "step = 6219600: loss = 3.220128059387207\n",
      "step = 6219800: loss = 3.5059306621551514\n",
      "step = 6220000: loss = 3.033586025238037\n",
      "step = 6220000: Average Return = 3.200000047683716\n",
      "step = 6220200: loss = 4.1641154289245605\n",
      "step = 6220400: loss = 5.465682029724121\n",
      "step = 6220600: loss = 3.5030102729797363\n",
      "step = 6220800: loss = 3.560197114944458\n",
      "step = 6221000: loss = 4.076101303100586\n",
      "step = 6221200: loss = 4.756260395050049\n",
      "step = 6221400: loss = 5.022886753082275\n",
      "step = 6221600: loss = 3.3585433959960938\n",
      "step = 6221800: loss = 3.2284109592437744\n",
      "step = 6222000: loss = 2.787659168243408\n",
      "step = 6222200: loss = 4.100955486297607\n",
      "step = 6222400: loss = 4.225765705108643\n",
      "step = 6222600: loss = 3.8666276931762695\n",
      "step = 6222800: loss = 4.119052886962891\n",
      "step = 6223000: loss = 2.513904571533203\n",
      "step = 6223200: loss = 4.479702472686768\n",
      "step = 6223400: loss = 4.188906192779541\n",
      "step = 6223600: loss = 4.354485511779785\n",
      "step = 6223800: loss = 3.8727409839630127\n",
      "step = 6224000: loss = 4.644430160522461\n",
      "step = 6224200: loss = 3.718587636947632\n",
      "step = 6224400: loss = 3.1536319255828857\n",
      "step = 6224600: loss = 2.8966784477233887\n",
      "step = 6224800: loss = 4.034093856811523\n",
      "step = 6225000: loss = 4.252902030944824\n",
      "step = 6225000: Average Return = 3.8499999046325684\n",
      "step = 6225200: loss = 3.1592376232147217\n",
      "step = 6225400: loss = 3.3523380756378174\n",
      "step = 6225600: loss = 3.2836248874664307\n",
      "step = 6225800: loss = 4.3523406982421875\n",
      "step = 6226000: loss = 3.4015820026397705\n",
      "step = 6226200: loss = 4.761401653289795\n",
      "step = 6226400: loss = 2.8312933444976807\n",
      "step = 6226600: loss = 3.1525866985321045\n",
      "step = 6226800: loss = 2.688230276107788\n",
      "step = 6227000: loss = 4.25378942489624\n",
      "step = 6227200: loss = 3.317817211151123\n",
      "step = 6227400: loss = 3.758638858795166\n",
      "step = 6227600: loss = 3.7016351222991943\n",
      "step = 6227800: loss = 4.182694911956787\n",
      "step = 6228000: loss = 2.7804107666015625\n",
      "step = 6228200: loss = 2.3824782371520996\n",
      "step = 6228400: loss = 4.518279552459717\n",
      "step = 6228600: loss = 3.71977162361145\n",
      "step = 6228800: loss = 3.2450244426727295\n",
      "step = 6229000: loss = 3.9136319160461426\n",
      "step = 6229200: loss = 3.7225663661956787\n",
      "step = 6229400: loss = 3.232436180114746\n",
      "step = 6229600: loss = 4.691389083862305\n",
      "step = 6229800: loss = 4.8738203048706055\n",
      "step = 6230000: loss = 3.980898857116699\n",
      "step = 6230000: Average Return = 2.9000000953674316\n",
      "step = 6230200: loss = 3.5766355991363525\n",
      "step = 6230400: loss = 4.169689178466797\n",
      "step = 6230600: loss = 3.8697144985198975\n",
      "step = 6230800: loss = 4.845620155334473\n",
      "step = 6231000: loss = 3.4039416313171387\n",
      "step = 6231200: loss = 4.63815450668335\n",
      "step = 6231400: loss = 3.7483901977539062\n",
      "step = 6231600: loss = 4.238517761230469\n",
      "step = 6231800: loss = 4.782681941986084\n",
      "step = 6232000: loss = 2.5147628784179688\n",
      "step = 6232200: loss = 4.615610122680664\n",
      "step = 6232400: loss = 3.20805287361145\n",
      "step = 6232600: loss = 4.063862323760986\n",
      "step = 6232800: loss = 4.398062229156494\n",
      "step = 6233000: loss = 5.128889083862305\n",
      "step = 6233200: loss = 3.634324312210083\n",
      "step = 6233400: loss = 5.508866310119629\n",
      "step = 6233600: loss = 4.08223819732666\n",
      "step = 6233800: loss = 3.8271751403808594\n",
      "step = 6234000: loss = 2.935286521911621\n",
      "step = 6234200: loss = 4.074221134185791\n",
      "step = 6234400: loss = 3.3099749088287354\n",
      "step = 6234600: loss = 4.333209037780762\n",
      "step = 6234800: loss = 3.8947813510894775\n",
      "step = 6235000: loss = 4.14725923538208\n",
      "step = 6235000: Average Return = 3.0999999046325684\n",
      "step = 6235200: loss = 3.479891538619995\n",
      "step = 6235400: loss = 3.3620965480804443\n",
      "step = 6235600: loss = 4.514925003051758\n",
      "step = 6235800: loss = 3.1363041400909424\n",
      "step = 6236000: loss = 3.1337010860443115\n",
      "step = 6236200: loss = 3.5785717964172363\n",
      "step = 6236400: loss = 3.4937565326690674\n",
      "step = 6236600: loss = 4.734678268432617\n",
      "step = 6236800: loss = 2.654207706451416\n",
      "step = 6237000: loss = 3.5710363388061523\n",
      "step = 6237200: loss = 3.9465746879577637\n",
      "step = 6237400: loss = 4.151481628417969\n",
      "step = 6237600: loss = 4.569939136505127\n",
      "step = 6237800: loss = 4.317806720733643\n",
      "step = 6238000: loss = 3.6414124965667725\n",
      "step = 6238200: loss = 4.134559631347656\n",
      "step = 6238400: loss = 2.7699835300445557\n",
      "step = 6238600: loss = 3.7572524547576904\n",
      "step = 6238800: loss = 4.391302108764648\n",
      "step = 6239000: loss = 4.788264751434326\n",
      "step = 6239200: loss = 2.476863145828247\n",
      "step = 6239400: loss = 2.785250425338745\n",
      "step = 6239600: loss = 4.553768634796143\n",
      "step = 6239800: loss = 4.555858135223389\n",
      "step = 6240000: loss = 4.026033401489258\n",
      "step = 6240000: Average Return = 2.9000000953674316\n",
      "step = 6240200: loss = 2.9317257404327393\n",
      "step = 6240400: loss = 3.3932008743286133\n",
      "step = 6240600: loss = 4.376825332641602\n",
      "step = 6240800: loss = 3.946011543273926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 6241000: loss = 2.767214298248291\n",
      "step = 6241200: loss = 3.5316648483276367\n",
      "step = 6241400: loss = 3.628180980682373\n",
      "step = 6241600: loss = 4.351380348205566\n",
      "step = 6241800: loss = 4.881364822387695\n",
      "step = 6242000: loss = 3.1259071826934814\n",
      "step = 6242200: loss = 2.677215576171875\n",
      "step = 6242400: loss = 2.850184679031372\n",
      "step = 6242600: loss = 4.475283622741699\n",
      "step = 6242800: loss = 4.338151931762695\n",
      "step = 6243000: loss = 3.1811656951904297\n",
      "step = 6243200: loss = 3.9290285110473633\n",
      "step = 6243400: loss = 4.010026931762695\n",
      "step = 6243600: loss = 3.707888603210449\n",
      "step = 6243800: loss = 3.4739537239074707\n",
      "step = 6244000: loss = 2.968850612640381\n",
      "step = 6244200: loss = 4.702167987823486\n",
      "step = 6244400: loss = 2.5714950561523438\n",
      "step = 6244600: loss = 1.9401934146881104\n",
      "step = 6244800: loss = 3.2901835441589355\n",
      "step = 6245000: loss = 3.9699056148529053\n",
      "step = 6245000: Average Return = 3.4000000953674316\n",
      "step = 6245200: loss = 3.0029077529907227\n",
      "step = 6245400: loss = 3.5229902267456055\n",
      "step = 6245600: loss = 3.648176431655884\n",
      "step = 6245800: loss = 4.21828031539917\n",
      "step = 6246000: loss = 3.049483060836792\n",
      "step = 6246200: loss = 3.904672861099243\n",
      "step = 6246400: loss = 3.627608060836792\n",
      "step = 6246600: loss = 4.277787208557129\n",
      "step = 6246800: loss = 3.0011584758758545\n",
      "step = 6247000: loss = 3.7525148391723633\n",
      "step = 6247200: loss = 4.736354351043701\n",
      "step = 6247400: loss = 3.647050142288208\n",
      "step = 6247600: loss = 3.965226888656616\n",
      "step = 6247800: loss = 3.829920530319214\n",
      "step = 6248000: loss = 5.413881778717041\n",
      "step = 6248200: loss = 3.081522226333618\n",
      "step = 6248400: loss = 3.88368821144104\n",
      "step = 6248600: loss = 2.4817352294921875\n",
      "step = 6248800: loss = 5.0211896896362305\n",
      "step = 6249000: loss = 3.9470062255859375\n",
      "step = 6249200: loss = 4.510467529296875\n",
      "step = 6249400: loss = 3.918966054916382\n",
      "step = 6249600: loss = 3.9227678775787354\n",
      "step = 6249800: loss = 3.7379400730133057\n",
      "step = 6250000: loss = 4.931711196899414\n",
      "step = 6250000: Average Return = 2.950000047683716\n",
      "step = 6250200: loss = 3.6692357063293457\n",
      "step = 6250400: loss = 3.3904902935028076\n",
      "step = 6250600: loss = 4.091668605804443\n",
      "step = 6250800: loss = 4.444216251373291\n",
      "step = 6251000: loss = 3.2622289657592773\n",
      "step = 6251200: loss = 3.3624038696289062\n",
      "step = 6251400: loss = 3.5643069744110107\n",
      "step = 6251600: loss = 3.5153608322143555\n",
      "step = 6251800: loss = 3.224944591522217\n",
      "step = 6252000: loss = 5.045076847076416\n",
      "step = 6252200: loss = 4.189113616943359\n",
      "step = 6252400: loss = 4.483188629150391\n",
      "step = 6252600: loss = 3.7334706783294678\n",
      "step = 6252800: loss = 3.6341235637664795\n",
      "step = 6253000: loss = 3.6152632236480713\n",
      "step = 6253200: loss = 4.5502610206604\n",
      "step = 6253400: loss = 4.963600158691406\n",
      "step = 6253600: loss = 4.168736934661865\n",
      "step = 6253800: loss = 3.927751302719116\n",
      "step = 6254000: loss = 3.9936482906341553\n",
      "step = 6254200: loss = 3.3709940910339355\n",
      "step = 6254400: loss = 4.406595230102539\n",
      "step = 6254600: loss = 4.807447910308838\n",
      "step = 6254800: loss = 3.7261528968811035\n",
      "step = 6255000: loss = 2.761472702026367\n",
      "step = 6255000: Average Return = 4.449999809265137\n",
      "step = 6255200: loss = 3.045085906982422\n",
      "step = 6255400: loss = 4.616220474243164\n",
      "step = 6255600: loss = 4.688420295715332\n",
      "step = 6255800: loss = 3.0565240383148193\n",
      "step = 6256000: loss = 4.337875843048096\n",
      "step = 6256200: loss = 3.7560558319091797\n",
      "step = 6256400: loss = 3.6954433917999268\n",
      "step = 6256600: loss = 3.6513519287109375\n",
      "step = 6256800: loss = 3.386197328567505\n",
      "step = 6257000: loss = 3.3395636081695557\n",
      "step = 6257200: loss = 4.5651140213012695\n",
      "step = 6257400: loss = 3.5307884216308594\n",
      "step = 6257600: loss = 2.6211769580841064\n",
      "step = 6257800: loss = 3.0345964431762695\n",
      "step = 6258000: loss = 3.8483715057373047\n",
      "step = 6258200: loss = 5.025367736816406\n",
      "step = 6258400: loss = 3.98516845703125\n",
      "step = 6258600: loss = 5.441630840301514\n",
      "step = 6258800: loss = 4.318368434906006\n",
      "step = 6259000: loss = 5.365060806274414\n",
      "step = 6259200: loss = 4.186640739440918\n",
      "step = 6259400: loss = 3.0805766582489014\n",
      "step = 6259600: loss = 4.3849077224731445\n",
      "step = 6259800: loss = 2.744075298309326\n",
      "step = 6260000: loss = 2.624544382095337\n",
      "step = 6260000: Average Return = 3.950000047683716\n",
      "step = 6260200: loss = 3.207731246948242\n",
      "step = 6260400: loss = 4.507476806640625\n",
      "step = 6260600: loss = 4.427070617675781\n",
      "step = 6260800: loss = 5.06799840927124\n",
      "step = 6261000: loss = 3.6815154552459717\n",
      "step = 6261200: loss = 4.0035014152526855\n",
      "step = 6261400: loss = 4.2780890464782715\n",
      "step = 6261600: loss = 2.4981584548950195\n",
      "step = 6261800: loss = 4.7988176345825195\n",
      "step = 6262000: loss = 3.1175026893615723\n",
      "step = 6262200: loss = 3.6153862476348877\n",
      "step = 6262400: loss = 4.775314807891846\n",
      "step = 6262600: loss = 4.674408912658691\n",
      "step = 6262800: loss = 4.4739670753479\n",
      "step = 6263000: loss = 4.3715925216674805\n",
      "step = 6263200: loss = 3.5705559253692627\n",
      "step = 6263400: loss = 4.222585201263428\n",
      "step = 6263600: loss = 5.397601127624512\n",
      "step = 6263800: loss = 3.159281015396118\n",
      "step = 6264000: loss = 3.774732828140259\n",
      "step = 6264200: loss = 4.908083438873291\n",
      "step = 6264400: loss = 3.680187702178955\n",
      "step = 6264600: loss = 4.148182392120361\n",
      "step = 6264800: loss = 4.8441667556762695\n",
      "step = 6265000: loss = 2.4429681301116943\n",
      "step = 6265000: Average Return = 4.599999904632568\n",
      "step = 6265200: loss = 3.12853741645813\n",
      "step = 6265400: loss = 4.622257709503174\n",
      "step = 6265600: loss = 3.479360818862915\n",
      "step = 6265800: loss = 2.1951003074645996\n",
      "step = 6266000: loss = 4.725042819976807\n",
      "step = 6266200: loss = 3.770047426223755\n",
      "step = 6266400: loss = 4.238188743591309\n",
      "step = 6266600: loss = 3.9640722274780273\n",
      "step = 6266800: loss = 3.485180377960205\n",
      "step = 6267000: loss = 3.36733078956604\n",
      "step = 6267200: loss = 3.558535099029541\n",
      "step = 6267400: loss = 2.9105334281921387\n",
      "step = 6267600: loss = 3.790285348892212\n",
      "step = 6267800: loss = 2.051908254623413\n",
      "step = 6268000: loss = 3.6119115352630615\n",
      "step = 6268200: loss = 3.9550673961639404\n",
      "step = 6268400: loss = 3.317629337310791\n",
      "step = 6268600: loss = 3.9765875339508057\n",
      "step = 6268800: loss = 3.7354490756988525\n",
      "step = 6269000: loss = 3.1755402088165283\n",
      "step = 6269200: loss = 3.716623544692993\n",
      "step = 6269400: loss = 3.0179600715637207\n",
      "step = 6269600: loss = 5.105212211608887\n",
      "step = 6269800: loss = 4.241394519805908\n",
      "step = 6270000: loss = 4.293450355529785\n",
      "step = 6270000: Average Return = 4.75\n",
      "step = 6270200: loss = 3.6633219718933105\n",
      "step = 6270400: loss = 4.115025520324707\n",
      "step = 6270600: loss = 2.9937798976898193\n",
      "step = 6270800: loss = 3.4600634574890137\n",
      "step = 6271000: loss = 3.8992321491241455\n",
      "step = 6271200: loss = 3.0323617458343506\n",
      "step = 6271400: loss = 3.0515859127044678\n",
      "step = 6271600: loss = 4.086912631988525\n",
      "step = 6271800: loss = 4.185070991516113\n",
      "step = 6272000: loss = 3.2398087978363037\n",
      "step = 6272200: loss = 2.5200743675231934\n",
      "step = 6272400: loss = 2.9775853157043457\n",
      "step = 6272600: loss = 3.082547187805176\n",
      "step = 6272800: loss = 4.365900993347168\n",
      "step = 6273000: loss = 2.7497408390045166\n",
      "step = 6273200: loss = 3.1582014560699463\n",
      "step = 6273400: loss = 4.135680675506592\n",
      "step = 6273600: loss = 4.109572410583496\n",
      "step = 6273800: loss = 3.401583671569824\n",
      "step = 6274000: loss = 3.7136175632476807\n",
      "step = 6274200: loss = 3.7815141677856445\n",
      "step = 6274400: loss = 3.4059486389160156\n",
      "step = 6274600: loss = 4.006826877593994\n",
      "step = 6274800: loss = 3.7512965202331543\n",
      "step = 6275000: loss = 4.814139366149902\n",
      "step = 6275000: Average Return = 2.3499999046325684\n",
      "step = 6275200: loss = 3.935635566711426\n",
      "step = 6275400: loss = 4.1469573974609375\n",
      "step = 6275600: loss = 4.455836296081543\n",
      "step = 6275800: loss = 3.9260900020599365\n",
      "step = 6276000: loss = 3.736394166946411\n",
      "step = 6276200: loss = 3.1715197563171387\n",
      "step = 6276400: loss = 2.1330134868621826\n",
      "step = 6276600: loss = 3.150684356689453\n",
      "step = 6276800: loss = 3.512740135192871\n",
      "step = 6277000: loss = 3.9265706539154053\n",
      "step = 6277200: loss = 3.8969061374664307\n",
      "step = 6277400: loss = 3.619222402572632\n",
      "step = 6277600: loss = 3.7668983936309814\n",
      "step = 6277800: loss = 3.514153003692627\n",
      "step = 6278000: loss = 4.25883150100708\n",
      "step = 6278200: loss = 3.6799495220184326\n",
      "step = 6278400: loss = 3.7462637424468994\n",
      "step = 6278600: loss = 3.0306570529937744\n",
      "step = 6278800: loss = 3.838615894317627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 6279000: loss = 2.8336246013641357\n",
      "step = 6279200: loss = 4.341048717498779\n",
      "step = 6279400: loss = 4.535970211029053\n",
      "step = 6279600: loss = 3.252981424331665\n",
      "step = 6279800: loss = 4.196390151977539\n",
      "step = 6280000: loss = 3.363233804702759\n",
      "step = 6280000: Average Return = 3.299999952316284\n",
      "step = 6280200: loss = 3.8546974658966064\n",
      "step = 6280400: loss = 3.3904051780700684\n",
      "step = 6280600: loss = 3.02980637550354\n",
      "step = 6280800: loss = 3.6686160564422607\n",
      "step = 6281000: loss = 3.2842793464660645\n",
      "step = 6281200: loss = 4.994241714477539\n",
      "step = 6281400: loss = 2.8416991233825684\n",
      "step = 6281600: loss = 4.707734107971191\n",
      "step = 6281800: loss = 5.198725700378418\n",
      "step = 6282000: loss = 3.243246078491211\n",
      "step = 6282200: loss = 3.8905229568481445\n",
      "step = 6282400: loss = 4.225902557373047\n",
      "step = 6282600: loss = 3.3357560634613037\n",
      "step = 6282800: loss = 2.8557422161102295\n",
      "step = 6283000: loss = 4.670887470245361\n",
      "step = 6283200: loss = 3.3889567852020264\n",
      "step = 6283400: loss = 3.992499828338623\n",
      "step = 6283600: loss = 3.186849355697632\n",
      "step = 6283800: loss = 3.1102726459503174\n",
      "step = 6284000: loss = 4.771899700164795\n",
      "step = 6284200: loss = 3.5988078117370605\n",
      "step = 6284400: loss = 2.891242265701294\n",
      "step = 6284600: loss = 3.199153423309326\n",
      "step = 6284800: loss = 2.842982053756714\n",
      "step = 6285000: loss = 3.562403678894043\n",
      "step = 6285000: Average Return = 3.1500000953674316\n",
      "step = 6285200: loss = 3.7538702487945557\n",
      "step = 6285400: loss = 4.160995006561279\n",
      "step = 6285600: loss = 5.02207088470459\n",
      "step = 6285800: loss = 3.8095593452453613\n",
      "step = 6286000: loss = 2.8971331119537354\n",
      "step = 6286200: loss = 3.332244873046875\n",
      "step = 6286400: loss = 3.6867973804473877\n",
      "step = 6286600: loss = 3.0620696544647217\n",
      "step = 6286800: loss = 2.7987725734710693\n",
      "step = 6287000: loss = 4.0258026123046875\n",
      "step = 6287200: loss = 4.152282238006592\n",
      "step = 6287400: loss = 3.9591808319091797\n",
      "step = 6287600: loss = 3.3688032627105713\n",
      "step = 6287800: loss = 2.8766674995422363\n",
      "step = 6288000: loss = 3.7051122188568115\n",
      "step = 6288200: loss = 2.7138562202453613\n",
      "step = 6288400: loss = 3.1061391830444336\n",
      "step = 6288600: loss = 2.514125108718872\n",
      "step = 6288800: loss = 4.786525726318359\n",
      "step = 6289000: loss = 4.043952465057373\n",
      "step = 6289200: loss = 4.383842468261719\n",
      "step = 6289400: loss = 4.812019348144531\n",
      "step = 6289600: loss = 4.165660858154297\n",
      "step = 6289800: loss = 3.6542553901672363\n",
      "step = 6290000: loss = 4.438268184661865\n",
      "step = 6290000: Average Return = 4.550000190734863\n",
      "step = 6290200: loss = 3.7423391342163086\n",
      "step = 6290400: loss = 2.9189066886901855\n",
      "step = 6290600: loss = 3.7701432704925537\n",
      "step = 6290800: loss = 3.437305450439453\n",
      "step = 6291000: loss = 4.429860591888428\n",
      "step = 6291200: loss = 4.1434712409973145\n",
      "step = 6291400: loss = 3.2077388763427734\n",
      "step = 6291600: loss = 3.2307121753692627\n",
      "step = 6291800: loss = 2.912482261657715\n",
      "step = 6292000: loss = 4.310644626617432\n",
      "step = 6292200: loss = 4.663504123687744\n",
      "step = 6292400: loss = 4.014252662658691\n",
      "step = 6292600: loss = 4.70845365524292\n",
      "step = 6292800: loss = 3.2149465084075928\n",
      "step = 6293000: loss = 3.7091550827026367\n",
      "step = 6293200: loss = 3.9877097606658936\n",
      "step = 6293400: loss = 3.149143695831299\n",
      "step = 6293600: loss = 3.869739294052124\n",
      "step = 6293800: loss = 3.4038097858428955\n",
      "step = 6294000: loss = 3.041754961013794\n",
      "step = 6294200: loss = 4.806412220001221\n",
      "step = 6294400: loss = 3.3869993686676025\n",
      "step = 6294600: loss = 3.3556535243988037\n",
      "step = 6294800: loss = 4.4998273849487305\n",
      "step = 6295000: loss = 3.073284149169922\n",
      "step = 6295000: Average Return = 4.650000095367432\n",
      "step = 6295200: loss = 3.6646392345428467\n",
      "step = 6295400: loss = 3.000977039337158\n",
      "step = 6295600: loss = 3.3247454166412354\n",
      "step = 6295800: loss = 3.013810396194458\n",
      "step = 6296000: loss = 3.100909948348999\n",
      "step = 6296200: loss = 2.903444528579712\n",
      "step = 6296400: loss = 3.467566967010498\n",
      "step = 6296600: loss = 3.9257447719573975\n",
      "step = 6296800: loss = 5.877810955047607\n",
      "step = 6297000: loss = 3.445858955383301\n",
      "step = 6297200: loss = 3.3505992889404297\n",
      "step = 6297400: loss = 2.7746682167053223\n",
      "step = 6297600: loss = 3.8046722412109375\n",
      "step = 6297800: loss = 3.8068389892578125\n",
      "step = 6298000: loss = 4.97318696975708\n",
      "step = 6298200: loss = 4.538280963897705\n",
      "step = 6298400: loss = 3.7158257961273193\n",
      "step = 6298600: loss = 3.4710028171539307\n",
      "step = 6298800: loss = 3.43275785446167\n",
      "step = 6299000: loss = 4.20442533493042\n",
      "step = 6299200: loss = 3.0804333686828613\n",
      "step = 6299400: loss = 4.076676368713379\n",
      "step = 6299600: loss = 4.811532020568848\n",
      "step = 6299800: loss = 4.382455825805664\n",
      "step = 6300000: loss = 3.7186453342437744\n",
      "step = 6300000: Average Return = 2.8499999046325684\n",
      "step = 6300200: loss = 3.7218685150146484\n",
      "step = 6300400: loss = 4.022355079650879\n",
      "step = 6300600: loss = 2.7531657218933105\n",
      "step = 6300800: loss = 3.713812828063965\n",
      "step = 6301000: loss = 3.365161895751953\n",
      "step = 6301200: loss = 3.6441409587860107\n",
      "step = 6301400: loss = 4.5239434242248535\n",
      "step = 6301600: loss = 3.6791927814483643\n",
      "step = 6301800: loss = 4.0379319190979\n",
      "step = 6302000: loss = 3.9165947437286377\n",
      "step = 6302200: loss = 4.352215766906738\n",
      "step = 6302400: loss = 2.5899770259857178\n",
      "step = 6302600: loss = 3.4507288932800293\n",
      "step = 6302800: loss = 2.2643814086914062\n",
      "step = 6303000: loss = 3.0980446338653564\n",
      "step = 6303200: loss = 3.0593795776367188\n",
      "step = 6303400: loss = 4.175049304962158\n",
      "step = 6303600: loss = 4.451236248016357\n",
      "step = 6303800: loss = 2.4369635581970215\n",
      "step = 6304000: loss = 2.9968175888061523\n",
      "step = 6304200: loss = 3.94046950340271\n",
      "step = 6304400: loss = 3.2125091552734375\n",
      "step = 6304600: loss = 3.5558836460113525\n",
      "step = 6304800: loss = 5.213730335235596\n",
      "step = 6305000: loss = 3.311652183532715\n",
      "step = 6305000: Average Return = 3.700000047683716\n",
      "step = 6305200: loss = 3.722163677215576\n",
      "step = 6305400: loss = 4.293247699737549\n",
      "step = 6305600: loss = 3.2822117805480957\n",
      "step = 6305800: loss = 5.625275611877441\n",
      "step = 6306000: loss = 3.7736339569091797\n",
      "step = 6306200: loss = 2.7787556648254395\n",
      "step = 6306400: loss = 2.638002872467041\n",
      "step = 6306600: loss = 4.010506629943848\n",
      "step = 6306800: loss = 3.5640134811401367\n",
      "step = 6307000: loss = 4.056923866271973\n",
      "step = 6307200: loss = 2.8553102016448975\n",
      "step = 6307400: loss = 3.5450072288513184\n",
      "step = 6307600: loss = 3.301027536392212\n",
      "step = 6307800: loss = 3.839250326156616\n",
      "step = 6308000: loss = 3.2953529357910156\n",
      "step = 6308200: loss = 3.311548948287964\n",
      "step = 6308400: loss = 3.373246908187866\n",
      "step = 6308600: loss = 4.3989691734313965\n",
      "step = 6308800: loss = 3.0153427124023438\n",
      "step = 6309000: loss = 2.4060518741607666\n",
      "step = 6309200: loss = 4.2607879638671875\n",
      "step = 6309400: loss = 4.054348468780518\n",
      "step = 6309600: loss = 3.7701005935668945\n",
      "step = 6309800: loss = 3.6517632007598877\n",
      "step = 6310000: loss = 3.4695048332214355\n",
      "step = 6310000: Average Return = 4.949999809265137\n",
      "step = 6310200: loss = 3.4136040210723877\n",
      "step = 6310400: loss = 2.9104580879211426\n",
      "step = 6310600: loss = 2.8953256607055664\n",
      "step = 6310800: loss = 4.781999588012695\n",
      "step = 6311000: loss = 3.85998272895813\n",
      "step = 6311200: loss = 3.273895740509033\n",
      "step = 6311400: loss = 3.1583175659179688\n",
      "step = 6311600: loss = 3.138540267944336\n",
      "step = 6311800: loss = 4.521991729736328\n",
      "step = 6312000: loss = 4.535122394561768\n",
      "step = 6312200: loss = 2.5311765670776367\n",
      "step = 6312400: loss = 3.002586603164673\n",
      "step = 6312600: loss = 4.549415111541748\n",
      "step = 6312800: loss = 4.034185886383057\n",
      "step = 6313000: loss = 3.12101149559021\n",
      "step = 6313200: loss = 3.679893732070923\n",
      "step = 6313400: loss = 5.007678508758545\n",
      "step = 6313600: loss = 5.49195671081543\n",
      "step = 6313800: loss = 3.3058788776397705\n",
      "step = 6314000: loss = 3.30856990814209\n",
      "step = 6314200: loss = 3.7400646209716797\n",
      "step = 6314400: loss = 3.885448455810547\n",
      "step = 6314600: loss = 3.670365571975708\n",
      "step = 6314800: loss = 3.9113306999206543\n",
      "step = 6315000: loss = 4.1904826164245605\n",
      "step = 6315000: Average Return = 2.4000000953674316\n",
      "step = 6315200: loss = 4.540862083435059\n",
      "step = 6315400: loss = 3.540743350982666\n",
      "step = 6315600: loss = 4.795537948608398\n",
      "step = 6315800: loss = 3.8503942489624023\n",
      "step = 6316000: loss = 4.799666404724121\n",
      "step = 6316200: loss = 4.023336410522461\n",
      "step = 6316400: loss = 4.511025428771973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 6316600: loss = 4.542575359344482\n",
      "step = 6316800: loss = 3.5240397453308105\n",
      "step = 6317000: loss = 3.98862886428833\n",
      "step = 6317200: loss = 2.725816249847412\n",
      "step = 6317400: loss = 4.578917026519775\n",
      "step = 6317600: loss = 3.1153008937835693\n",
      "step = 6317800: loss = 4.148638725280762\n",
      "step = 6318000: loss = 3.901007652282715\n",
      "step = 6318200: loss = 4.207172870635986\n",
      "step = 6318400: loss = 6.258719444274902\n",
      "step = 6318600: loss = 3.620839834213257\n",
      "step = 6318800: loss = 3.3239033222198486\n",
      "step = 6319000: loss = 4.489083290100098\n",
      "step = 6319200: loss = 3.8810834884643555\n",
      "step = 6319400: loss = 2.5742013454437256\n",
      "step = 6319600: loss = 3.527594566345215\n",
      "step = 6319800: loss = 3.556354522705078\n",
      "step = 6320000: loss = 3.367035150527954\n",
      "step = 6320000: Average Return = 2.450000047683716\n",
      "step = 6320200: loss = 3.098568916320801\n",
      "step = 6320400: loss = 3.7828691005706787\n",
      "step = 6320600: loss = 4.4021100997924805\n",
      "step = 6320800: loss = 4.561493396759033\n",
      "step = 6321000: loss = 2.719778060913086\n",
      "step = 6321200: loss = 3.6068389415740967\n",
      "step = 6321400: loss = 4.449921607971191\n",
      "step = 6321600: loss = 3.0086958408355713\n",
      "step = 6321800: loss = 3.4945170879364014\n",
      "step = 6322000: loss = 3.8898403644561768\n",
      "step = 6322200: loss = 3.7993152141571045\n",
      "step = 6322400: loss = 3.279078960418701\n",
      "step = 6322600: loss = 2.8715286254882812\n",
      "step = 6322800: loss = 3.8508553504943848\n",
      "step = 6323000: loss = 3.283991575241089\n",
      "step = 6323200: loss = 4.311519622802734\n",
      "step = 6323400: loss = 3.8729608058929443\n",
      "step = 6323600: loss = 3.953117609024048\n",
      "step = 6323800: loss = 3.1284825801849365\n",
      "step = 6324000: loss = 4.130090236663818\n",
      "step = 6324200: loss = 4.478227615356445\n",
      "step = 6324400: loss = 2.39011812210083\n",
      "step = 6324600: loss = 5.736349582672119\n",
      "step = 6324800: loss = 4.142319679260254\n",
      "step = 6325000: loss = 3.049001455307007\n",
      "step = 6325000: Average Return = 3.200000047683716\n",
      "step = 6325200: loss = 3.814161539077759\n",
      "step = 6325400: loss = 3.0204100608825684\n",
      "step = 6325600: loss = 4.0362067222595215\n",
      "step = 6325800: loss = 4.345125675201416\n",
      "step = 6326000: loss = 4.216757297515869\n",
      "step = 6326200: loss = 4.200738430023193\n",
      "step = 6326400: loss = 4.001110076904297\n",
      "step = 6326600: loss = 2.8873825073242188\n",
      "step = 6326800: loss = 3.414856195449829\n",
      "step = 6327000: loss = 4.019901752471924\n",
      "step = 6327200: loss = 3.618208885192871\n",
      "step = 6327400: loss = 2.341428279876709\n",
      "step = 6327600: loss = 4.999594688415527\n",
      "step = 6327800: loss = 4.477946758270264\n",
      "step = 6328000: loss = 2.9793620109558105\n",
      "step = 6328200: loss = 2.882375478744507\n",
      "step = 6328400: loss = 3.991152763366699\n",
      "step = 6328600: loss = 3.7362561225891113\n",
      "step = 6328800: loss = 4.179976940155029\n",
      "step = 6329000: loss = 3.6344921588897705\n",
      "step = 6329200: loss = 4.55125093460083\n",
      "step = 6329400: loss = 3.9781668186187744\n",
      "step = 6329600: loss = 3.7578930854797363\n",
      "step = 6329800: loss = 2.6294097900390625\n",
      "step = 6330000: loss = 3.9270589351654053\n",
      "step = 6330000: Average Return = 2.8499999046325684\n",
      "step = 6330200: loss = 2.4078760147094727\n",
      "step = 6330400: loss = 4.419530391693115\n",
      "step = 6330600: loss = 4.785965919494629\n",
      "step = 6330800: loss = 5.414711952209473\n",
      "step = 6331000: loss = 4.196491241455078\n",
      "step = 6331200: loss = 3.956000804901123\n",
      "step = 6331400: loss = 2.7797670364379883\n",
      "step = 6331600: loss = 3.005643844604492\n",
      "step = 6331800: loss = 3.529061794281006\n",
      "step = 6332000: loss = 3.4295976161956787\n",
      "step = 6332200: loss = 4.266170024871826\n",
      "step = 6332400: loss = 3.7453062534332275\n",
      "step = 6332600: loss = 2.8651201725006104\n",
      "step = 6332800: loss = 3.592643976211548\n",
      "step = 6333000: loss = 3.5139055252075195\n",
      "step = 6333200: loss = 3.040968656539917\n",
      "step = 6333400: loss = 3.9135801792144775\n",
      "step = 6333600: loss = 3.482741355895996\n",
      "step = 6333800: loss = 3.1940953731536865\n",
      "step = 6334000: loss = 3.9457364082336426\n",
      "step = 6334200: loss = 3.377044677734375\n",
      "step = 6334400: loss = 4.849009990692139\n",
      "step = 6334600: loss = 4.24770450592041\n",
      "step = 6334800: loss = 2.731273651123047\n",
      "step = 6335000: loss = 3.986393451690674\n",
      "step = 6335000: Average Return = 2.450000047683716\n",
      "step = 6335200: loss = 3.282942056655884\n",
      "step = 6335400: loss = 3.7243106365203857\n",
      "step = 6335600: loss = 3.806602954864502\n",
      "step = 6335800: loss = 4.319325923919678\n",
      "step = 6336000: loss = 3.385396718978882\n",
      "step = 6336200: loss = 3.7552852630615234\n",
      "step = 6336400: loss = 3.1562814712524414\n",
      "step = 6336600: loss = 4.592564105987549\n",
      "step = 6336800: loss = 4.747471332550049\n",
      "step = 6337000: loss = 2.965177297592163\n",
      "step = 6337200: loss = 4.638974666595459\n",
      "step = 6337400: loss = 2.806321382522583\n",
      "step = 6337600: loss = 4.232010841369629\n",
      "step = 6337800: loss = 4.181497573852539\n",
      "step = 6338000: loss = 5.3416428565979\n",
      "step = 6338200: loss = 2.832080841064453\n",
      "step = 6338400: loss = 3.3500921726226807\n",
      "step = 6338600: loss = 3.9651939868927\n",
      "step = 6338800: loss = 3.915097951889038\n",
      "step = 6339000: loss = 4.968623638153076\n",
      "step = 6339200: loss = 4.087565898895264\n",
      "step = 6339400: loss = 3.5000767707824707\n",
      "step = 6339600: loss = 3.5929219722747803\n",
      "step = 6339800: loss = 3.624502420425415\n",
      "step = 6340000: loss = 3.7809269428253174\n",
      "step = 6340000: Average Return = 4.349999904632568\n",
      "step = 6340200: loss = 4.064826488494873\n",
      "step = 6340400: loss = 5.117892742156982\n",
      "step = 6340600: loss = 4.373534202575684\n",
      "step = 6340800: loss = 2.8656418323516846\n",
      "step = 6341000: loss = 4.446281433105469\n",
      "step = 6341200: loss = 3.5035817623138428\n",
      "step = 6341400: loss = 4.31822395324707\n",
      "step = 6341600: loss = 3.5010159015655518\n",
      "step = 6341800: loss = 4.436840534210205\n",
      "step = 6342000: loss = 3.690920352935791\n",
      "step = 6342200: loss = 3.7804338932037354\n",
      "step = 6342400: loss = 3.527769088745117\n",
      "step = 6342600: loss = 4.304197311401367\n",
      "step = 6342800: loss = 3.2052626609802246\n",
      "step = 6343000: loss = 3.256568431854248\n",
      "step = 6343200: loss = 3.904337167739868\n",
      "step = 6343400: loss = 3.811723232269287\n",
      "step = 6343600: loss = 3.1510753631591797\n",
      "step = 6343800: loss = 4.070417404174805\n",
      "step = 6344000: loss = 3.97525691986084\n",
      "step = 6344200: loss = 3.4551327228546143\n",
      "step = 6344400: loss = 4.650547504425049\n",
      "step = 6344600: loss = 3.493997812271118\n",
      "step = 6344800: loss = 3.8693864345550537\n",
      "step = 6345000: loss = 4.710540771484375\n",
      "step = 6345000: Average Return = 4.050000190734863\n",
      "step = 6345200: loss = 3.6133620738983154\n",
      "step = 6345400: loss = 3.7531542778015137\n",
      "step = 6345600: loss = 2.9394915103912354\n",
      "step = 6345800: loss = 3.6801371574401855\n",
      "step = 6346000: loss = 3.3802406787872314\n",
      "step = 6346200: loss = 4.098384857177734\n",
      "step = 6346400: loss = 3.3603789806365967\n",
      "step = 6346600: loss = 4.137496471405029\n",
      "step = 6346800: loss = 4.421564102172852\n",
      "step = 6347000: loss = 3.950944662094116\n",
      "step = 6347200: loss = 2.7709970474243164\n",
      "step = 6347400: loss = 3.7456016540527344\n",
      "step = 6347600: loss = 3.936516046524048\n",
      "step = 6347800: loss = 4.426687717437744\n",
      "step = 6348000: loss = 2.508683204650879\n",
      "step = 6348200: loss = 3.348905563354492\n",
      "step = 6348400: loss = 3.9678738117218018\n",
      "step = 6348600: loss = 3.618614435195923\n",
      "step = 6348800: loss = 3.6633007526397705\n",
      "step = 6349000: loss = 2.9476001262664795\n",
      "step = 6349200: loss = 5.0558929443359375\n",
      "step = 6349400: loss = 3.5415306091308594\n",
      "step = 6349600: loss = 2.5240025520324707\n",
      "step = 6349800: loss = 3.574467658996582\n",
      "step = 6350000: loss = 4.080533504486084\n",
      "step = 6350000: Average Return = 3.049999952316284\n",
      "step = 6350200: loss = 3.5193662643432617\n",
      "step = 6350400: loss = 3.3246397972106934\n",
      "step = 6350600: loss = 3.2361881732940674\n",
      "step = 6350800: loss = 4.189043045043945\n",
      "step = 6351000: loss = 4.659657001495361\n",
      "step = 6351200: loss = 4.008217811584473\n",
      "step = 6351400: loss = 3.9754302501678467\n",
      "step = 6351600: loss = 3.9845635890960693\n",
      "step = 6351800: loss = 5.171872615814209\n",
      "step = 6352000: loss = 3.0720911026000977\n",
      "step = 6352200: loss = 3.226534128189087\n",
      "step = 6352400: loss = 4.203010082244873\n",
      "step = 6352600: loss = 3.9186501502990723\n",
      "step = 6352800: loss = 3.8315207958221436\n",
      "step = 6353000: loss = 3.9297311305999756\n",
      "step = 6353200: loss = 4.046873569488525\n",
      "step = 6353400: loss = 3.2988393306732178\n",
      "step = 6353600: loss = 3.2512011528015137\n",
      "step = 6353800: loss = 4.641241550445557\n",
      "step = 6354000: loss = 4.715098857879639\n",
      "step = 6354200: loss = 2.095445156097412\n",
      "step = 6354400: loss = 3.0092227458953857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 6354600: loss = 2.839888334274292\n",
      "step = 6354800: loss = 4.561308860778809\n",
      "step = 6355000: loss = 4.070228576660156\n",
      "step = 6355000: Average Return = 3.799999952316284\n",
      "step = 6355200: loss = 3.4362664222717285\n",
      "step = 6355400: loss = 3.819904088973999\n",
      "step = 6355600: loss = 3.8827462196350098\n",
      "step = 6355800: loss = 3.5644874572753906\n",
      "step = 6356000: loss = 3.658891201019287\n",
      "step = 6356200: loss = 4.027995586395264\n",
      "step = 6356400: loss = 2.8364593982696533\n",
      "step = 6356600: loss = 4.59271240234375\n",
      "step = 6356800: loss = 4.0071516036987305\n",
      "step = 6357000: loss = 4.975329399108887\n",
      "step = 6357200: loss = 3.718966007232666\n",
      "step = 6357400: loss = 2.5153326988220215\n",
      "step = 6357600: loss = 4.01694393157959\n",
      "step = 6357800: loss = 3.4677867889404297\n",
      "step = 6358000: loss = 3.2129745483398438\n",
      "step = 6358200: loss = 3.427034854888916\n",
      "step = 6358400: loss = 3.343395233154297\n",
      "step = 6358600: loss = 3.7774670124053955\n",
      "step = 6358800: loss = 4.0924482345581055\n",
      "step = 6359000: loss = 4.499020099639893\n",
      "step = 6359200: loss = 5.482162952423096\n",
      "step = 6359400: loss = 3.9579684734344482\n",
      "step = 6359600: loss = 4.26019287109375\n",
      "step = 6359800: loss = 2.4524190425872803\n",
      "step = 6360000: loss = 2.862974166870117\n",
      "step = 6360000: Average Return = 2.9000000953674316\n",
      "step = 6360200: loss = 5.065176486968994\n",
      "step = 6360400: loss = 2.6838014125823975\n",
      "step = 6360600: loss = 5.047518253326416\n",
      "step = 6360800: loss = 3.2423956394195557\n",
      "step = 6361000: loss = 4.069040775299072\n",
      "step = 6361200: loss = 4.556704521179199\n",
      "step = 6361400: loss = 3.059758186340332\n",
      "step = 6361600: loss = 4.154526710510254\n",
      "step = 6361800: loss = 3.4535162448883057\n",
      "step = 6362000: loss = 4.288529396057129\n",
      "step = 6362200: loss = 4.486351490020752\n",
      "step = 6362400: loss = 4.729291915893555\n",
      "step = 6362600: loss = 3.5624730587005615\n",
      "step = 6362800: loss = 3.0930001735687256\n",
      "step = 6363000: loss = 3.5661065578460693\n",
      "step = 6363200: loss = 2.7872564792633057\n",
      "step = 6363400: loss = 3.4410150051116943\n",
      "step = 6363600: loss = 4.961636543273926\n",
      "step = 6363800: loss = 3.788803815841675\n",
      "step = 6364000: loss = 5.466986179351807\n",
      "step = 6364200: loss = 4.671375751495361\n",
      "step = 6364400: loss = 3.7927894592285156\n",
      "step = 6364600: loss = 5.030566215515137\n",
      "step = 6364800: loss = 3.7829790115356445\n",
      "step = 6365000: loss = 3.722832202911377\n",
      "step = 6365000: Average Return = 1.350000023841858\n",
      "step = 6365200: loss = 3.4298417568206787\n",
      "step = 6365400: loss = 4.2911505699157715\n",
      "step = 6365600: loss = 3.9662282466888428\n",
      "step = 6365800: loss = 3.843667507171631\n",
      "step = 6366000: loss = 2.569488525390625\n",
      "step = 6366200: loss = 3.432861566543579\n",
      "step = 6366400: loss = 4.09100341796875\n",
      "step = 6366600: loss = 4.058491230010986\n",
      "step = 6366800: loss = 2.848834276199341\n",
      "step = 6367000: loss = 3.7511043548583984\n",
      "step = 6367200: loss = 3.5479204654693604\n",
      "step = 6367400: loss = 3.7285313606262207\n",
      "step = 6367600: loss = 3.730975866317749\n",
      "step = 6367800: loss = 4.230236530303955\n",
      "step = 6368000: loss = 3.6829521656036377\n",
      "step = 6368200: loss = 4.131408214569092\n",
      "step = 6368400: loss = 3.2209599018096924\n",
      "step = 6368600: loss = 4.264011859893799\n",
      "step = 6368800: loss = 3.692981481552124\n",
      "step = 6369000: loss = 3.877230167388916\n",
      "step = 6369200: loss = 3.525738477706909\n",
      "step = 6369400: loss = 3.2426981925964355\n",
      "step = 6369600: loss = 5.153725624084473\n",
      "step = 6369800: loss = 3.949658155441284\n",
      "step = 6370000: loss = 3.7761356830596924\n",
      "step = 6370000: Average Return = 4.599999904632568\n",
      "step = 6370200: loss = 4.488937854766846\n",
      "step = 6370400: loss = 4.23541259765625\n",
      "step = 6370600: loss = 3.9458696842193604\n",
      "step = 6370800: loss = 3.269322395324707\n",
      "step = 6371000: loss = 4.346597671508789\n",
      "step = 6371200: loss = 4.646303653717041\n",
      "step = 6371400: loss = 3.5210094451904297\n",
      "step = 6371600: loss = 4.201019287109375\n",
      "step = 6371800: loss = 4.213417053222656\n",
      "step = 6372000: loss = 3.563981771469116\n",
      "step = 6372200: loss = 4.133491039276123\n",
      "step = 6372400: loss = 3.39540958404541\n",
      "step = 6372600: loss = 3.7168421745300293\n",
      "step = 6372800: loss = 3.079362392425537\n",
      "step = 6373000: loss = 3.4189958572387695\n",
      "step = 6373200: loss = 4.183713436126709\n",
      "step = 6373400: loss = 4.504786491394043\n",
      "step = 6373600: loss = 3.772925615310669\n",
      "step = 6373800: loss = 4.155153274536133\n",
      "step = 6374000: loss = 3.2052488327026367\n",
      "step = 6374200: loss = 4.794062614440918\n",
      "step = 6374400: loss = 2.5486648082733154\n",
      "step = 6374600: loss = 3.478412389755249\n",
      "step = 6374800: loss = 4.348118305206299\n",
      "step = 6375000: loss = 4.149998188018799\n",
      "step = 6375000: Average Return = 3.950000047683716\n",
      "step = 6375200: loss = 4.5466203689575195\n",
      "step = 6375400: loss = 4.132316589355469\n",
      "step = 6375600: loss = 3.743783712387085\n",
      "step = 6375800: loss = 4.003547191619873\n",
      "step = 6376000: loss = 3.296786069869995\n",
      "step = 6376200: loss = 3.002631664276123\n",
      "step = 6376400: loss = 4.080659866333008\n",
      "step = 6376600: loss = 4.017547607421875\n",
      "step = 6376800: loss = 4.453124523162842\n",
      "step = 6377000: loss = 3.4994425773620605\n",
      "step = 6377200: loss = 2.3897078037261963\n",
      "step = 6377400: loss = 3.1601476669311523\n",
      "step = 6377600: loss = 4.697621822357178\n",
      "step = 6377800: loss = 3.3134334087371826\n",
      "step = 6378000: loss = 5.1480841636657715\n",
      "step = 6378200: loss = 3.713656425476074\n",
      "step = 6378400: loss = 3.5469133853912354\n",
      "step = 6378600: loss = 2.9367833137512207\n",
      "step = 6378800: loss = 4.019500732421875\n",
      "step = 6379000: loss = 4.586619853973389\n",
      "step = 6379200: loss = 3.4282708168029785\n",
      "step = 6379400: loss = 6.31547212600708\n",
      "step = 6379600: loss = 4.134310245513916\n",
      "step = 6379800: loss = 3.588129758834839\n",
      "step = 6380000: loss = 3.8557357788085938\n",
      "step = 6380000: Average Return = 4.150000095367432\n",
      "step = 6380200: loss = 3.2700212001800537\n",
      "step = 6380400: loss = 3.070035934448242\n",
      "step = 6380600: loss = 4.666043281555176\n",
      "step = 6380800: loss = 3.7572734355926514\n",
      "step = 6381000: loss = 4.015307426452637\n",
      "step = 6381200: loss = 5.10584020614624\n",
      "step = 6381400: loss = 3.677051305770874\n",
      "step = 6381600: loss = 4.216385841369629\n",
      "step = 6381800: loss = 4.244687557220459\n",
      "step = 6382000: loss = 3.915069580078125\n",
      "step = 6382200: loss = 3.7766454219818115\n",
      "step = 6382400: loss = 3.341641664505005\n",
      "step = 6382600: loss = 3.9292027950286865\n",
      "step = 6382800: loss = 3.399542808532715\n",
      "step = 6383000: loss = 2.8990795612335205\n",
      "step = 6383200: loss = 3.218083381652832\n",
      "step = 6383400: loss = 3.219782829284668\n",
      "step = 6383600: loss = 3.979201078414917\n",
      "step = 6383800: loss = 4.0090813636779785\n",
      "step = 6384000: loss = 3.669834613800049\n",
      "step = 6384200: loss = 2.4292256832122803\n",
      "step = 6384400: loss = 4.327849864959717\n",
      "step = 6384600: loss = 4.44349479675293\n",
      "step = 6384800: loss = 3.116607189178467\n",
      "step = 6385000: loss = 4.421621322631836\n",
      "step = 6385000: Average Return = 2.950000047683716\n",
      "step = 6385200: loss = 5.057636737823486\n",
      "step = 6385400: loss = 2.1663620471954346\n",
      "step = 6385600: loss = 3.2277398109436035\n",
      "step = 6385800: loss = 4.429062843322754\n",
      "step = 6386000: loss = 4.242835998535156\n",
      "step = 6386200: loss = 5.19936466217041\n",
      "step = 6386400: loss = 3.995720148086548\n",
      "step = 6386600: loss = 2.9880871772766113\n",
      "step = 6386800: loss = 3.279442310333252\n",
      "step = 6387000: loss = 4.8671488761901855\n",
      "step = 6387200: loss = 3.5627734661102295\n",
      "step = 6387400: loss = 3.3632540702819824\n",
      "step = 6387600: loss = 4.814797878265381\n",
      "step = 6387800: loss = 3.353344440460205\n",
      "step = 6388000: loss = 3.407668113708496\n",
      "step = 6388200: loss = 2.5464723110198975\n",
      "step = 6388400: loss = 5.264094352722168\n",
      "step = 6388600: loss = 4.293294429779053\n",
      "step = 6388800: loss = 3.219578266143799\n",
      "step = 6389000: loss = 4.755160808563232\n",
      "step = 6389200: loss = 2.7125189304351807\n",
      "step = 6389400: loss = 3.491375684738159\n",
      "step = 6389600: loss = 3.8402791023254395\n",
      "step = 6389800: loss = 3.022707462310791\n",
      "step = 6390000: loss = 4.061488151550293\n",
      "step = 6390000: Average Return = 2.700000047683716\n",
      "step = 6390200: loss = 4.4434003829956055\n",
      "step = 6390400: loss = 4.5098066329956055\n",
      "step = 6390600: loss = 3.417679786682129\n",
      "step = 6390800: loss = 3.3162734508514404\n",
      "step = 6391000: loss = 4.569591999053955\n",
      "step = 6391200: loss = 5.180812358856201\n",
      "step = 6391400: loss = 5.705418586730957\n",
      "step = 6391600: loss = 4.779982566833496\n",
      "step = 6391800: loss = 4.339387893676758\n",
      "step = 6392000: loss = 3.037226438522339\n",
      "step = 6392200: loss = 3.9006402492523193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 6392400: loss = 2.91021466255188\n",
      "step = 6392600: loss = 3.4500012397766113\n",
      "step = 6392800: loss = 3.954021453857422\n",
      "step = 6393000: loss = 3.9212286472320557\n",
      "step = 6393200: loss = 2.492276191711426\n",
      "step = 6393400: loss = 4.197525978088379\n",
      "step = 6393600: loss = 5.115484714508057\n",
      "step = 6393800: loss = 3.796456813812256\n",
      "step = 6394000: loss = 3.6982085704803467\n",
      "step = 6394200: loss = 4.363584518432617\n",
      "step = 6394400: loss = 3.9249043464660645\n",
      "step = 6394600: loss = 4.277926921844482\n",
      "step = 6394800: loss = 4.832815170288086\n",
      "step = 6395000: loss = 4.777397155761719\n",
      "step = 6395000: Average Return = 2.950000047683716\n",
      "step = 6395200: loss = 4.407007694244385\n",
      "step = 6395400: loss = 3.544520139694214\n",
      "step = 6395600: loss = 3.7875280380249023\n",
      "step = 6395800: loss = 5.119160175323486\n",
      "step = 6396000: loss = 4.932976722717285\n",
      "step = 6396200: loss = 2.970798969268799\n",
      "step = 6396400: loss = 3.96034836769104\n",
      "step = 6396600: loss = 4.10599422454834\n",
      "step = 6396800: loss = 2.1380767822265625\n",
      "step = 6397000: loss = 3.936025381088257\n",
      "step = 6397200: loss = 3.233966588973999\n",
      "step = 6397400: loss = 3.4898266792297363\n",
      "step = 6397600: loss = 2.841390609741211\n",
      "step = 6397800: loss = 3.721400737762451\n",
      "step = 6398000: loss = 3.2206311225891113\n",
      "step = 6398200: loss = 2.676137685775757\n",
      "step = 6398400: loss = 4.075141906738281\n",
      "step = 6398600: loss = 4.0317230224609375\n",
      "step = 6398800: loss = 3.158212900161743\n",
      "step = 6399000: loss = 3.698880434036255\n",
      "step = 6399200: loss = 5.109776496887207\n",
      "step = 6399400: loss = 4.025019645690918\n",
      "step = 6399600: loss = 4.845365047454834\n",
      "step = 6399800: loss = 4.198159217834473\n",
      "step = 6400000: loss = 4.606629371643066\n",
      "step = 6400000: Average Return = 2.8499999046325684\n",
      "step = 6400200: loss = 3.9487144947052\n",
      "step = 6400400: loss = 3.256610870361328\n",
      "step = 6400600: loss = 4.403258800506592\n",
      "step = 6400800: loss = 4.220548629760742\n",
      "step = 6401000: loss = 5.694687843322754\n",
      "step = 6401200: loss = 3.592741012573242\n",
      "step = 6401400: loss = 3.935791015625\n",
      "step = 6401600: loss = 3.687279462814331\n",
      "step = 6401800: loss = 4.721965312957764\n",
      "step = 6402000: loss = 3.7136309146881104\n",
      "step = 6402200: loss = 4.217199802398682\n",
      "step = 6402400: loss = 4.1492204666137695\n",
      "step = 6402600: loss = 4.621537208557129\n",
      "step = 6402800: loss = 3.9629178047180176\n",
      "step = 6403000: loss = 3.311378002166748\n",
      "step = 6403200: loss = 4.345820426940918\n",
      "step = 6403400: loss = 3.2758781909942627\n",
      "step = 6403600: loss = 2.7383127212524414\n",
      "step = 6403800: loss = 5.219570636749268\n",
      "step = 6404000: loss = 4.50611686706543\n",
      "step = 6404200: loss = 4.0514421463012695\n",
      "step = 6404400: loss = 4.1477580070495605\n",
      "step = 6404600: loss = 4.33760929107666\n",
      "step = 6404800: loss = 3.7712957859039307\n",
      "step = 6405000: loss = 4.30800199508667\n",
      "step = 6405000: Average Return = 4.0\n",
      "step = 6405200: loss = 3.1055169105529785\n",
      "step = 6405400: loss = 3.6034252643585205\n",
      "step = 6405600: loss = 4.628244400024414\n",
      "step = 6405800: loss = 4.421295642852783\n",
      "step = 6406000: loss = 4.03795862197876\n",
      "step = 6406200: loss = 4.5659284591674805\n",
      "step = 6406400: loss = 3.793390989303589\n",
      "step = 6406600: loss = 1.8906062841415405\n",
      "step = 6406800: loss = 3.3244776725769043\n",
      "step = 6407000: loss = 4.389859676361084\n",
      "step = 6407200: loss = 5.217270851135254\n",
      "step = 6407400: loss = 3.9229860305786133\n",
      "step = 6407600: loss = 3.7955589294433594\n",
      "step = 6407800: loss = 4.615144729614258\n",
      "step = 6408000: loss = 3.797459363937378\n",
      "step = 6408200: loss = 5.05606746673584\n",
      "step = 6408400: loss = 3.336662530899048\n",
      "step = 6408600: loss = 2.776951789855957\n",
      "step = 6408800: loss = 4.0845441818237305\n",
      "step = 6409000: loss = 2.956439733505249\n",
      "step = 6409200: loss = 3.2469100952148438\n",
      "step = 6409400: loss = 4.173558712005615\n",
      "step = 6409600: loss = 4.925432205200195\n",
      "step = 6409800: loss = 2.90018367767334\n",
      "step = 6410000: loss = 3.1280674934387207\n",
      "step = 6410000: Average Return = 2.25\n",
      "step = 6410200: loss = 3.7110073566436768\n",
      "step = 6410400: loss = 3.6803812980651855\n",
      "step = 6410600: loss = 4.562916278839111\n",
      "step = 6410800: loss = 3.9329307079315186\n",
      "step = 6411000: loss = 4.159903526306152\n",
      "step = 6411200: loss = 3.4469871520996094\n",
      "step = 6411400: loss = 4.713385581970215\n",
      "step = 6411600: loss = 3.823662042617798\n",
      "step = 6411800: loss = 3.8781023025512695\n",
      "step = 6412000: loss = 3.0768990516662598\n",
      "step = 6412200: loss = 5.0401225090026855\n",
      "step = 6412400: loss = 3.9430243968963623\n",
      "step = 6412600: loss = 2.9916460514068604\n",
      "step = 6412800: loss = 3.96380615234375\n",
      "step = 6413000: loss = 2.8110766410827637\n",
      "step = 6413200: loss = 4.162509441375732\n",
      "step = 6413400: loss = 3.9991836547851562\n",
      "step = 6413600: loss = 4.265748023986816\n",
      "step = 6413800: loss = 3.901137113571167\n",
      "step = 6414000: loss = 3.446465492248535\n",
      "step = 6414200: loss = 4.010123252868652\n",
      "step = 6414400: loss = 3.5131380558013916\n",
      "step = 6414600: loss = 4.445741653442383\n",
      "step = 6414800: loss = 4.011389255523682\n",
      "step = 6415000: loss = 4.39380407333374\n",
      "step = 6415000: Average Return = 3.3499999046325684\n",
      "step = 6415200: loss = 3.6921141147613525\n",
      "step = 6415400: loss = 4.141090393066406\n",
      "step = 6415600: loss = 3.814066171646118\n",
      "step = 6415800: loss = 3.6571171283721924\n",
      "step = 6416000: loss = 5.333033561706543\n",
      "step = 6416200: loss = 3.6865458488464355\n",
      "step = 6416400: loss = 3.826643228530884\n",
      "step = 6416600: loss = 5.5623459815979\n",
      "step = 6416800: loss = 3.1210949420928955\n",
      "step = 6417000: loss = 3.7408342361450195\n",
      "step = 6417200: loss = 3.7481749057769775\n",
      "step = 6417400: loss = 4.671255588531494\n",
      "step = 6417600: loss = 3.652026891708374\n",
      "step = 6417800: loss = 3.5610454082489014\n",
      "step = 6418000: loss = 4.27675724029541\n",
      "step = 6418200: loss = 3.8994603157043457\n",
      "step = 6418400: loss = 4.313262462615967\n",
      "step = 6418600: loss = 3.225651502609253\n",
      "step = 6418800: loss = 3.5872654914855957\n",
      "step = 6419000: loss = 4.212706565856934\n",
      "step = 6419200: loss = 4.163753032684326\n",
      "step = 6419400: loss = 3.7958171367645264\n",
      "step = 6419600: loss = 4.607625484466553\n",
      "step = 6419800: loss = 3.816779136657715\n",
      "step = 6420000: loss = 3.5155162811279297\n",
      "step = 6420000: Average Return = 4.150000095367432\n",
      "step = 6420200: loss = 4.397873878479004\n",
      "step = 6420400: loss = 3.565279960632324\n",
      "step = 6420600: loss = 4.22165584564209\n",
      "step = 6420800: loss = 3.9519848823547363\n",
      "step = 6421000: loss = 3.9601080417633057\n",
      "step = 6421200: loss = 3.3159217834472656\n",
      "step = 6421400: loss = 3.306783676147461\n",
      "step = 6421600: loss = 4.817804336547852\n",
      "step = 6421800: loss = 3.9987056255340576\n",
      "step = 6422000: loss = 4.713562488555908\n",
      "step = 6422200: loss = 4.746875286102295\n",
      "step = 6422400: loss = 3.7024354934692383\n",
      "step = 6422600: loss = 4.019265174865723\n",
      "step = 6422800: loss = 5.5011725425720215\n",
      "step = 6423000: loss = 4.813879489898682\n",
      "step = 6423200: loss = 4.564910411834717\n",
      "step = 6423400: loss = 3.6032299995422363\n",
      "step = 6423600: loss = 3.726886510848999\n",
      "step = 6423800: loss = 4.250140190124512\n",
      "step = 6424000: loss = 3.993514060974121\n",
      "step = 6424200: loss = 4.2619147300720215\n",
      "step = 6424400: loss = 4.261995792388916\n",
      "step = 6424600: loss = 3.7063145637512207\n",
      "step = 6424800: loss = 4.280449867248535\n",
      "step = 6425000: loss = 3.7272396087646484\n",
      "step = 6425000: Average Return = 3.75\n",
      "step = 6425200: loss = 3.4454221725463867\n",
      "step = 6425400: loss = 3.736250638961792\n",
      "step = 6425600: loss = 3.456631660461426\n",
      "step = 6425800: loss = 3.7651751041412354\n",
      "step = 6426000: loss = 3.2904458045959473\n",
      "step = 6426200: loss = 3.8085711002349854\n",
      "step = 6426400: loss = 2.693948984146118\n",
      "step = 6426600: loss = 4.01414155960083\n",
      "step = 6426800: loss = 2.776763439178467\n",
      "step = 6427000: loss = 4.019733428955078\n",
      "step = 6427200: loss = 4.5153985023498535\n",
      "step = 6427400: loss = 3.1068694591522217\n",
      "step = 6427600: loss = 4.383761405944824\n",
      "step = 6427800: loss = 5.5981125831604\n",
      "step = 6428000: loss = 4.5305280685424805\n",
      "step = 6428200: loss = 3.9754467010498047\n",
      "step = 6428400: loss = 3.460496425628662\n",
      "step = 6428600: loss = 3.370103597640991\n",
      "step = 6428800: loss = 2.0825650691986084\n",
      "step = 6429000: loss = 4.023025035858154\n",
      "step = 6429200: loss = 3.931220293045044\n",
      "step = 6429400: loss = 3.360330820083618\n",
      "step = 6429600: loss = 3.627742290496826\n",
      "step = 6429800: loss = 3.5569121837615967\n",
      "step = 6430000: loss = 2.370948553085327\n",
      "step = 6430000: Average Return = 5.449999809265137\n",
      "step = 6430200: loss = 5.198901176452637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 6430400: loss = 4.28941535949707\n",
      "step = 6430600: loss = 3.0479037761688232\n",
      "step = 6430800: loss = 3.3355937004089355\n",
      "step = 6431000: loss = 3.2052743434906006\n",
      "step = 6431200: loss = 3.7274656295776367\n",
      "step = 6431400: loss = 4.508556842803955\n",
      "step = 6431600: loss = 3.806908369064331\n",
      "step = 6431800: loss = 4.118042469024658\n",
      "step = 6432000: loss = 3.809757709503174\n",
      "step = 6432200: loss = 3.931835889816284\n",
      "step = 6432400: loss = 3.9952192306518555\n",
      "step = 6432600: loss = 3.942119598388672\n",
      "step = 6432800: loss = 3.3144617080688477\n",
      "step = 6433000: loss = 3.897374391555786\n",
      "step = 6433200: loss = 4.517910480499268\n",
      "step = 6433400: loss = 4.381270885467529\n",
      "step = 6433600: loss = 3.4535162448883057\n",
      "step = 6433800: loss = 3.6380908489227295\n",
      "step = 6434000: loss = 3.9658761024475098\n",
      "step = 6434200: loss = 4.309756755828857\n",
      "step = 6434400: loss = 3.978519916534424\n",
      "step = 6434600: loss = 4.292654514312744\n",
      "step = 6434800: loss = 4.024550914764404\n",
      "step = 6435000: loss = 2.922452688217163\n",
      "step = 6435000: Average Return = 2.799999952316284\n",
      "step = 6435200: loss = 2.7850537300109863\n",
      "step = 6435400: loss = 4.82533073425293\n",
      "step = 6435600: loss = 3.687763214111328\n",
      "step = 6435800: loss = 3.9579668045043945\n",
      "step = 6436000: loss = 3.2959303855895996\n",
      "step = 6436200: loss = 2.9099667072296143\n",
      "step = 6436400: loss = 3.765789031982422\n",
      "step = 6436600: loss = 4.294022560119629\n",
      "step = 6436800: loss = 3.4273900985717773\n",
      "step = 6437000: loss = 3.585829973220825\n",
      "step = 6437200: loss = 3.7863545417785645\n",
      "step = 6437400: loss = 2.777212142944336\n",
      "step = 6437600: loss = 3.979905843734741\n",
      "step = 6437800: loss = 5.011630058288574\n",
      "step = 6438000: loss = 3.5013585090637207\n",
      "step = 6438200: loss = 3.6843855381011963\n",
      "step = 6438400: loss = 4.53848934173584\n",
      "step = 6438600: loss = 3.9390666484832764\n",
      "step = 6438800: loss = 3.4658203125\n",
      "step = 6439000: loss = 2.9936351776123047\n",
      "step = 6439200: loss = 4.3760175704956055\n",
      "step = 6439400: loss = 5.059106826782227\n",
      "step = 6439600: loss = 3.7850897312164307\n",
      "step = 6439800: loss = 3.2085790634155273\n",
      "step = 6440000: loss = 4.40516996383667\n",
      "step = 6440000: Average Return = 4.199999809265137\n",
      "step = 6440200: loss = 3.9619905948638916\n",
      "step = 6440400: loss = 4.913304805755615\n",
      "step = 6440600: loss = 3.433309555053711\n",
      "step = 6440800: loss = 3.882066488265991\n",
      "step = 6441000: loss = 5.301535606384277\n",
      "step = 6441200: loss = 3.865318536758423\n",
      "step = 6441400: loss = 4.765782833099365\n",
      "step = 6441600: loss = 2.853036403656006\n",
      "step = 6441800: loss = 4.315603733062744\n",
      "step = 6442000: loss = 3.66306209564209\n",
      "step = 6442200: loss = 3.2615294456481934\n",
      "step = 6442400: loss = 4.122317790985107\n",
      "step = 6442600: loss = 2.21464467048645\n",
      "step = 6442800: loss = 3.37225604057312\n",
      "step = 6443000: loss = 3.334102153778076\n",
      "step = 6443200: loss = 3.6618614196777344\n",
      "step = 6443400: loss = 3.579055070877075\n",
      "step = 6443600: loss = 3.908707857131958\n",
      "step = 6443800: loss = 4.103740215301514\n",
      "step = 6444000: loss = 3.048607110977173\n",
      "step = 6444200: loss = 5.390805721282959\n",
      "step = 6444400: loss = 5.252781867980957\n",
      "step = 6444600: loss = 2.6827588081359863\n",
      "step = 6444800: loss = 4.879185676574707\n",
      "step = 6445000: loss = 4.2016730308532715\n",
      "step = 6445000: Average Return = 2.5999999046325684\n",
      "step = 6445200: loss = 4.195852279663086\n",
      "step = 6445400: loss = 3.72579026222229\n",
      "step = 6445600: loss = 4.401390075683594\n",
      "step = 6445800: loss = 3.908154010772705\n",
      "step = 6446000: loss = 4.639547824859619\n"
     ]
    }
   ],
   "source": [
    "for _ in range(num_iterations):\n",
    "    collect_data(train_env, agent.collect_policy, replay_buffer, collect_steps_per_iteration)\n",
    "\n",
    "    experience, unused_info = next(iterator)\n",
    "    train_loss = agent.train(experience).loss\n",
    "\n",
    "    step = agent.train_step_counter.numpy()\n",
    "\n",
    "    if step % log_interval == 0:\n",
    "        print('step = {0}: loss = {1}'.format(step, train_loss))\n",
    "\n",
    "    if step % eval_interval == 0:\n",
    "        avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "        print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
    "        returns.append(avg_return)\n",
    "        train_checkpointer.save(train_step_counter)\n",
    "        with open(\"Checkpoints1/returns.txt\", \"w\") as txt:\n",
    "            for item in returns:\n",
    "                txt.write(str(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d881e4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(policy):\n",
    "    agent_policy = policy\n",
    "    pygame.init()\n",
    "    running = True\n",
    "    env = TsuroEnv()\n",
    "    state = env.reset()\n",
    "    \n",
    "    for i in range(env.num_players):\n",
    "        temp = np.where(env.player_board == i+1)\n",
    "        print(\"PLAYER \" + str(i+1) + \"'S STARTING POS: \\nTile: \" + str(temp[0]) + \"    Node: \" + str(temp[1]))\n",
    "        \n",
    "    while running:\n",
    "        to_move = True\n",
    "        env.render(mode = \"human\")\n",
    "        print(env.player_tiles[0])\n",
    "        print(env.player_tiles[1])\n",
    "        while to_move:\n",
    "            mouse = pygame.mouse.get_pos()\n",
    "            if env.current_player == 1:\n",
    "                if 75 + 100 > mouse[0] > 75 and 635 + 100 > mouse[1] > 635:\n",
    "                    for event in pygame.event.get():\n",
    "                        if event.type == pygame.KEYDOWN:\n",
    "                            if event.key == pygame.K_r:\n",
    "                                tile = env.tiles[env.player_tiles[0][0]]\n",
    "                                tile.rotate_tile(1)\n",
    "                                env.render(mode = \"human\")\n",
    "                        if event.type == pygame.MOUSEBUTTONDOWN:\n",
    "                            to_move = False\n",
    "                            env.step(move = 0)\n",
    "                            env.render(mode = \"human\")\n",
    "                elif 275 + 100 > mouse[0] > 275 and 635 + 100 > mouse[1] > 635:\n",
    "                    for event in pygame.event.get():\n",
    "                        if event.type == pygame.KEYDOWN:\n",
    "                            if event.key == pygame.K_r:\n",
    "                                tile = env.tiles[env.player_tiles[0][1]]\n",
    "                                tile.rotate_tile(1)\n",
    "                                env.render(mode = \"human\")\n",
    "                        if event.type == pygame.MOUSEBUTTONDOWN:\n",
    "                            to_move = False\n",
    "                            env.step(move = 1)\n",
    "                            env.render(mode = \"human\")\n",
    "                elif 475 + 100 > mouse[0] > 475 and 635 + 100 > mouse[1] > 635:\n",
    "                    for event in pygame.event.get():\n",
    "                        if event.type == pygame.KEYDOWN:\n",
    "                            if event.key == pygame.K_r:\n",
    "                                tile = env.tiles[env.player_tiles[0][2]]\n",
    "                                tile.rotate_tile(1)\n",
    "                                env.render(mode = \"human\")\n",
    "                        if event.type == pygame.MOUSEBUTTONDOWN:\n",
    "                            to_move = False\n",
    "                            env.step(move = 2)\n",
    "                            env.render(mode = \"human\")\n",
    "\n",
    "            elif env.current_player == 2:\n",
    "                time.sleep(2)\n",
    "                observation = env.get_state\n",
    "                action = agent_policy.action(observation)\n",
    "                env.step(action)\n",
    "                env.render(mode = \"human\")\n",
    "                \n",
    "            if env.current_player == -1 or env.game_is_over():\n",
    "                env.render(mode = \"human\")\n",
    "                print(\"Winner: Player \" + str(env.current_player))\n",
    "                running = False\n",
    "\n",
    "            for event in pygame.event.get():\n",
    "                if event.type == pygame.QUIT:\n",
    "                    running = False\n",
    "                    pygame.quit()\n",
    "                 \n",
    "    if not running:\n",
    "        env.render(mode = \"human\")\n",
    "        \n",
    "    while not running:\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                pygame.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeacc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = range(0, train_step_counter + 1, eval_interval)\n",
    "plt.plot(iterations, returns)\n",
    "plt.ylabel('Average Return')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylim(top=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f864a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfec27c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
