{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bcaa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gym\n",
    "!pip install pygame\n",
    "!pip install tf_agents==0.15.0\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4929ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import pygame\n",
    "import time\n",
    "import random\n",
    "from gym import spaces\n",
    "from gym.envs.registration import register\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.networks import sequential\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.utils import common\n",
    "\n",
    "# player piece colors [player1, player2]\n",
    "colors = ['#FF0000', '#0000FF']\n",
    "\n",
    "# paths for each tile 1-35\n",
    "node_combinations = [ \n",
    "    [(0,3), (1,5), (2,6), (4,7)], [(0,4), (1,5), (2,6), (3,7)], [(0,3), (1,6), (2,5), (4,7)], [(0,6), (1,5), (2,4), (3,7)],\n",
    "    [(0,1), (2,3), (4,5), (6,7)], [(0,4), (1,5), (2,3), (6,7)], [(0,6), (1,5), (2,3), (4,7)], [(0,5), (1,4), (2,7), (3,6)],\n",
    "    [(0,5), (1,4), (2,6), (3,7)], [(0,3), (1,4), (2,5), (6,7)], [(0,6), (1,4), (2,5), (3,7)], [(0,5), (1,4), (2,3), (6,7)],\n",
    "    [(0,2), (1,3), (4,6), (5,7)], [(0,2), (1,3), (4,5), (6,7)], [(0,5), (1,3), (2,7), (4,6)], [(0,6), (1,3), (2,7), (4,5)],\n",
    "    [(0,4), (1,3), (2,6), (5,7)], [(0,5), (1,3), (2,6), (4,7)], [(0,4), (1,3), (2,5), (6,7)], [(0,6), (1,3), (2,5), (4,7)],\n",
    "    [(0,5), (1,3), (2,4), (6,7)], [(0,6), (1,3), (2,4), (5,7)], [(0,3), (1,2), (4,7), (5,6)], [(0,3), (1,2), (4,6), (5,7)],\n",
    "    [(0,3), (1,2), (4,5), (6,7)], [(0,4), (1,2), (3,7), (5,6)], [(0,5), (1,2), (3,7), (4,6)], [(0,6), (1,2), (3,7), (4,5)],\n",
    "    [(0,4), (1,2), (3,6), (5,7)], [(0,5), (1,2), (3,6), (4,7)], [(0,4), (1,2), (3,5), (6,7)], [(0,6), (1,2), (3,5), (4,7)],\n",
    "    [(0,5), (1,2), (3,4), (6,7)], [(0,6), (1,2), (3,4), (5,7)], [(0,7), (1,2), (3,4), (5,6)]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7550d8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tile():\n",
    "    def __init__(self, tile_num, tile_connections):\n",
    "        self.tile_num = tile_num\n",
    "        self.image = pygame.image.load(\"TsuroImages/\" + str(tile_num) + \".png\")\n",
    "        self.image = pygame.transform.scale(self.image, (100, 100))\n",
    "        self.tile_connections = tile_connections\n",
    "    \n",
    "    def move(self, current_node):\n",
    "        next_node = 0\n",
    "        next_player_tile = 0\n",
    "        for connection in self.tile_connections:\n",
    "            if current_node in connection:\n",
    "                n1, n2 = connection\n",
    "                if n1 == current_node:\n",
    "                    next_node, next_player_tile, next_x, next_y = self.new_tile_node(n2)\n",
    "                else:\n",
    "                    next_node, next_player_tile, next_x, next_y = self.new_tile_node(n1)\n",
    "                return next_node, next_player_tile, next_x, next_y\n",
    "        raise Exception(\"Issue in moving players\")\n",
    "    \n",
    "    # update number of times rotation should be applied to connections and image\n",
    "    def rotate_tile(self, rotate):\n",
    "        self.image = pygame.transform.rotate(self.image, rotate * -90)\n",
    "        self.tile_connections = [tuple((element + (2 * rotate)) % 8 for element in couple ) for couple in self.tile_connections]\n",
    "    \n",
    "    def new_tile_node(self, current_node):\n",
    "        next_node = 0\n",
    "        next_x = 0\n",
    "        next_y = 0\n",
    "        next_player_tile = 0\n",
    "        match current_node:\n",
    "            case 0:\n",
    "                next_node = 3\n",
    "                next_player_tile = -1\n",
    "                next_x = -1\n",
    "            case 1:\n",
    "                next_node = 6\n",
    "                next_player_tile = -6\n",
    "                next_y = -1\n",
    "            case 2:\n",
    "                next_node = 5\n",
    "                next_player_tile = -6\n",
    "                next_y = -1\n",
    "            case 3:\n",
    "                next_node = 0\n",
    "                next_player_tile = 1\n",
    "                next_x = 1\n",
    "            case 4:\n",
    "                next_node = 7\n",
    "                next_player_tile = 1\n",
    "                next_x = 1\n",
    "            case 5:\n",
    "                next_node = 2\n",
    "                next_player_tile = 6\n",
    "                next_y = 1\n",
    "            case 6:\n",
    "                next_node = 1\n",
    "                next_player_tile = 6\n",
    "                next_y = 1\n",
    "            case 7:\n",
    "                next_node = 4\n",
    "                next_player_tile = -1\n",
    "                next_x = -1\n",
    "            case _:\n",
    "                raise Exception(\"Issue in tile board\")\n",
    "                \n",
    "        return next_node, next_player_tile, next_x, next_y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f8391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TsuroEnv(gym.Env):\n",
    "    #\n",
    "    def __init__(self):\n",
    "        self.screen = None\n",
    "        self.current_player = 1\n",
    "        self.num_tiles = 35\n",
    "        self.tile_board_size = (6, 6)\n",
    "        self.player_board_size = (36,8)\n",
    "        self.num_players = 2\n",
    "        self.tiles = []\n",
    "        for i in range(self.num_tiles):\n",
    "            self.tiles.append(Tile(i, node_combinations[i]))\n",
    "            \n",
    "        self.remaining_tiles = []\n",
    "        for i in range(self.num_tiles):\n",
    "            self.remaining_tiles.append(i)\n",
    "        random.shuffle(self.remaining_tiles)\n",
    "\n",
    "        self.remaining_players = []\n",
    "        for i in range(self.num_players):\n",
    "            self.remaining_players.append(i+1)\n",
    "        \n",
    "        self.player_tiles = []\n",
    "        for i in range(self.num_players):\n",
    "            player_tiles = []\n",
    "            for i in range(3):\n",
    "                player_tiles.append(self.remaining_tiles.pop())\n",
    "            self.player_tiles.append(player_tiles)\n",
    "            \n",
    "        self.tile_board = np.zeros(self.tile_board_size, dtype = int)\n",
    "        self.player_board = np.zeros(self.player_board_size, dtype = int)\n",
    "\n",
    "        self.action_space = spaces.Discrete(11)\n",
    "        self.observation_space = spaces.Box(low=-1, high=35, shape=(327,))\n",
    "        \n",
    "    # Resets the environment to default state\n",
    "    def reset(self): \n",
    "        self.current_player = 1\n",
    "        self.tile_board = np.zeros(self.tile_board_size, dtype = int)\n",
    "        self.player_board = np.zeros(self.player_board_size, dtype = int)\n",
    "        \n",
    "        self.tiles = []\n",
    "        for i in range(self.num_tiles):\n",
    "            self.tiles.append(Tile(i, node_combinations[i]))\n",
    "            \n",
    "        self.remaining_tiles = []\n",
    "        for i in range(self.num_tiles):\n",
    "            self.remaining_tiles.append(i)\n",
    "        random.shuffle(self.remaining_tiles)\n",
    "            \n",
    "        self.remaining_players = []\n",
    "        for i in range(self.num_players):\n",
    "            self.remaining_players.append(i+1)\n",
    "            \n",
    "        self.player_tiles = []\n",
    "        for i in range(self.num_players):\n",
    "            player_tiles = []\n",
    "            for i in range(3):\n",
    "                player_tiles.append(self.remaining_tiles.pop())\n",
    "            self.player_tiles.append(player_tiles)\n",
    "            \n",
    "        #########################################\n",
    "        #TODO: TESTING STUFF TO BE REMOVED LATER#\n",
    "        #########################################\n",
    "        for i in range(self.num_players):\n",
    "            self.player_board[random.randint(0,5)][i+1] = i+1\n",
    "            \n",
    "        initial_obs = np.hstack((self.player_tiles[self.current_player - 1], self.player_board.flatten(), self.tile_board.flatten()))\n",
    "\n",
    "        return initial_obs\n",
    "    \n",
    "    # Makes a move in the game based on inputs from player or AI\n",
    "    def step(self, action = -2, move = -1):\n",
    "        if move == -1:\n",
    "            card, rotate = self.get_card(action)\n",
    "        else:\n",
    "            card = move\n",
    "            rotate = 0\n",
    "        \n",
    "        action = self.player_tiles[self.current_player - 1][card]\n",
    "        \n",
    "        if action == -1:\n",
    "            observation = np.hstack((self.player_tiles[self.current_player - 1], self.player_board.flatten(), self.tile_board.flatten()))\n",
    "            reward = -1\n",
    "            done = 0\n",
    "            return observation, reward, done, {}\n",
    "            \n",
    "        # Removes used tile and adds new tile from deck to hand\n",
    "        self.player_tiles[self.current_player-1].remove(action)\n",
    "        if len(self.remaining_tiles) > 0:\n",
    "            self.player_tiles[self.current_player-1].append(self.remaining_tiles.pop())\n",
    "        else:\n",
    "            self.player_tiles[self.current_player-1].append(-1)\n",
    "        \n",
    "        # Rotates tile (Only used by AI)\n",
    "        self.tiles[action].rotate_tile(rotate)\n",
    "        \n",
    "        reward = 0\n",
    "        self.place_tile(action+1)\n",
    "        self.move_players()\n",
    "        reward = self.reward_function()\n",
    "        if self.game_is_over():\n",
    "            done = 1\n",
    "        else:\n",
    "            done = 0\n",
    "        self.current_player = self.next_player()\n",
    "        observation = np.hstack((self.player_tiles[self.current_player - 1], self.player_board.flatten(), self.tile_board.flatten()))\n",
    "        return observation, reward, done, {}\n",
    "    \n",
    "    # Decides if the game is over\n",
    "    def game_is_over(self):\n",
    "        if len(self.remaining_players) <= 1:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    # Decides the reward (Only used for AI)\n",
    "    def reward_function(self):\n",
    "        if not self.game_is_over():\n",
    "            return 1\n",
    "        if self.game_is_over() and self.current_player in self.remaining_players:\n",
    "            return 2\n",
    "        return -1\n",
    "    \n",
    "    # Places tile in self.tile_board\n",
    "    def place_tile(self, tile):\n",
    "        tile_number, node_number = np.where(self.player_board == self.current_player)\n",
    "        x, y = TsuroEnv.euclidean_division(self, tile_number)\n",
    "        x = x[0]\n",
    "        y = y[0]\n",
    "        self.tile_board[x][y] += tile\n",
    "    \n",
    "    # Moves player piece in self.player_board\n",
    "    def move_players(self):\n",
    "        for player in self.remaining_players:\n",
    "            tile_number, node_number = np.where(self.player_board == player)\n",
    "            x, y = TsuroEnv.euclidean_division(self, tile_number)\n",
    "            x = x[0]\n",
    "            y = y[0]\n",
    "            while self.tile_board[x][y] != 0:\n",
    "                tile = self.tiles[(self.tile_board[x][y])-1]\n",
    "                next_node, next_player_tile, next_x, next_y = tile.move(node_number)\n",
    "                self.player_board[tile_number[0]][node_number[0]] = 0\n",
    "                if ((tile_number[0] % 6 == 0) and ((tile_number[0] + next_player_tile) % 6 == 5)) or (tile_number[0] + next_player_tile < 0) or (tile_number[0] + next_player_tile > 35) or ((tile_number[0] % 6 == 5) and ((tile_number[0] + next_player_tile) % 6 == 0)):\n",
    "                    self.remaining_players.remove(player)\n",
    "                    break\n",
    "                else:\n",
    "                    self.player_board[tile_number[0] + next_player_tile][next_node] = player\n",
    "                    x += next_x\n",
    "                    y += next_y\n",
    "                    tile_number, node_number = np.where(self.player_board == player)\n",
    "    \n",
    "    # Quotient and Remainder\n",
    "    def euclidean_division(self, x, y = 6):\n",
    "        return x % y, x // y\n",
    "    \n",
    "    # Action (card, rotation) from input\n",
    "    def get_card(self, x, y = 4):\n",
    "        return  x // y, x % y\n",
    "    \n",
    "    def get_state(self):\n",
    "        observation = np.hstack((self.player_tiles[self.current_player - 1], self.player_board.flatten(), self.tile_board.flatten()))\n",
    "        return observation\n",
    "\n",
    "    # Decide whos turn it is\n",
    "    def next_player(self):\n",
    "        if len(self.remaining_players) == 0:\n",
    "            return -1\n",
    "        if self.current_player not in self.remaining_players:\n",
    "            for player in self.remaining_players:\n",
    "                if player > self.current_player:\n",
    "                    return player\n",
    "                else:\n",
    "                    return self.remaining_players[0]\n",
    "        return self.remaining_players[(self.remaining_players.index(self.current_player) + 1) % len(self.remaining_players)]\n",
    "        \n",
    "    # Render the environment\n",
    "    def render(self, mode):\n",
    "        screen = pygame.display.set_mode((650, 750))\n",
    "        screen.fill((255, 255, 255))\n",
    "\n",
    "        # Draw the game board\n",
    "        board = pygame.image.load(\"TsuroImages/board.png\")\n",
    "        board = pygame.transform.scale(board, (600, 600))\n",
    "        screen.blit(board, (25,25))\n",
    "        \n",
    "        # Draw current players hand\n",
    "        for i in range (len(self.player_tiles[self.current_player-1])):\n",
    "            tile = self.player_tiles[self.current_player-1][i]\n",
    "            screen.blit(self.tiles[tile].image, (75 + (i * 200), 635))\n",
    "        \n",
    "        # Draw the tiles on the board\n",
    "        for x in range(self.tile_board_size[0]):\n",
    "            for y in range(self.tile_board_size[1]):\n",
    "                val = self.tile_board[x][y]\n",
    "                if val != 0:\n",
    "                    tile = self.tiles[val-1]\n",
    "                    screen.blit(tile.image, (25 + x * 100, 25 + y * 100))\n",
    "                    \n",
    "        # Draw the players' pieces on the board\n",
    "        for i in self.remaining_players:\n",
    "            tile_number, node_number = np.where(self.player_board == i)\n",
    "            y_add = 0\n",
    "            x_add = 0\n",
    "            y_mult = 0\n",
    "            x_mult = 0\n",
    "            \n",
    "            match node_number[0]:\n",
    "                case 0:\n",
    "                    y_add = 35\n",
    "                case 1:\n",
    "                    x_add = 35\n",
    "                case 2:\n",
    "                    x_add = 70\n",
    "                case 3:\n",
    "                    x_add = 100\n",
    "                    y_add = 35\n",
    "                case 4:\n",
    "                    x_add = 100\n",
    "                    y_add = 70\n",
    "                case 5:\n",
    "                    x_add = 70\n",
    "                    y_add = 100\n",
    "                case 6:\n",
    "                    x_add = 35\n",
    "                    y_add = 100\n",
    "                case 7:\n",
    "                     y_add = 70\n",
    "                case _:\n",
    "                    raise Exception(\"Issue in drawing the player board\")\n",
    "                    \n",
    "            if tile_number[0] != 0:\n",
    "                x_mult, y_mult = TsuroEnv.euclidean_division(self, tile_number[0])\n",
    "            \n",
    "            pygame.draw.circle(screen, colors[i-1], (25 + x_add + (100 * x_mult), 25 + y_add + (100 * y_mult)), 5)\n",
    "            \n",
    "        # Draw text to show who won when game is over\n",
    "        if self.game_is_over() or self.current_player == -1:\n",
    "            font = pygame.font.Font('freesansbold.ttf', 32)\n",
    "            text = font.render('Player ' + str(self.current_player) + ' wins', True, '#00FF00')\n",
    "            textRect = text.get_rect()\n",
    "            textRect.center = (650 // 2, 750 // 2)\n",
    "            screen.blit(text, textRect)\n",
    "            \n",
    "        pygame.display.update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8016cc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 25000000\n",
    "\n",
    "initial_collect_steps = 5000\n",
    "collect_steps_per_iteration = 1\n",
    "replay_buffer_max_length = 100000\n",
    "\n",
    "batch_size = 100\n",
    "learning_rate = 1e-3\n",
    "log_interval = 200\n",
    "\n",
    "num_eval_episodes = 20\n",
    "eval_interval = 5000\n",
    "\n",
    "register(\n",
    "    id='TsuroEnv',\n",
    "    entry_point=TsuroEnv,\n",
    ")\n",
    "\n",
    "env_name = \"TsuroEnv\"\n",
    "\n",
    "train_py_env = suite_gym.load(env_name)\n",
    "eval_py_env = suite_gym.load(env_name)\n",
    "\n",
    "train_env = tf_py_environment.TFPyEnvironment(train_py_env)\n",
    "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)\n",
    "\n",
    "fc_layer_params = (200, 100)\n",
    "action_tensor_spec = tensor_spec.from_spec(train_env.action_spec())\n",
    "num_actions = action_tensor_spec.maximum - action_tensor_spec.minimum + 1\n",
    "\n",
    "def dense_layer(num_units):\n",
    "    return tf.keras.layers.Dense(num_units, activation=tf.keras.activations.relu, kernel_initializer=tf.keras.initializers.VarianceScaling(scale=2.0, mode='fan_in', distribution='truncated_normal'))\n",
    "\n",
    "dense_layers = [dense_layer(num_units) for num_units in fc_layer_params]\n",
    "q_values_layer = tf.keras.layers.Dense(num_actions, activation=None, kernel_initializer=tf.keras.initializers.RandomUniform(minval=-0.03, maxval=0.03), bias_initializer=tf.keras.initializers.Constant(-0.2))\n",
    "q_net = sequential.Sequential(dense_layers + [q_values_layer])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "train_step_counter = tf.Variable(0)\n",
    "\n",
    "agent = dqn_agent.DqnAgent(\n",
    "    train_env.time_step_spec(),\n",
    "    train_env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer,\n",
    "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "    train_step_counter=train_step_counter)\n",
    "\n",
    "agent.initialize()\n",
    "\n",
    "eval_policy = agent.policy\n",
    "collect_policy = agent.collect_policy\n",
    "\n",
    "random_policy = random_tf_policy.RandomTFPolicy(train_env.time_step_spec(),\n",
    "                                                train_env.action_spec())\n",
    "\n",
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    data_spec=agent.collect_data_spec,\n",
    "    batch_size=train_env.batch_size,\n",
    "    max_length=replay_buffer_max_length)\n",
    "    \n",
    "def compute_avg_return(environment, policy, num_episodes=10):\n",
    "\n",
    "    total_return = 0.0\n",
    "    for _ in range(num_episodes):\n",
    "\n",
    "        time_step = environment.reset()\n",
    "        episode_return = 0.0\n",
    "\n",
    "        while not time_step.is_last():\n",
    "            action_step = policy.action(time_step)\n",
    "            time_step = environment.step(action_step.action)\n",
    "            episode_return += time_step.reward\n",
    "        total_return += episode_return\n",
    "\n",
    "    avg_return = total_return / num_episodes\n",
    "    return avg_return.numpy()[0]\n",
    "\n",
    "def collect_step(environment, policy, buffer):\n",
    "    time_step = environment.current_time_step()\n",
    "    action_step = policy.action(time_step)\n",
    "    next_time_step = environment.step(action_step)\n",
    "    # commenting out render will make training quicker\n",
    "    # environment.render(\"human\")\n",
    "    traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
    "    buffer.add_batch(traj)\n",
    "\n",
    "def collect_data(env, policy, buffer, steps):\n",
    "    for _ in range(steps):\n",
    "        collect_step(env, policy, buffer)\n",
    "\n",
    "train_checkpointer = common.Checkpointer(\n",
    "    ckpt_dir=\"Checkpoints2/\",\n",
    "    max_to_keep=1,\n",
    "    agent=agent,\n",
    "    policy=agent.policy,\n",
    "    replay_buffer=replay_buffer,\n",
    "    global_step=train_step_counter\n",
    ")\n",
    "\n",
    "train_checkpointer.initialize_or_restore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a4868d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=3, \n",
    "    sample_batch_size=batch_size, \n",
    "    num_steps=2).prefetch(3)\n",
    "\n",
    "iterator = iter(dataset)\n",
    "\n",
    "agent.train = common.function(agent.train)\n",
    "\n",
    "returns = []\n",
    "\n",
    "with open(\"Checkpoints2/returns.txt\", \"r\") as txt:\n",
    "    for line in txt:\n",
    "        returns.append(line)\n",
    "        \n",
    "for i in range(len(returns)):\n",
    "    returns[i] = returns[i].strip()\n",
    "    returns[i] = float(returns[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9565a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Collection for new agent\n",
    "'''\n",
    "collect_data(train_env, random_policy, replay_buffer, initial_collect_steps)\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "returns = [avg_return]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016920e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(num_iterations):\n",
    "    collect_data(train_env, agent.collect_policy, replay_buffer, collect_steps_per_iteration)\n",
    "\n",
    "    experience, unused_info = next(iterator)\n",
    "    train_loss = agent.train(experience).loss\n",
    "\n",
    "    step = agent.train_step_counter.numpy()\n",
    "\n",
    "    if step % log_interval == 0:\n",
    "        print('step = {0}: loss = {1}'.format(step, train_loss))\n",
    "\n",
    "    if step % eval_interval == 0:\n",
    "        avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "        print('step = {0}: Total Reward (last 10 epsiodes) = {1}'.format(step, avg_return))\n",
    "        returns.append(avg_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeacc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = range(0, train_step_counter + 1, eval_interval)\n",
    "plt.plot(iterations, returns)\n",
    "plt.ylabel('Average Return')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylim(top=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35468749",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_checkpointer.save(train_step_counter)\n",
    "with open(\"Checkpoints2/returns.txt\", \"w\") as txt:\n",
    "    for item in returns:\n",
    "        txt.write(str(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9111cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
